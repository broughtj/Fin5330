{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Brough Lecture Notes: GARCH Models in R__\n",
    "\n",
    "<br>\n",
    "\n",
    "Finance 5330: Financial Econometrics <br>\n",
    "Tyler J. Brough <br>\n",
    "Last Updated: April 1, 2019 <br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(bayesGARCH)\n",
    "require(rugarch)\n",
    "require(fGarch)\n",
    "require(zoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm <- read.csv(\"./data/IBM-1999-2003.csv\", header=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>PERMNO</th><th scope=col>date</th><th scope=col>TICKER</th><th scope=col>COMNAM</th><th scope=col>PERMCO</th><th scope=col>PRC</th><th scope=col>RET</th><th scope=col>CFACPR</th><th scope=col>RETX</th><th scope=col>sprtrn</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>12490                           </td><td>19990104                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>183.0000                        </td><td>-0.007458                       </td><td>2                               </td><td>-0.007458                       </td><td>-0.000919                       </td></tr>\n",
       "\t<tr><td>12490                           </td><td>19990105                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>189.6250                        </td><td> 0.036202                       </td><td>2                               </td><td> 0.036202                       </td><td> 0.013582                       </td></tr>\n",
       "\t<tr><td>12490                           </td><td>19990106                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>188.7500                        </td><td>-0.004614                       </td><td>2                               </td><td>-0.004614                       </td><td> 0.022140                       </td></tr>\n",
       "\t<tr><td>12490                           </td><td>19990107                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>190.1875                        </td><td> 0.007616                       </td><td>2                               </td><td> 0.007616                       </td><td>-0.002051                       </td></tr>\n",
       "\t<tr><td>12490                           </td><td>19990108                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>187.5625                        </td><td>-0.013802                       </td><td>2                               </td><td>-0.013802                       </td><td> 0.004221                       </td></tr>\n",
       "\t<tr><td>12490                           </td><td>19990111                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>189.2500                        </td><td> 0.008997                       </td><td>2                               </td><td> 0.008997                       </td><td>-0.008792                       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " PERMNO & date & TICKER & COMNAM & PERMCO & PRC & RET & CFACPR & RETX & sprtrn\\\\\n",
       "\\hline\n",
       "\t 12490                            & 19990104                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 183.0000                         & -0.007458                        & 2                                & -0.007458                        & -0.000919                       \\\\\n",
       "\t 12490                            & 19990105                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 189.6250                         &  0.036202                        & 2                                &  0.036202                        &  0.013582                       \\\\\n",
       "\t 12490                            & 19990106                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 188.7500                         & -0.004614                        & 2                                & -0.004614                        &  0.022140                       \\\\\n",
       "\t 12490                            & 19990107                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 190.1875                         &  0.007616                        & 2                                &  0.007616                        & -0.002051                       \\\\\n",
       "\t 12490                            & 19990108                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 187.5625                         & -0.013802                        & 2                                & -0.013802                        &  0.004221                       \\\\\n",
       "\t 12490                            & 19990111                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 189.2500                         &  0.008997                        & 2                                &  0.008997                        & -0.008792                       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| PERMNO | date | TICKER | COMNAM | PERMCO | PRC | RET | CFACPR | RETX | sprtrn |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 12490                            | 19990104                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 183.0000                         | -0.007458                        | 2                                | -0.007458                        | -0.000919                        |\n",
       "| 12490                            | 19990105                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 189.6250                         |  0.036202                        | 2                                |  0.036202                        |  0.013582                        |\n",
       "| 12490                            | 19990106                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 188.7500                         | -0.004614                        | 2                                | -0.004614                        |  0.022140                        |\n",
       "| 12490                            | 19990107                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 190.1875                         |  0.007616                        | 2                                |  0.007616                        | -0.002051                        |\n",
       "| 12490                            | 19990108                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 187.5625                         | -0.013802                        | 2                                | -0.013802                        |  0.004221                        |\n",
       "| 12490                            | 19990111                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 189.2500                         |  0.008997                        | 2                                |  0.008997                        | -0.008792                        |\n",
       "\n"
      ],
      "text/plain": [
       "  PERMNO date     TICKER COMNAM                           PERMCO PRC     \n",
       "1 12490  19990104 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  183.0000\n",
       "2 12490  19990105 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  189.6250\n",
       "3 12490  19990106 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  188.7500\n",
       "4 12490  19990107 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  190.1875\n",
       "5 12490  19990108 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  187.5625\n",
       "6 12490  19990111 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  189.2500\n",
       "  RET       CFACPR RETX      sprtrn   \n",
       "1 -0.007458 2      -0.007458 -0.000919\n",
       "2  0.036202 2       0.036202  0.013582\n",
       "3 -0.004614 2      -0.004614  0.022140\n",
       "4  0.007616 2       0.007616 -0.002051\n",
       "5 -0.013802 2      -0.013802  0.004221\n",
       "6  0.008997 2       0.008997 -0.008792"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>PERMNO</th><th scope=col>date</th><th scope=col>TICKER</th><th scope=col>COMNAM</th><th scope=col>PERMCO</th><th scope=col>PRC</th><th scope=col>RET</th><th scope=col>CFACPR</th><th scope=col>RETX</th><th scope=col>sprtrn</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1251</th><td>12490                           </td><td>20031223                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>92.79                           </td><td>-0.006425                       </td><td>1                               </td><td>-0.006425                       </td><td> 0.002818                       </td></tr>\n",
       "\t<tr><th scope=row>1252</th><td>12490                           </td><td>20031224                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>92.27                           </td><td>-0.005604                       </td><td>1                               </td><td>-0.005604                       </td><td>-0.001807                       </td></tr>\n",
       "\t<tr><th scope=row>1253</th><td>12490                           </td><td>20031226                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>92.90                           </td><td> 0.006828                       </td><td>1                               </td><td> 0.006828                       </td><td> 0.001691                       </td></tr>\n",
       "\t<tr><th scope=row>1254</th><td>12490                           </td><td>20031229                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>93.52                           </td><td> 0.006674                       </td><td>1                               </td><td> 0.006674                       </td><td> 0.012401                       </td></tr>\n",
       "\t<tr><th scope=row>1255</th><td>12490                           </td><td>20031230                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>92.63                           </td><td>-0.009517                       </td><td>1                               </td><td>-0.009517                       </td><td> 0.000144                       </td></tr>\n",
       "\t<tr><th scope=row>1256</th><td>12490                           </td><td>20031231                        </td><td>IBM                             </td><td>INTERNATIONAL BUSINESS MACHS COR</td><td>20990                           </td><td>92.68                           </td><td> 0.000540                       </td><td>1                               </td><td> 0.000540                       </td><td> 0.002055                       </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       "  & PERMNO & date & TICKER & COMNAM & PERMCO & PRC & RET & CFACPR & RETX & sprtrn\\\\\n",
       "\\hline\n",
       "\t1251 & 12490                            & 20031223                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 92.79                            & -0.006425                        & 1                                & -0.006425                        &  0.002818                       \\\\\n",
       "\t1252 & 12490                            & 20031224                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 92.27                            & -0.005604                        & 1                                & -0.005604                        & -0.001807                       \\\\\n",
       "\t1253 & 12490                            & 20031226                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 92.90                            &  0.006828                        & 1                                &  0.006828                        &  0.001691                       \\\\\n",
       "\t1254 & 12490                            & 20031229                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 93.52                            &  0.006674                        & 1                                &  0.006674                        &  0.012401                       \\\\\n",
       "\t1255 & 12490                            & 20031230                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 92.63                            & -0.009517                        & 1                                & -0.009517                        &  0.000144                       \\\\\n",
       "\t1256 & 12490                            & 20031231                         & IBM                              & INTERNATIONAL BUSINESS MACHS COR & 20990                            & 92.68                            &  0.000540                        & 1                                &  0.000540                        &  0.002055                       \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | PERMNO | date | TICKER | COMNAM | PERMCO | PRC | RET | CFACPR | RETX | sprtrn |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1251 | 12490                            | 20031223                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 92.79                            | -0.006425                        | 1                                | -0.006425                        |  0.002818                        |\n",
       "| 1252 | 12490                            | 20031224                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 92.27                            | -0.005604                        | 1                                | -0.005604                        | -0.001807                        |\n",
       "| 1253 | 12490                            | 20031226                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 92.90                            |  0.006828                        | 1                                |  0.006828                        |  0.001691                        |\n",
       "| 1254 | 12490                            | 20031229                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 93.52                            |  0.006674                        | 1                                |  0.006674                        |  0.012401                        |\n",
       "| 1255 | 12490                            | 20031230                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 92.63                            | -0.009517                        | 1                                | -0.009517                        |  0.000144                        |\n",
       "| 1256 | 12490                            | 20031231                         | IBM                              | INTERNATIONAL BUSINESS MACHS COR | 20990                            | 92.68                            |  0.000540                        | 1                                |  0.000540                        |  0.002055                        |\n",
       "\n"
      ],
      "text/plain": [
       "     PERMNO date     TICKER COMNAM                           PERMCO PRC  \n",
       "1251 12490  20031223 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  92.79\n",
       "1252 12490  20031224 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  92.27\n",
       "1253 12490  20031226 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  92.90\n",
       "1254 12490  20031229 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  93.52\n",
       "1255 12490  20031230 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  92.63\n",
       "1256 12490  20031231 IBM    INTERNATIONAL BUSINESS MACHS COR 20990  92.68\n",
       "     RET       CFACPR RETX      sprtrn   \n",
       "1251 -0.006425 1      -0.006425  0.002818\n",
       "1252 -0.005604 1      -0.005604 -0.001807\n",
       "1253  0.006828 1       0.006828  0.001691\n",
       "1254  0.006674 1       0.006674  0.012401\n",
       "1255 -0.009517 1      -0.009517  0.000144\n",
       "1256  0.000540 1       0.000540  0.002055"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "index <- as.Date(as.character(ibm$date), \"%Y%m%d\")\n",
    "ret <- zoo(ibm$RET, as.Date(as.character(ibm$date), \"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\ngEgA2ABEAsAGIBIANgCRALCB/wcvBvqTk8fUyQAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for ugarchspec-methods {rugarch}\"><tr><td>ugarchspec-methods {rugarch}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>function: Univariate GARCH Specification</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>Method for creating a univariate GARCH specification object prior to fitting.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "ugarchspec(variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1), \n",
       "submodel = NULL, external.regressors = NULL, variance.targeting = FALSE), \n",
       "mean.model = list(armaOrder = c(1, 1), include.mean = TRUE, archm = FALSE, \n",
       "archpow = 1, arfima = FALSE, external.regressors = NULL, archex = FALSE), \n",
       "distribution.model = \"norm\", start.pars = list(), fixed.pars = list(), ...)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>variance.model</code></td>\n",
       "<td>\n",
       "\n",
       "<p>List containing the variance model specification:<br />\n",
       "<code>model</code> Valid models (currently implemented) are &ldquo;sGARCH&rdquo;, \n",
       "&ldquo;fGARCH&rdquo;, &ldquo;eGARCH&rdquo;, &ldquo;gjrGARCH&rdquo;, &ldquo;apARCH&rdquo; and\n",
       "&ldquo;iGARCH&rdquo; and &ldquo;csGARCH&rdquo;.<br />\n",
       "<code>garchOrder</code> The ARCH (q) and GARCH (p) orders.<br />\n",
       "<code>submodel</code> If the model is &ldquo;fGARCH&rdquo;, valid submodels are \n",
       "&ldquo;GARCH&rdquo;, &ldquo;TGARCH&rdquo;, &ldquo;AVGARCH&rdquo;, &ldquo;NGARCH&rdquo;, \n",
       "&ldquo;NAGARCH&rdquo;, &ldquo;APARCH&rdquo;,&ldquo;GJRGARCH&rdquo; and &ldquo;ALLGARCH&rdquo;.<br />\n",
       "<code>external.regressors</code> A matrix object containing the external regressors to \n",
       "include in the variance equation with as many rows as will be included in the\n",
       "data (which is passed in the fit function).\n",
       "<code>variance.targeting</code> (Logical or Numeric) If logical, indicates whether to use \n",
       "variance targeting for the conditional variance intercept &ldquo;omega&rdquo;, else\n",
       "if numeric, the value provided is used instead of the unconditional variance for \n",
       "the calculation of the intercept (in combination with the persistence value). \n",
       "Care should be taken if using the numeric option for apARCH and fGARCH models \n",
       "since the intercept is not the variance but sigma raised to the power of some \n",
       "positive value. Finally, if scaling is used (from the fit.control option \n",
       "in <code>ugarchfit</code>), the value provided is adjusted accordingly by the\n",
       "routine.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>mean.model</code></td>\n",
       "<td>\n",
       "\n",
       "<p>List containing the mean model specification:<br />\n",
       "<code>armaOrder</code> The autoregressive (ar) and moving average (ma) orders (if any).<br />\n",
       "<code>include.mean</code> Whether to include the mean.<br />\n",
       "<code>archm</code> Whether to include ARCH volatility in the mean regression.<br />\n",
       "<code>archpow</code> Indicates whether to use st.deviation (1) or variance (2) in the \n",
       "ARCH in mean regression.<br />\n",
       "<code>arfima</code> Whether to fractional differencing in the ARMA regression.<br />\n",
       "<code>external.regressors</code> A matrix object containing the external regressors to \n",
       "include in the mean equation with as many rows as will be included in the data \n",
       "(which is passed in the fit function).<br />\n",
       "<code>archex</code> (integer) Whether to multiply the last 'archex' external regressors\n",
       "by the conditional standard deviation.\n",
       "</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>distribution.model</code></td>\n",
       "<td>\n",
       "\n",
       "<p>The conditional density to use for the innovations. Valid choices are \n",
       "&ldquo;norm&rdquo; for the normal distibution, &ldquo;snorm&rdquo; for the skew-normal \n",
       "distribution, &ldquo;std&rdquo; for the student-t, &ldquo;sstd&rdquo; for the skew-student, \n",
       "&ldquo;ged&rdquo; for the generalized error distribution, &ldquo;sged&rdquo; for the \n",
       "skew-generalized error distribution, &ldquo;nig&rdquo; for the normal inverse \n",
       "gaussian distribution, &ldquo;ghyp&rdquo; for the Generalized  Hyperbolic, and &ldquo;jsu&rdquo; \n",
       "for Johnson's SU distribution. Note that some of the distributions are taken \n",
       "from the fBasics package and implenented locally here for convenience. \n",
       "The &ldquo;jsu&rdquo; distribution is the reparametrized version from the \n",
       "&ldquo;gamlss&rdquo; package.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>start.pars</code></td>\n",
       "<td>\n",
       "\n",
       "<p>List of staring parameters for the optimization routine. These are not usually \n",
       "required unless the optimization has problems converging.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>fixed.pars</code></td>\n",
       "<td>\n",
       "\n",
       "<p>List of parameters which are to be kept fixed during the optimization. It is \n",
       "possible that you designate all parameters as fixed so as to quickly recover \n",
       "just the results of some previous work or published work. The optional argument\n",
       "&ldquo;fixed.se&rdquo; in the <code>ugarchfit</code> function indicates whether to\n",
       "calculate standard errors for those parameters fixed during the post \n",
       "optimization stage.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p> . </p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>The specification allows for a wide choice in univariate GARCH models, \n",
       "distributions, and mean equation modelling. For the &ldquo;fGARCH&rdquo; model, \n",
       "this represents Hentschel's omnibus model which subsumes many others.<br />\n",
       "For the mean equation, ARFIMAX is fully supported in fitting, forecasting and \n",
       "simulation. There is also an option to multiply the external regressors by\n",
       "the conditional standard deviation, which may be of use for example in \n",
       "calculating the  correlation coefficient in a CAPM type setting.<br />\n",
       "The &ldquo;iGARCH&rdquo; implements the integrated GARCH model. For the &ldquo;EWMA&rdquo; \n",
       "model just set &ldquo;omega&rdquo; to zero in the fixed parameters list.<br />\n",
       "The asymmetry term in the rugarch package, for all implemented models, follows \n",
       "the order of the arch parameter <code>alpha</code>.<br />\n",
       "Variance targeting, referred to in Engle and Mezrich (1996), replaces the \n",
       "intercept &ldquo;omega&rdquo; in the variance equation by 1 minus the persistence \n",
       "multiplied by the unconditional variance which is calculated by its sample \n",
       "counterpart in the squared residuals during estimation. In the presence of \n",
       "external regressors in the variance equation, the sample average of the external \n",
       "regresssors is multiplied by their coefficient and subtracted from the \n",
       "variance target.<br />\n",
       "In order to understand which parameters can be entered in the start.pars and \n",
       "fixed.pars optional arguments, the list below exposes the names used for the\n",
       "parameters across the various models:(note that when a parameter is followed by \n",
       "a number, this represents the order of the model. Just increment the number \n",
       "for higher orders, with the exception of the component sGARCH permanent \n",
       "component parameters which are fixed to have a lag-1 autoregressive structure.):<br />\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p><em><b>Mean Model</b></em><br />\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p> constant: <code>mu</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> AR term:\t<code>ar1</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> MA term:\t<code>ma1</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> ARCH-in-mean: <code>archm</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> exogenous regressors: <code>mxreg1</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> arfima: <code>arfima</code><br />\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "</li>\n",
       "<li> <p><em><b>Distribution Model</b></em><br />\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p> skew:     <code>skew</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> shape:    <code>shape</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> ghlambda: <code>lambda (for GHYP distribution)</code><br />  \n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "</li>\n",
       "<li> <p><em><b>Variance Model (common specs)</b></em><br />\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p> constant:   <code>omega</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> ARCH term:  <code>alpha1</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> GARCH term: <code>beta1</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> exogenous regressors: <code>vxreg1</code><br />\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "</li>\n",
       "<li> <p><em><b>Variance Model (GJR, EGARCH)</b></em><br />\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p> assymetry term: <code>gamma1</code><br />\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "</li>\n",
       "<li> <p><em><b>Variance Model (APARCH)</b></em><br />\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p> assymetry term: <code>gamma1</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> power term: <code>delta</code><br />\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "</li>\n",
       "<li> <p><em><b>Variance Model (FGARCH)</b></em><br />\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p> assymetry term1 (rotation): <code>eta11</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> assymetry term2 (shift): <code>eta21</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> power term1(shock): <code>delta</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> power term2(variance): <code>lambda</code><br />\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "</li>\n",
       "<li> <p><em><b>Variance Model (csGARCH)</b></em><br />\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li><p> permanent component autoregressive term (rho): <code>eta11</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> permanent component shock term (phi): <code>eta21</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> permanent component intercept:   <code>omega</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> transitory component ARCH term:  <code>alpha1</code><br />\n",
       "</p>\n",
       "</li>\n",
       "<li><p> transitory component GARCH term: <code>beta1</code><br />\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "</li></ul>\n",
       "\n",
       "<p>The terms defined above are better explained in the vignette which provides each model's specification\n",
       "and exact representation. For instance, in the eGARCH model, both alpha and gamma jointly determine the\n",
       "assymetry, and relate to the magnitude and sign of the standardized innovations.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>A <code>uGARCHspec</code> object containing details of the GARCH \n",
       "specification.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "<p>Alexios Ghalanos</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "# a standard specification\n",
       "spec1 = ugarchspec()\n",
       "spec1\n",
       "# an example which keep the ar1 and ma1 coefficients fixed:\n",
       "spec2 = ugarchspec(mean.model=list(armaOrder=c(2,2), \n",
       "fixed.pars=list(ar1=0.3,ma1=0.3)))\n",
       "spec2\n",
       "# an example of the EWMA Model\n",
       "spec3 = ugarchspec(variance.model=list(model=\"iGARCH\", garchOrder=c(1,1)), \n",
       "\t\tmean.model=list(armaOrder=c(0,0), include.mean=TRUE),  \n",
       "\t\tdistribution.model=\"norm\", fixed.pars=list(omega=0))\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>rugarch</em> version 1.4-1 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{ugarchspec-methods}{function: Univariate GARCH Specification}{ugarchspec.Rdash.methods}\n",
       "\\aliasA{ugarchspec}{ugarchspec-methods}{ugarchspec}\n",
       "\\aliasA{ugarchspec,ANY-method}{ugarchspec-methods}{ugarchspec,ANY.Rdash.method}\n",
       "\\keyword{methods}{ugarchspec-methods}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "Method for creating a univariate GARCH specification object prior to fitting.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "ugarchspec(variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1), \n",
       "submodel = NULL, external.regressors = NULL, variance.targeting = FALSE), \n",
       "mean.model = list(armaOrder = c(1, 1), include.mean = TRUE, archm = FALSE, \n",
       "archpow = 1, arfima = FALSE, external.regressors = NULL, archex = FALSE), \n",
       "distribution.model = \"norm\", start.pars = list(), fixed.pars = list(), ...)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{variance.model}] \n",
       "List containing the variance model specification:\\\\{}\n",
       "\\code{model} Valid models (currently implemented) are ``sGARCH'', \n",
       "``fGARCH'', ``eGARCH'', ``gjrGARCH'', ``apARCH'' and\n",
       "``iGARCH'' and ``csGARCH''.\\\\{}\n",
       "\\code{garchOrder} The ARCH (q) and GARCH (p) orders.\\\\{}\n",
       "\\code{submodel} If the model is ``fGARCH'', valid submodels are \n",
       "``GARCH'', ``TGARCH'', ``AVGARCH'', ``NGARCH'', \n",
       "``NAGARCH'', ``APARCH'',``GJRGARCH'' and ``ALLGARCH''.\\\\{}\n",
       "\\code{external.regressors} A matrix object containing the external regressors to \n",
       "include in the variance equation with as many rows as will be included in the\n",
       "data (which is passed in the fit function).\n",
       "\\code{variance.targeting} (Logical or Numeric) If logical, indicates whether to use \n",
       "variance targeting for the conditional variance intercept ``omega'', else\n",
       "if numeric, the value provided is used instead of the unconditional variance for \n",
       "the calculation of the intercept (in combination with the persistence value). \n",
       "Care should be taken if using the numeric option for apARCH and fGARCH models \n",
       "since the intercept is not the variance but sigma raised to the power of some \n",
       "positive value. Finally, if scaling is used (from the fit.control option \n",
       "in \\code{\\LinkA{ugarchfit}{ugarchfit}}), the value provided is adjusted accordingly by the\n",
       "routine.\n",
       "\n",
       "\\item[\\code{mean.model}] \n",
       "List containing the mean model specification:\\\\{}\n",
       "\\code{armaOrder} The autoregressive (ar) and moving average (ma) orders (if any).\\\\{}\n",
       "\\code{include.mean} Whether to include the mean.\\\\{}\n",
       "\\code{archm} Whether to include ARCH volatility in the mean regression.\\\\{}\n",
       "\\code{archpow} Indicates whether to use st.deviation (1) or variance (2) in the \n",
       "ARCH in mean regression.\\\\{}\n",
       "\\code{arfima} Whether to fractional differencing in the ARMA regression.\\\\{}\n",
       "\\code{external.regressors} A matrix object containing the external regressors to \n",
       "include in the mean equation with as many rows as will be included in the data \n",
       "(which is passed in the fit function).\\\\{}\n",
       "\\code{archex} (integer) Whether to multiply the last 'archex' external regressors\n",
       "by the conditional standard deviation.\n",
       "\n",
       "\\item[\\code{distribution.model}] \n",
       "The conditional density to use for the innovations. Valid choices are \n",
       "``norm'' for the normal distibution, ``snorm'' for the skew-normal \n",
       "distribution, ``std'' for the student-t, ``sstd'' for the skew-student, \n",
       "``ged'' for the generalized error distribution, ``sged'' for the \n",
       "skew-generalized error distribution, ``nig'' for the normal inverse \n",
       "gaussian distribution, ``ghyp'' for the Generalized  Hyperbolic, and ``jsu'' \n",
       "for Johnson's SU distribution. Note that some of the distributions are taken \n",
       "from the fBasics package and implenented locally here for convenience. \n",
       "The ``jsu'' distribution is the reparametrized version from the \n",
       "``gamlss'' package.\n",
       "\\item[\\code{start.pars}] \n",
       "List of staring parameters for the optimization routine. These are not usually \n",
       "required unless the optimization has problems converging.\n",
       "\\item[\\code{fixed.pars}] \n",
       "List of parameters which are to be kept fixed during the optimization. It is \n",
       "possible that you designate all parameters as fixed so as to quickly recover \n",
       "just the results of some previous work or published work. The optional argument\n",
       "``fixed.se'' in the \\code{\\LinkA{ugarchfit}{ugarchfit}} function indicates whether to\n",
       "calculate standard errors for those parameters fixed during the post \n",
       "optimization stage.\n",
       "\\item[\\code{...}]  . \n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "The specification allows for a wide choice in univariate GARCH models, \n",
       "distributions, and mean equation modelling. For the ``fGARCH'' model, \n",
       "this represents Hentschel's omnibus model which subsumes many others.\\\\{}\n",
       "For the mean equation, ARFIMAX is fully supported in fitting, forecasting and \n",
       "simulation. There is also an option to multiply the external regressors by\n",
       "the conditional standard deviation, which may be of use for example in \n",
       "calculating the  correlation coefficient in a CAPM type setting.\\\\{}\n",
       "The ``iGARCH'' implements the integrated GARCH model. For the ``EWMA'' \n",
       "model just set ``omega'' to zero in the fixed parameters list.\\\\{}\n",
       "The asymmetry term in the rugarch package, for all implemented models, follows \n",
       "the order of the arch parameter \\code{alpha}.\\\\{}\n",
       "Variance targeting, referred to in Engle and Mezrich (1996), replaces the \n",
       "intercept ``omega'' in the variance equation by 1 minus the persistence \n",
       "multiplied by the unconditional variance which is calculated by its sample \n",
       "counterpart in the squared residuals during estimation. In the presence of \n",
       "external regressors in the variance equation, the sample average of the external \n",
       "regresssors is multiplied by their coefficient and subtracted from the \n",
       "variance target.\\\\{}\n",
       "In order to understand which parameters can be entered in the start.pars and \n",
       "fixed.pars optional arguments, the list below exposes the names used for the\n",
       "parameters across the various models:(note that when a parameter is followed by \n",
       "a number, this represents the order of the model. Just increment the number \n",
       "for higher orders, with the exception of the component sGARCH permanent \n",
       "component parameters which are fixed to have a lag-1 autoregressive structure.):\\\\{}\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\emph{\\bold{Mean Model}}\\\\{}\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item constant: \\code{mu}\\\\{}\n",
       "\\item AR term:\t\\code{ar1}\\\\{}\n",
       "\\item MA term:\t\\code{ma1}\\\\{}\n",
       "\\item ARCH-in-mean: \\code{archm}\\\\{}\n",
       "\\item exogenous regressors: \\code{mxreg1}\\\\{}\n",
       "\\item arfima: \\code{arfima}\\\\{}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\item \\emph{\\bold{Distribution Model}}\\\\{}\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item skew:     \\code{skew}\\\\{}\n",
       "\\item shape:    \\code{shape}\\\\{}\n",
       "\\item ghlambda: \\code{lambda (for GHYP distribution)}\\\\{}  \n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\item \\emph{\\bold{Variance Model (common specs)}}\\\\{}\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item constant:   \\code{omega}\\\\{}\n",
       "\\item ARCH term:  \\code{alpha1}\\\\{}\n",
       "\\item GARCH term: \\code{beta1}\\\\{}\n",
       "\\item exogenous regressors: \\code{vxreg1}\\\\{}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\item \\emph{\\bold{Variance Model (GJR, EGARCH)}}\\\\{}\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item assymetry term: \\code{gamma1}\\\\{}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\item \\emph{\\bold{Variance Model (APARCH)}}\\\\{}\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item assymetry term: \\code{gamma1}\\\\{}\n",
       "\\item power term: \\code{delta}\\\\{}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\item \\emph{\\bold{Variance Model (FGARCH)}}\\\\{}\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item assymetry term1 (rotation): \\code{eta11}\\\\{}\n",
       "\\item assymetry term2 (shift): \\code{eta21}\\\\{}\n",
       "\\item power term1(shock): \\code{delta}\\\\{}\n",
       "\\item power term2(variance): \\code{lambda}\\\\{}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\item \\emph{\\bold{Variance Model (csGARCH)}}\\\\{}\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item permanent component autoregressive term (rho): \\code{eta11}\\\\{}\n",
       "\\item permanent component shock term (phi): \\code{eta21}\\\\{}\n",
       "\\item permanent component intercept:   \\code{omega}\\\\{}\n",
       "\\item transitory component ARCH term:  \\code{alpha1}\\\\{}\n",
       "\\item transitory component GARCH term: \\code{beta1}\\\\{}\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "The terms defined above are better explained in the vignette which provides each model's specification\n",
       "and exact representation. For instance, in the eGARCH model, both alpha and gamma jointly determine the\n",
       "assymetry, and relate to the magnitude and sign of the standardized innovations.\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "A \\code{\\LinkA{uGARCHspec}{uGARCHspec.Rdash.class}} object containing details of the GARCH \n",
       "specification.\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "Alexios Ghalanos\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "# a standard specification\n",
       "spec1 = ugarchspec()\n",
       "spec1\n",
       "# an example which keep the ar1 and ma1 coefficients fixed:\n",
       "spec2 = ugarchspec(mean.model=list(armaOrder=c(2,2), \n",
       "fixed.pars=list(ar1=0.3,ma1=0.3)))\n",
       "spec2\n",
       "# an example of the EWMA Model\n",
       "spec3 = ugarchspec(variance.model=list(model=\"iGARCH\", garchOrder=c(1,1)), \n",
       "\t\tmean.model=list(armaOrder=c(0,0), include.mean=TRUE),  \n",
       "\t\tdistribution.model=\"norm\", fixed.pars=list(omega=0))\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "ugarchspec-methods           package:rugarch           R Documentation\n",
       "\n",
       "_\bf_\bu_\bn_\bc_\bt_\bi_\bo_\bn: _\bU_\bn_\bi_\bv_\ba_\br_\bi_\ba_\bt_\be _\bG_\bA_\bR_\bC_\bH _\bS_\bp_\be_\bc_\bi_\bf_\bi_\bc_\ba_\bt_\bi_\bo_\bn\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Method for creating a univariate GARCH specification object prior\n",
       "     to fitting.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     ugarchspec(variance.model = list(model = \"sGARCH\", garchOrder = c(1, 1), \n",
       "     submodel = NULL, external.regressors = NULL, variance.targeting = FALSE), \n",
       "     mean.model = list(armaOrder = c(1, 1), include.mean = TRUE, archm = FALSE, \n",
       "     archpow = 1, arfima = FALSE, external.regressors = NULL, archex = FALSE), \n",
       "     distribution.model = \"norm\", start.pars = list(), fixed.pars = list(), ...)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "variance.model: List containing the variance model specification:\n",
       "          model Valid models (currently implemented) are sGARCH,\n",
       "          fGARCH, eGARCH, gjrGARCH, apARCH and iGARCH and\n",
       "          csGARCH.\n",
       "          garchOrder The ARCH (q) and GARCH (p) orders.\n",
       "          submodel If the model is fGARCH, valid submodels are\n",
       "          GARCH, TGARCH, AVGARCH, NGARCH, NAGARCH,\n",
       "          APARCH,GJRGARCH and ALLGARCH.\n",
       "          external.regressors A matrix object containing the external\n",
       "          regressors to include in the variance equation with as many\n",
       "          rows as will be included in the data (which is passed in the\n",
       "          fit function). variance.targeting (Logical or Numeric) If\n",
       "          logical, indicates whether to use variance targeting for the\n",
       "          conditional variance intercept omega, else if numeric, the\n",
       "          value provided is used instead of the unconditional variance\n",
       "          for the calculation of the intercept (in combination with the\n",
       "          persistence value).  Care should be taken if using the\n",
       "          numeric option for apARCH and fGARCH models since the\n",
       "          intercept is not the variance but sigma raised to the power\n",
       "          of some positive value. Finally, if scaling is used (from the\n",
       "          fit.control option in ugarchfit), the value provided is\n",
       "          adjusted accordingly by the routine.\n",
       "\n",
       "mean.model: List containing the mean model specification:\n",
       "          armaOrder The autoregressive (ar) and moving average (ma)\n",
       "          orders (if any).\n",
       "          include.mean Whether to include the mean.\n",
       "          archm Whether to include ARCH volatility in the mean\n",
       "          regression.\n",
       "          archpow Indicates whether to use st.deviation (1) or\n",
       "          variance (2) in the ARCH in mean regression.\n",
       "          arfima Whether to fractional differencing in the ARMA\n",
       "          regression.\n",
       "          external.regressors A matrix object containing the external\n",
       "          regressors to include in the mean equation with as many rows\n",
       "          as will be included in the data (which is passed in the fit\n",
       "          function).\n",
       "          archex (integer) Whether to multiply the last 'archex'\n",
       "          external regressors by the conditional standard deviation.\n",
       "\n",
       "distribution.model: The conditional density to use for the innovations.\n",
       "          Valid choices are norm for the normal distibution, snorm\n",
       "          for the skew-normal distribution, std for the student-t,\n",
       "          sstd for the skew-student, ged for the generalized error\n",
       "          distribution, sged for the skew-generalized error\n",
       "          distribution, nig for the normal inverse gaussian\n",
       "          distribution, ghyp for the Generalized Hyperbolic, and\n",
       "          jsu for Johnson's SU distribution. Note that some of the\n",
       "          distributions are taken from the fBasics package and\n",
       "          implenented locally here for convenience.  The jsu\n",
       "          distribution is the reparametrized version from the gamlss\n",
       "          package.\n",
       "\n",
       "start.pars: List of staring parameters for the optimization routine.\n",
       "          These are not usually required unless the optimization has\n",
       "          problems converging.\n",
       "\n",
       "fixed.pars: List of parameters which are to be kept fixed during the\n",
       "          optimization. It is possible that you designate all\n",
       "          parameters as fixed so as to quickly recover just the results\n",
       "          of some previous work or published work. The optional\n",
       "          argument fixed.se in the ugarchfit function indicates\n",
       "          whether to calculate standard errors for those parameters\n",
       "          fixed during the post optimization stage.\n",
       "\n",
       "     ...: .\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The specification allows for a wide choice in univariate GARCH\n",
       "     models, distributions, and mean equation modelling. For the\n",
       "     fGARCH model, this represents Hentschel's omnibus model which\n",
       "     subsumes many others.\n",
       "     For the mean equation, ARFIMAX is fully supported in fitting,\n",
       "     forecasting and simulation. There is also an option to multiply\n",
       "     the external regressors by the conditional standard deviation,\n",
       "     which may be of use for example in calculating the correlation\n",
       "     coefficient in a CAPM type setting.\n",
       "     The iGARCH implements the integrated GARCH model. For the EWMA\n",
       "     model just set omega to zero in the fixed parameters list.\n",
       "     The asymmetry term in the rugarch package, for all implemented\n",
       "     models, follows the order of the arch parameter alpha.\n",
       "     Variance targeting, referred to in Engle and Mezrich (1996),\n",
       "     replaces the intercept omega in the variance equation by 1 minus\n",
       "     the persistence multiplied by the unconditional variance which is\n",
       "     calculated by its sample counterpart in the squared residuals\n",
       "     during estimation. In the presence of external regressors in the\n",
       "     variance equation, the sample average of the external regresssors\n",
       "     is multiplied by their coefficient and subtracted from the\n",
       "     variance target.\n",
       "     In order to understand which parameters can be entered in the\n",
       "     start.pars and fixed.pars optional arguments, the list below\n",
       "     exposes the names used for the parameters across the various\n",
       "     models:(note that when a parameter is followed by a number, this\n",
       "     represents the order of the model. Just increment the number for\n",
       "     higher orders, with the exception of the component sGARCH\n",
       "     permanent component parameters which are fixed to have a lag-1\n",
       "     autoregressive structure.):\n",
       "\n",
       "         _*Mean Model*_\n",
       "\n",
       "             constant: mu\n",
       "\n",
       "             AR term: ar1\n",
       "\n",
       "             MA term: ma1\n",
       "\n",
       "             ARCH-in-mean: archm\n",
       "\n",
       "             exogenous regressors: mxreg1\n",
       "\n",
       "             arfima: arfima\n",
       "\n",
       "         _*Distribution Model*_\n",
       "\n",
       "             skew: skew\n",
       "\n",
       "             shape: shape\n",
       "\n",
       "             ghlambda: lambda (for GHYP distribution)\n",
       "\n",
       "         _*Variance Model (common specs)*_\n",
       "\n",
       "             constant: omega\n",
       "\n",
       "             ARCH term: alpha1\n",
       "\n",
       "             GARCH term: beta1\n",
       "\n",
       "             exogenous regressors: vxreg1\n",
       "\n",
       "         _*Variance Model (GJR, EGARCH)*_\n",
       "\n",
       "             assymetry term: gamma1\n",
       "\n",
       "         _*Variance Model (APARCH)*_\n",
       "\n",
       "             assymetry term: gamma1\n",
       "\n",
       "             power term: delta\n",
       "\n",
       "         _*Variance Model (FGARCH)*_\n",
       "\n",
       "             assymetry term1 (rotation): eta11\n",
       "\n",
       "             assymetry term2 (shift): eta21\n",
       "\n",
       "             power term1(shock): delta\n",
       "\n",
       "             power term2(variance): lambda\n",
       "\n",
       "         _*Variance Model (csGARCH)*_\n",
       "\n",
       "             permanent component autoregressive term (rho): eta11\n",
       "\n",
       "             permanent component shock term (phi): eta21\n",
       "\n",
       "             permanent component intercept: omega\n",
       "\n",
       "             transitory component ARCH term: alpha1\n",
       "\n",
       "             transitory component GARCH term: beta1\n",
       "\n",
       "     The terms defined above are better explained in the vignette which\n",
       "     provides each model's specification and exact representation. For\n",
       "     instance, in the eGARCH model, both alpha and gamma jointly\n",
       "     determine the assymetry, and relate to the magnitude and sign of\n",
       "     the standardized innovations.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A uGARCHspec object containing details of the GARCH\n",
       "     specification.\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     Alexios Ghalanos\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     # a standard specification\n",
       "     spec1 = ugarchspec()\n",
       "     spec1\n",
       "     # an example which keep the ar1 and ma1 coefficients fixed:\n",
       "     spec2 = ugarchspec(mean.model=list(armaOrder=c(2,2), \n",
       "     fixed.pars=list(ar1=0.3,ma1=0.3)))\n",
       "     spec2\n",
       "     # an example of the EWMA Model\n",
       "     spec3 = ugarchspec(variance.model=list(model=\"iGARCH\", garchOrder=c(1,1)), \n",
       "                     mean.model=list(armaOrder=c(0,0), include.mean=TRUE),  \n",
       "                     distribution.model=\"norm\", fixed.pars=list(omega=0))\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "help(ugarchspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec <- ugarchspec(mean.model = list(armaOrder = c(0,0), include.mean=FALSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(ugarchfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data <- zoo\n",
    "fit <- ugarchfit(data = ret, spec = spec, solver=\"hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "*---------------------------------*\n",
       "*          GARCH Model Fit        *\n",
       "*---------------------------------*\n",
       "\n",
       "Conditional Variance Dynamics \t\n",
       "-----------------------------------\n",
       "GARCH Model\t: sGARCH(1,1)\n",
       "Mean Model\t: ARFIMA(0,0,0)\n",
       "Distribution\t: norm \n",
       "\n",
       "Optimal Parameters\n",
       "------------------------------------\n",
       "        Estimate  Std. Error   t value Pr(>|t|)\n",
       "omega   0.000001    0.000002   0.56769  0.57025\n",
       "alpha1  0.042130    0.008328   5.05891  0.00000\n",
       "beta1   0.956870    0.008117 117.88426  0.00000\n",
       "\n",
       "Robust Standard Errors:\n",
       "        Estimate  Std. Error  t value Pr(>|t|)\n",
       "omega   0.000001    0.000011  0.12407  0.90126\n",
       "alpha1  0.042130    0.026578  1.58515  0.11293\n",
       "beta1   0.956870    0.027183 35.20093  0.00000\n",
       "\n",
       "LogLikelihood : 2917.855 \n",
       "\n",
       "Information Criteria\n",
       "------------------------------------\n",
       "                    \n",
       "Akaike       -4.6415\n",
       "Bayes        -4.6292\n",
       "Shibata      -4.6415\n",
       "Hannan-Quinn -4.6369\n",
       "\n",
       "Weighted Ljung-Box Test on Standardized Residuals\n",
       "------------------------------------\n",
       "                        statistic p-value\n",
       "Lag[1]                      1.766  0.1839\n",
       "Lag[2*(p+q)+(p+q)-1][2]     1.778  0.3025\n",
       "Lag[4*(p+q)+(p+q)-1][5]     4.471  0.2009\n",
       "d.o.f=0\n",
       "H0 : No serial correlation\n",
       "\n",
       "Weighted Ljung-Box Test on Standardized Squared Residuals\n",
       "------------------------------------\n",
       "                        statistic p-value\n",
       "Lag[1]                    0.01249  0.9110\n",
       "Lag[2*(p+q)+(p+q)-1][5]   0.67249  0.9281\n",
       "Lag[4*(p+q)+(p+q)-1][9]   1.50526  0.9551\n",
       "d.o.f=2\n",
       "\n",
       "Weighted ARCH LM Tests\n",
       "------------------------------------\n",
       "            Statistic Shape Scale P-Value\n",
       "ARCH Lag[3]   0.07453 0.500 2.000  0.7849\n",
       "ARCH Lag[5]   1.33126 1.440 1.667  0.6378\n",
       "ARCH Lag[7]   1.81006 2.315 1.543  0.7574\n",
       "\n",
       "Nyblom stability test\n",
       "------------------------------------\n",
       "Joint Statistic:  7.721\n",
       "Individual Statistics:             \n",
       "omega  0.2667\n",
       "alpha1 0.2725\n",
       "beta1  0.3853\n",
       "\n",
       "Asymptotic Critical Values (10% 5% 1%)\n",
       "Joint Statistic:     \t 0.846 1.01 1.35\n",
       "Individual Statistic:\t 0.35 0.47 0.75\n",
       "\n",
       "Sign Bias Test\n",
       "------------------------------------\n",
       "                   t-value   prob sig\n",
       "Sign Bias           0.1204 0.9042    \n",
       "Negative Sign Bias  0.2040 0.8384    \n",
       "Positive Sign Bias  0.3235 0.7464    \n",
       "Joint Effect        0.1898 0.9792    \n",
       "\n",
       "\n",
       "Adjusted Pearson Goodness-of-Fit Test:\n",
       "------------------------------------\n",
       "  group statistic p-value(g-1)\n",
       "1    20     53.04    4.609e-05\n",
       "2    30     70.31    2.753e-05\n",
       "3    40     86.29    1.981e-05\n",
       "4    50     92.09    1.908e-04\n",
       "\n",
       "\n",
       "Elapsed time : 0.08196592 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAADAFBMVEUAAAABAQECAgIDAwME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\noKe3wQAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(sigma(fit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with McDonald Chapter 24\n",
    "\n",
    "![](./images/McDonald-IBM-GARCH.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals <- coef(fit)\n",
    "w.hat <- coef(fit)[1]\n",
    "a.hat <- coef(fit)[2]\n",
    "b.hat <- coef(fit)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>omega:</strong> 1.39783931036735e-06"
      ],
      "text/latex": [
       "\\textbf{omega:} 1.39783931036735e-06"
      ],
      "text/markdown": [
       "**omega:** 1.39783931036735e-06"
      ],
      "text/plain": [
       "       omega \n",
       "1.397839e-06 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w.hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>alpha1:</strong> 0.0421300940051404"
      ],
      "text/latex": [
       "\\textbf{alpha1:} 0.0421300940051404"
      ],
      "text/markdown": [
       "**alpha1:** 0.0421300940051404"
      ],
      "text/plain": [
       "    alpha1 \n",
       "0.04213009 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>beta1:</strong> 0.956869870286429"
      ],
      "text/latex": [
       "\\textbf{beta1:} 0.956869870286429"
      ],
      "text/markdown": [
       "**beta1:** 0.956869870286429"
      ],
      "text/plain": [
       "    beta1 \n",
       "0.9568699 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "b.hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999-04-22 \n",
       "  0.131636 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret[76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999-04-22 1999-10-21 2000-07-20 2000-10-18 2001-01-18 \n",
       "  0.131636  -0.149533   0.130435  -0.155420   0.120233 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind <- (abs(ret) >= 0.12)\n",
    "ret[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    " ii <- 1:length(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>76</li>\n",
       "\t<li>203</li>\n",
       "\t<li>391</li>\n",
       "\t<li>454</li>\n",
       "\t<li>516</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 76\n",
       "\\item 203\n",
       "\\item 391\n",
       "\\item 454\n",
       "\\item 516\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 76\n",
       "2. 203\n",
       "3. 391\n",
       "4. 454\n",
       "5. 516\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  76 203 391 454 516"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c(ii[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec2 <- ugarchspec(variance.model=list(model = \"gjrGARCH\", garchOrder=c(1,1,1)), mean.model=list(armaOrder=c(0,0), include.mean=F))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 <- ugarchfit(data=ret, spec=spec2, solver=\"hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "*---------------------------------*\n",
       "*          GARCH Model Fit        *\n",
       "*---------------------------------*\n",
       "\n",
       "Conditional Variance Dynamics \t\n",
       "-----------------------------------\n",
       "GARCH Model\t: gjrGARCH(1,1)\n",
       "Mean Model\t: ARFIMA(0,0,0)\n",
       "Distribution\t: norm \n",
       "\n",
       "Optimal Parameters\n",
       "------------------------------------\n",
       "        Estimate  Std. Error  t value Pr(>|t|)\n",
       "omega   0.000003    0.000003  0.79813 0.424794\n",
       "alpha1  0.003790    0.005563  0.68119 0.495748\n",
       "beta1   0.952995    0.010954 86.99676 0.000000\n",
       "gamma1  0.084431    0.016816  5.02102 0.000001\n",
       "\n",
       "Robust Standard Errors:\n",
       "        Estimate  Std. Error  t value Pr(>|t|)\n",
       "omega   0.000003    0.000014  0.18586  0.85256\n",
       "alpha1  0.003790    0.012459  0.30416  0.76101\n",
       "beta1   0.952995    0.039385 24.19662  0.00000\n",
       "gamma1  0.084431    0.051710  1.63279  0.10251\n",
       "\n",
       "LogLikelihood : 2944.735 \n",
       "\n",
       "Information Criteria\n",
       "------------------------------------\n",
       "                    \n",
       "Akaike       -4.6827\n",
       "Bayes        -4.6663\n",
       "Shibata      -4.6827\n",
       "Hannan-Quinn -4.6766\n",
       "\n",
       "Weighted Ljung-Box Test on Standardized Residuals\n",
       "------------------------------------\n",
       "                        statistic p-value\n",
       "Lag[1]                      1.283  0.2574\n",
       "Lag[2*(p+q)+(p+q)-1][2]     1.596  0.3395\n",
       "Lag[4*(p+q)+(p+q)-1][5]     3.864  0.2715\n",
       "d.o.f=0\n",
       "H0 : No serial correlation\n",
       "\n",
       "Weighted Ljung-Box Test on Standardized Squared Residuals\n",
       "------------------------------------\n",
       "                        statistic p-value\n",
       "Lag[1]                    0.09315  0.7602\n",
       "Lag[2*(p+q)+(p+q)-1][5]   1.47439  0.7462\n",
       "Lag[4*(p+q)+(p+q)-1][9]   2.83436  0.7860\n",
       "d.o.f=2\n",
       "\n",
       "Weighted ARCH LM Tests\n",
       "------------------------------------\n",
       "            Statistic Shape Scale P-Value\n",
       "ARCH Lag[3]     1.150 0.500 2.000  0.2835\n",
       "ARCH Lag[5]     2.642 1.440 1.667  0.3460\n",
       "ARCH Lag[7]     3.168 2.315 1.543  0.4825\n",
       "\n",
       "Nyblom stability test\n",
       "------------------------------------\n",
       "Joint Statistic:  4.6317\n",
       "Individual Statistics:             \n",
       "omega  0.3393\n",
       "alpha1 0.7642\n",
       "beta1  0.7844\n",
       "gamma1 0.6561\n",
       "\n",
       "Asymptotic Critical Values (10% 5% 1%)\n",
       "Joint Statistic:     \t 1.07 1.24 1.6\n",
       "Individual Statistic:\t 0.35 0.47 0.75\n",
       "\n",
       "Sign Bias Test\n",
       "------------------------------------\n",
       "                   t-value   prob sig\n",
       "Sign Bias          0.20715 0.8359    \n",
       "Negative Sign Bias 0.30853 0.7577    \n",
       "Positive Sign Bias 0.04102 0.9673    \n",
       "Joint Effect       0.40646 0.9389    \n",
       "\n",
       "\n",
       "Adjusted Pearson Goodness-of-Fit Test:\n",
       "------------------------------------\n",
       "  group statistic p-value(g-1)\n",
       "1    20     33.17      0.02296\n",
       "2    30     47.90      0.01505\n",
       "3    40     56.55      0.03424\n",
       "4    50     68.84      0.03222\n",
       "\n",
       "\n",
       "Elapsed time : 0.2421682 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data(dem2gbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y <- dem2gbp$DEM2GBP[1:750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec1 <- ugarchspec(mean.model=list(armaOrder=c(0,0), include.mean=F), distribution=\"norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit1 <- ugarchfit(data=y, spec=spec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>omega</dt>\n",
       "\t\t<dd>0.0472423904127151</dd>\n",
       "\t<dt>alpha1</dt>\n",
       "\t\t<dd>0.220805636030745</dd>\n",
       "\t<dt>beta1</dt>\n",
       "\t\t<dd>0.637570063240716</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[omega] 0.0472423904127151\n",
       "\\item[alpha1] 0.220805636030745\n",
       "\\item[beta1] 0.637570063240716\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "omega\n",
       ":   0.0472423904127151alpha1\n",
       ":   0.220805636030745beta1\n",
       ":   0.637570063240716\n",
       "\n"
      ],
      "text/plain": [
       "     omega     alpha1      beta1 \n",
       "0.04724239 0.22080564 0.63757006 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef(fit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec2 <- ugarchspec(mean.model=list(armaOrder=c(0,0), include.mean=F), distribution=\"std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit2 <- ugarchfit(data=y, spec=spec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>omega</dt>\n",
       "\t\t<dd>0.0342231293336863</dd>\n",
       "\t<dt>alpha1</dt>\n",
       "\t\t<dd>0.238849983775989</dd>\n",
       "\t<dt>beta1</dt>\n",
       "\t\t<dd>0.684938703717931</dd>\n",
       "\t<dt>shape</dt>\n",
       "\t\t<dd>5.32761286696864</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[omega] 0.0342231293336863\n",
       "\\item[alpha1] 0.238849983775989\n",
       "\\item[beta1] 0.684938703717931\n",
       "\\item[shape] 5.32761286696864\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "omega\n",
       ":   0.0342231293336863alpha1\n",
       ":   0.238849983775989beta1\n",
       ":   0.684938703717931shape\n",
       ":   5.32761286696864\n",
       "\n"
      ],
      "text/plain": [
       "     omega     alpha1      beta1      shape \n",
       "0.03422313 0.23884998 0.68493870 5.32761287 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef(fit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian GARCH Modelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for bayesGARCH {bayesGARCH}\"><tr><td>bayesGARCH {bayesGARCH}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Bayesian Estimation of the GARCH(1,1) Model with Student-t Innovations</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "\n",
       "<p>Performs the Bayesian estimation of the GARCH(1,1) model with\n",
       "Student-t innovations.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "  bayesGARCH(y, mu.alpha = c(0,0), Sigma.alpha = 1000 * diag(1,2), \n",
       "             mu.beta = 0, Sigma.beta = 1000,\n",
       "             lambda = 0.01, delta = 2, control = list())\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>y</code></td>\n",
       "<td>\n",
       "<p>vector of observations of size <i>T</i>. <code>NA</code> values are not allowed.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>mu.alpha</code></td>\n",
       "<td>\n",
       "<p>hyper-parameter <i>mu_alpha</i> (prior mean)\n",
       "for the truncated Normal prior on parameter\n",
       "<i>alpha:=(alpha0\n",
       "      alpha1)'</i>. Default: a <i>2x1</i> vector of zeros.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>Sigma.alpha</code></td>\n",
       "<td>\n",
       "<p>hyper-parameter <i>Sigma_alpha</i>\n",
       "(prior covariance matrix) for\n",
       "the truncated Normal prior on parameter\n",
       "<i>alpha</i>. Default: a <i>2x2</i> diagonal matrix whose\n",
       "variances are set to 1'000, i.e., a diffuse prior. Note that the matrix\n",
       "must be symmetric positive definite.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>mu.beta</code></td>\n",
       "<td>\n",
       "<p>hyper-parameter <i>mu_beta</i> (prior mean) for the truncated Normal prior on\n",
       "parameter <i>beta</i>. Default: zero.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>Sigma.beta</code></td>\n",
       "<td>\n",
       "<p>hyper-parameter <i>Sigma_beta&gt;0</i> (prior variance) for the truncated\n",
       "Normal prior on parameter <i>beta</i>. Default: 1'000, i.e.,\n",
       "a diffuse prior.</p>\n",
       "</td></tr> \n",
       "<tr valign=\"top\"><td><code>lambda</code></td>\n",
       "<td>\n",
       "<p>hyper-parameter <i>lambda&gt;0</i> for the translated\n",
       "Exponential distribution on parameter <i>nu</i>. Default: 0.01.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>delta</code></td>\n",
       "<td>\n",
       "<p>hyper-parameter <i>delta&gt;=2</i> for the translated\n",
       "Exponential distribution on parameter <i>nu</i>. Default: 2 (to\n",
       "ensure the existence of the conditional variance).</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>control</code></td>\n",
       "<td>\n",
       "<p>list of control parameters (See *Details*).</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "\n",
       "<p>The function <code>bayesGARCH</code> performs the Bayesian estimation of the\n",
       "GARCH(1,1) model with Student-t innovations. The underlying algorithm is based on Nakatsuma\n",
       "(1998, 2000) for generating the parameters of the GARCH(1,1) scedastic\n",
       "function <i>alpha:=(alpha0 alpha1)'</i> and <i>beta</i> and on\n",
       "Geweke (1993) and Deschamps (2006) for the generating the degrees of freedom\n",
       "parameter <i>nu</i>. Further details and examples can be found in Ardia (2008) and \n",
       "Ardia and Hoogerheide (2010). See also the package vignette by typing <code>vignette(\"bayesGARCH\")</code>. Finally, we refer to \n",
       "Ardia (2009) for an extension of the algorithm to Markov-switching GARCH models.\n",
       "</p>\n",
       "<p>The <code>control</code> argument is a list that can supply any of\n",
       "the following components:\n",
       "</p>\n",
       "\n",
       "<dl>\n",
       "<dt><code>n.chain</code></dt><dd><p>number of MCMC chain(s) to be\n",
       "generated. Default: <code>n.chain=1</code>.</p>\n",
       "</dd>\n",
       "<dt><code>l.chain</code></dt><dd><p>length of each MCMC chain. Default: <code>l.chain=10000</code>.</p>\n",
       "</dd>    \n",
       "<dt><code>start.val</code></dt><dd><p>vector of starting values of\n",
       "chain(s). Default: <code>start.val=c(0.01,0.1,0.7,20)</code>. A matrix of\n",
       "size <i>nx4</i>\n",
       "containing starting values in rows can also be provided. This will generate <i>n</i> chains starting at the\n",
       "different row values.</p>\n",
       "</dd>\n",
       "<dt><code>addPriorConditions</code></dt><dd><p>function which allows the user to add constraints on the model parameters. \n",
       "Default: <code>NULL</code>, i.e. not additional constraints are imposed (see below).</p>\n",
       "</dd>\n",
       "<dt><code>refresh</code></dt><dd><p>frequency of reports. Default: <code>refresh=10</code> iterations.</p>\n",
       "</dd>\n",
       "<dt><code>digits</code></dt><dd><p>number of printed digits in the\n",
       "reports. Default: <code>digits=4</code>.</p>\n",
       "</dd>\n",
       "</dl>\n",
       "\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "\n",
       "<p>A list of class <code>mcmc.list</code> (<span style=\"font-family: Courier New, Courier; color: #666666;\"><b>R</b></span> package <span class=\"pkg\">coda</span>).\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Note</h3>\n",
       "\n",
       "\n",
       "<p>The GARCH(1,1) model with Student-t innovations may be written as follows:\n",
       "</p>\n",
       "<p style=\"text-align: center;\"><i>\n",
       "    y(t) = e(t)*(varrho * h(t))^(1/2)  \n",
       "  </i></p>\n",
       "\n",
       "<p>for <i>t=1,...,T</i>, where the conditional variance equation is defined as:\n",
       "</p>\n",
       "<p style=\"text-align: center;\"><i>\n",
       "    h(t) := alpha0 + alpha1 * y(t-1)^2 + beta * h(t-1)\n",
       "  </i></p>\n",
       "\n",
       "<p>where <i>alpha0&gt;0,alpha1,beta&gt;=0</i> to ensure a\n",
       "positive conditional variance. We set the initial variance to\n",
       "<i>h(0):=0</i> for convenience. The parameter <i>varrho:=(nu-2)/nu</i> is a scaling factor which ensures\n",
       "the conditional variance of <i>y(t)</i> to be\n",
       "<i>h(t)</i>. Finally, <i>e(t)</i>\n",
       "follows a Student-t distribution with <i>nu</i> degrees of freedom.\n",
       "</p>\n",
       "<p>The prior distributions on <i>alpha</i> is a bivariate truncated\n",
       "Normal distribution:\n",
       "</p>\n",
       "<p style=\"text-align: center;\"><i>\n",
       "    p(alpha) prop N2(alpha | mu_alpha, Sigma_alpha) I[alpha&gt;0]\n",
       "  </i></p>\n",
       "\n",
       "<p>where <i>mu_alpha</i> is the prior mean vector, <i>Sigma_alpha</i> is\n",
       "the prior covariance matrix and <i>I[alpha&gt;0]</i> is the indicator function.\n",
       "</p>\n",
       "<p>The prior distribution on <i>beta</i> is a univariate truncated Normal\n",
       "distribution:\n",
       "</p>\n",
       "<p style=\"text-align: center;\"><i>\n",
       "    p(theta) prop N(beta | mu_beta, Sigma_beta) I[beta&gt;0]\n",
       "  </i></p>\n",
       "\n",
       "<p>where <i>mu_beta</i> is the prior mean and <i>Sigma_beta</i> is the\n",
       "prior variance.\n",
       "</p>\n",
       "<p>The prior distribution on <i>nu</i> is a translated Exponential\n",
       "distribution:\n",
       "</p>\n",
       "<p style=\"text-align: center;\"><i>\n",
       "    p(nu) = lambda * exp(-lambda(nu-delta)) I[nu&gt;delta]\n",
       "  </i></p>\n",
       "\n",
       "<p>where <i>lambda&gt;0</i> and <i>delta&gt;=2</i>. The prior mean for\n",
       "<i>nu</i> is <i>delta + 1/lambda</i>.\n",
       "</p>\n",
       "<p>The joint prior on parameter <i>psi:=(alpha,beta,nu)</i> is obtained by assuming prior independence:\n",
       "</p>\n",
       "<p style=\"text-align: center;\"><i>\n",
       "    p(psi) = p(alpha) * p(beta) * p(nu).\n",
       "  </i></p>\n",
       "\n",
       "<p>The default hyperparameters <i>mu_alpha</i>, <i>Sigma_alpha</i>,\n",
       "<i>mu_beta</i>, <i>Sigma_beta</i> and <i>lambda</i> define a rather\n",
       "vague prior. The hyper-parameter <i>delta&gt;=2</i> ensures the\n",
       "existence of the conditional variance. The <i>k</i>th conditional\n",
       "moment for <i>e(t)</i> is guaranteed by setting <i>delta&gt;=k</i>.\n",
       "</p>\n",
       "<p>The Bayesian estimation of the GARCH(1,1) model with Normal\n",
       "innovations is obtained as a special case by setting <code>lambda=100</code>\n",
       "and <code>delta=500</code>. In this case, the generated values for\n",
       "<i>nu</i> are centered around 500 which ensure approximate Normality\n",
       "for the innovations. \n",
       "</p>\n",
       "<p>The function <code>addPriorConditions</code> allows to add prior conditions on the model\n",
       "parameters <i>psi:=(alpha0 alpha1 beta nu)'</i>. The\n",
       "function must return <code>TRUE</code> if the constraint holds and\n",
       "<code>FALSE</code> otherwise.\n",
       "</p>\n",
       "<p>By default, the function is:\n",
       "</p>\n",
       "<pre>\n",
       "    addPriorConditions &lt;- function(psi)\n",
       "    {\n",
       "      TRUE\n",
       "    }\n",
       "  </pre>\n",
       "<p>and therefore does not add any other constraint than the positivity of\n",
       "the parameters which are obtained through the prior distribution\n",
       "for <i>&psi;</i>. \n",
       "</p>\n",
       "<p>You simply need to modify <code>addPriorConditions</code> in order to add\n",
       "constraints on the model parameters <i>&psi;</i>. For instance, to impose the\n",
       "covariance-stationary conditions to hold,\n",
       "i.e. <i>&alpha;_1 + &beta; &lt; 1</i>, just define\n",
       "the function <code>addPriorConditions</code> as follows:\n",
       "</p>\n",
       "<pre>\n",
       "    addPriorConditions &lt;- function(psi)\n",
       "    {\n",
       "      psi[2] + psi[3] &lt; 1\n",
       "    }\n",
       "  </pre>\n",
       "<p>Note that adding prior constraints on the model parameters\n",
       "can diminish the acceptance rate and therefore\n",
       "lead to a very inefficient sampler. This would however indicate that the\n",
       "condition is not supported by the data.\n",
       "</p>\n",
       "<p>The estimation strategy implemented in <code>bayesGARCH</code> is fully automatic and does not require \n",
       "any tuning of the MCMC sampler. The generation of the Markov chains is however time\n",
       "consuming and estimating the model over several datasets on a daily basis can therefore take a significant amount\n",
       "of time. In this case, the algorithm can be easily parallelized, by running a single chain on several processors.\n",
       "Also, when the estimation is repeated over updated time series (i.e. time series with more recent \n",
       "observations), it is wise to start the algorithm using the posterior mean or median of the parameters \n",
       "obtained at the previous estimation step. The impact of the starting values (burn-in phase) is likely to be \n",
       "smaller and thus the convergence faster.\n",
       "</p>\n",
       "<p>Finally, note that as any MH algorithm, the sampler can get stuck to a given value, so that the chain does not move\n",
       "anymore. However, the sampler uses Taylor-made candidate densities that are especially &lsquo;constructed&rsquo; at each step,\n",
       "so it is almost impossible for this MCMC sampler to get stuck at a given value for many subsequent draws.\n",
       "In the unlikely case that such ill behavior would occur, one could scale the data (to have standard deviation 1),\n",
       "or run the algorithm with different initial values or a different random seed.\n",
       "</p>\n",
       "<p>Please cite the package in publications. Use <code>citation(\"bayesGARCH\")</code>.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Author(s)</h3>\n",
       "\n",
       "\n",
       "<p>David Ardia <a href=\"mailto:david.ardia.ch@gmail.com\">david.ardia.ch@gmail.com</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>References</h3>\n",
       "\n",
       "\n",
       "<p>Ardia, D. (2009)\n",
       "Bayesian Estimation of a Markov-Switching Threshold Asymmetric GARCH Model with Student-t Innovations.\n",
       "<em>Econometrics Journal</em> <b>12</b>(1), pp. 105-126. \n",
       "<a href=\"http://doi.org/10.1111/j.1368-423X.2008.00253.x\">doi: 10.1111/j.1368-423X.2008.00253.x</a>\n",
       "</p>\n",
       "<p>Ardia, D., Hoogerheide, L.F. (2010)\n",
       "Bayesian Estimation of the GARCH(1,1) Model with Student-t Innovations.\n",
       "<em>The R Journal</em> <b>2</b>(2), pp.41-47. \n",
       "<a href=\"https://journal.r-project.org/archive/2010-2/\">https://journal.r-project.org/archive/2010-2/</a>\n",
       "</p>\n",
       "<p>Ardia, D. (2008) \n",
       "Financial Risk Management with Bayesian Estimation of GARCH Models. \n",
       "Lecture Notes in Economics and Mathematical Systems <b>612</b>. Springer-Verlag, Berlin, Germany.\n",
       "ISBN 978-3-540-78656-6, e-ISBN 978-3-540-78657-3, \n",
       "<a href=\"http://doi.org/10.1007/978-3-540-78657-3\">doi: 10.1007/978-3-540-78657-3</a>\n",
       "<a href=\"http://www.springer.com/de/book/9783540786566\">http://www.springer.com/de/book/9783540786566</a>\n",
       "</p>\n",
       "<p>Deschamps, P.J. (2006) \n",
       "A Flexible Prior Distribution for Markov Switching Autoregressions with Student-t Errors. \n",
       "<em>Journal of Econometrics</em> <b>133</b>, pp.153-190.\n",
       "<a href=\"http://doi.org/10.1016/j.jeconom.2005.03.012\">doi: 10.1016/j.jeconom.2005.03.012</a>\n",
       "</p>\n",
       "<p>Geweke, J.F. (1993)\n",
       "Bayesian Treatment of the Independent Student-t Linear Model. \n",
       "<em>Journal of Applied Econometrics</em> <b>8</b>, pp.19-40.\n",
       "<a href=\"http://doi.org/10.1002/jae.3950080504\">doi: 10.1002/jae.3950080504</a>\n",
       "</p>\n",
       "<p>Nakatsuma, T. (2000)\n",
       "Bayesian Analysis of ARMA-GARCH Models: A Markov Chain Sampling Approach. \n",
       "<em>Journal of Econometrics</em> <b>95</b>(1), pp.57-69.\n",
       "<a href=\"http://doi.org/10.1016/S0304-4076(99)00029-9\">doi: 10.1016/S0304-4076(99)00029-9</a>\n",
       "</p>\n",
       "<p>Nakatsuma, T. (1998)\n",
       "A Markov-Chain Sampling Algorithm for GARCH Models. \n",
       "<em>Studies in Nonlinear Dynamics and Econometrics</em> <b>3</b>(2), pp.107-117.\n",
       "<a href=\"http://doi.org/10.2202/1558-3708.1043\">doi: 10.2202/1558-3708.1043</a>\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "\n",
       "<p><code>garchFit</code> (<span style=\"font-family: Courier New, Courier; color: #666666;\"><b>R</b></span> package <span class=\"pkg\">fGarch</span>) for the classical\n",
       "Maximum Likelihood estimation of GARCH models.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "  ## !!! INCREASE THE NUMBER OF MCMC ITERATIONS !!!\n",
       "\n",
       "  ## LOAD DATA\n",
       "  data(dem2gbp)\n",
       "  y &lt;- dem2gbp[1:750]\n",
       "\n",
       "  ## RUN THE SAMPLER (2 chains)\n",
       "  MCMC &lt;- bayesGARCH(y, control = list(n.chain = 2, l.chain = 200))\n",
       "\n",
       "  ## MCMC ANALYSIS (using coda)\n",
       "  plot(MCMC)\n",
       "  \n",
       "  ## FORM THE POSTERIOR SAMPLE\n",
       "  smpl &lt;- formSmpl(MCMC, l.bi = 50)\n",
       "\n",
       "  ## POSTERIOR STATISTICS\n",
       "  summary(smpl)\n",
       "  smpl &lt;- as.matrix(smpl)\n",
       "  pairs(smpl)\n",
       "\n",
       "  ## GARCH(1,1) WITH NORMAL INNOVATIONS\n",
       "  MCMC &lt;- bayesGARCH(y, lambda = 100, delta = 500,\n",
       "                     control = list(n.chain = 2, l.chain = 200))\n",
       "\n",
       "  ## GARCH(1,1) WITH NORMAL INNOVATIONS AND \n",
       "  ## WITH COVARIANCE STATIONARITY CONDITION\n",
       "  addPriorConditions &lt;- function(psi){psi[2] + psi[3] &lt; 1}\n",
       "  MCMC &lt;- bayesGARCH(y, lambda = 100, delta = 500,\n",
       "                     control = list(n.chain = 2, l.chain = 200, \n",
       "                     addPriorConditions = addPriorConditions))\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>bayesGARCH</em> version 2.1.3 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{bayesGARCH}{Bayesian Estimation of the GARCH(1,1) Model with Student-t Innovations}{bayesGARCH}\n",
       "\\keyword{models}{bayesGARCH}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "\n",
       "Performs the Bayesian estimation of the GARCH(1,1) model with\n",
       "Student-t innovations.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "\n",
       "  bayesGARCH(y, mu.alpha = c(0,0), Sigma.alpha = 1000 * diag(1,2), \n",
       "             mu.beta = 0, Sigma.beta = 1000,\n",
       "             lambda = 0.01, delta = 2, control = list())\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\n",
       "\\item[\\code{y}] vector of observations of size \\eqn{T}{}. \\code{NA} values are not allowed.\n",
       "\\item[\\code{mu.alpha}] hyper-parameter \\eqn{\\mu_\\alpha}{} (prior mean)\n",
       "for the truncated Normal prior on parameter\n",
       "\\eqn{\\alpha := (\\alpha_0 \\ \\alpha_1)'}{}. Default: a \\eqn{2 \\times 1}{} vector of zeros.\n",
       "\\item[\\code{Sigma.alpha}] hyper-parameter \\eqn{\\Sigma_\\alpha}{}\n",
       "(prior covariance matrix) for\n",
       "the truncated Normal prior on parameter\n",
       "\\eqn{\\alpha}{}. Default: a \\eqn{2 \\times 2}{} diagonal matrix whose\n",
       "variances are set to 1'000, i.e., a diffuse prior. Note that the matrix\n",
       "must be symmetric positive definite.\n",
       "\\item[\\code{mu.beta}] hyper-parameter \\eqn{\\mu_\\beta}{} (prior mean) for the truncated Normal prior on\n",
       "parameter \\eqn{\\beta}{}. Default: zero.\n",
       "\\item[\\code{Sigma.beta}] hyper-parameter \\eqn{\\Sigma_\\beta > 0}{} (prior variance) for the truncated\n",
       "Normal prior on parameter \\eqn{\\beta}{}. Default: 1'000, i.e.,\n",
       "a diffuse prior.\n",
       "\\item[\\code{lambda}] hyper-parameter \\eqn{\\lambda > 0}{} for the translated\n",
       "Exponential distribution on parameter \\eqn{\\nu}{}. Default: 0.01.\n",
       "\\item[\\code{delta}] hyper-parameter \\eqn{\\delta \\ge 2}{} for the translated\n",
       "Exponential distribution on parameter \\eqn{\\nu}{}. Default: 2 (to\n",
       "ensure the existence of the conditional variance).\n",
       "\\item[\\code{control}] list of control parameters (See *Details*).\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "\n",
       "The function \\code{bayesGARCH} performs the Bayesian estimation of the\n",
       "GARCH(1,1) model with Student-t innovations. The underlying algorithm is based on Nakatsuma\n",
       "(1998, 2000) for generating the parameters of the GARCH(1,1) scedastic\n",
       "function \\eqn{\\alpha := (\\alpha_0 \\ \\alpha_1)'}{} and \\eqn{\\beta}{} and on\n",
       "Geweke (1993) and Deschamps (2006) for the generating the degrees of freedom\n",
       "parameter \\eqn{\\nu}{}. Further details and examples can be found in Ardia (2008) and \n",
       "Ardia and Hoogerheide (2010). See also the package vignette by typing \\code{vignette(\"bayesGARCH\")}. Finally, we refer to \n",
       "Ardia (2009) for an extension of the algorithm to Markov-switching GARCH models.\n",
       "\n",
       "The \\code{control} argument is a list that can supply any of\n",
       "the following components:\n",
       "\n",
       "\\begin{description}\n",
       "\n",
       "\\item[\\code{n.chain}] number of MCMC chain(s) to be\n",
       "generated. Default: \\code{n.chain=1}.\n",
       "\\item[\\code{l.chain}] length of each MCMC chain. Default: \\code{l.chain=10000}.   \n",
       "\\item[\\code{start.val}] vector of starting values of\n",
       "chain(s). Default: \\code{start.val=c(0.01,0.1,0.7,20)}. A matrix of\n",
       "size \\eqn{n \\times 4}{}\n",
       "containing starting values in rows can also be provided. This will generate \\eqn{n}{} chains starting at the\n",
       "different row values.\n",
       "\\item[\\code{addPriorConditions}] function which allows the user to add constraints on the model parameters. \n",
       "Default: \\code{NULL}, i.e. not additional constraints are imposed (see below).\n",
       "\\item[\\code{refresh}] frequency of reports. Default: \\code{refresh=10} iterations.\n",
       "\\item[\\code{digits}] number of printed digits in the\n",
       "reports. Default: \\code{digits=4}.\n",
       "\n",
       "\\end{description}\n",
       "\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "\n",
       "A list of class \\code{mcmc.list} (\\R{} package \\pkg{coda}).\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{Note}\\relax\n",
       "\n",
       "The GARCH(1,1) model with Student-t innovations may be written as follows:\n",
       "\\deqn{\n",
       "    y_t = \\epsilon_t (\\varrho h_t)^{1/2}\n",
       "  }{}\n",
       "for \\eqn{t=1,\\ldots,T}{}, where the conditional variance equation is defined as:\n",
       "\\deqn{\n",
       "    h_t := \\alpha_0 + \\alpha_1 y_{t-1}^2 + \\beta h_{t-1}\n",
       "  }{}\n",
       "where \\eqn{\\alpha_0 > 0, \\alpha_1 \\ge 0, \\beta \\ge 0}{} to ensure a\n",
       "positive conditional variance. We set the initial variance to\n",
       "\\eqn{h_0 := 0}{} for convenience. The parameter \\eqn{\\varrho :=\n",
       "    (\\nu-2)/\\nu}{} is a scaling factor which ensures\n",
       "the conditional variance of \\eqn{y_t}{} to be\n",
       "\\eqn{h_t}{}. Finally, \\eqn{\\epsilon_t}{}\n",
       "follows a Student-t distribution with \\eqn{\\nu}{} degrees of freedom.\n",
       "\n",
       "The prior distributions on \\eqn{\\alpha}{} is a bivariate truncated\n",
       "Normal distribution:\n",
       "\\deqn{\n",
       "    p(\\alpha) \\propto N_2(\\alpha \\mid \\mu_\\alpha, \\Sigma_\\alpha)\n",
       "    I_{[\\alpha > 0]}\n",
       "  }{}\n",
       "where \\eqn{\\mu_\\alpha}{} is the prior mean vector, \\eqn{\\Sigma_\\alpha}{} is\n",
       "the prior covariance matrix and \\eqn{I_{[\\bullet]}}{} is the indicator function.\n",
       "\n",
       "The prior distribution on \\eqn{\\beta}{} is a univariate truncated Normal\n",
       "distribution:\n",
       "\\deqn{\n",
       "    p(\\beta) \\propto N(\\beta \\mid \\mu_\\beta, \\Sigma_\\beta) I_{[\\beta > 0]}\n",
       "  }{}\n",
       "where \\eqn{\\mu_\\beta}{} is the prior mean and \\eqn{\\Sigma_\\beta}{} is the\n",
       "prior variance.\n",
       "\n",
       "The prior distribution on \\eqn{\\nu}{} is a translated Exponential\n",
       "distribution:\n",
       "\\deqn{\n",
       "    p(\\nu) = \\lambda \\exp [ - \\lambda (\\nu - \\delta) ] I_{[\\nu > \\delta]}\n",
       "  }{}\n",
       "where \\eqn{\\lambda > 0}{} and \\eqn{\\delta \\ge 2}{}. The prior mean for\n",
       "\\eqn{\\nu}{} is \\eqn{\\delta + 1/\\lambda}{}.\n",
       "\n",
       "The joint prior on parameter \\eqn{\\psi := (\\alpha,\n",
       "    \\beta, \\nu)}{} is obtained by assuming prior independence:\n",
       "\\deqn{\n",
       "    p(\\psi) = p(\\alpha) p(\\beta) p(\\nu).\n",
       "  }{}\n",
       "\n",
       "The default hyperparameters \\eqn{\\mu_\\alpha}{}, \\eqn{\\Sigma_\\alpha}{},\n",
       "\\eqn{\\mu_\\beta}{}, \\eqn{\\Sigma_\\beta}{} and \\eqn{\\lambda}{} define a rather\n",
       "vague prior. The hyper-parameter \\eqn{\\delta \\geq 2}{} ensures the\n",
       "existence of the conditional variance. The \\eqn{k}{}th conditional\n",
       "moment for \\eqn{\\epsilon_t}{} is guaranteed by setting \\eqn{\\delta \\geq k}{}.\n",
       "\n",
       "The Bayesian estimation of the GARCH(1,1) model with Normal\n",
       "innovations is obtained as a special case by setting \\code{lambda=100}\n",
       "and \\code{delta=500}. In this case, the generated values for\n",
       "\\eqn{\\nu}{} are centered around 500 which ensure approximate Normality\n",
       "for the innovations. \n",
       "\n",
       "The function \\code{addPriorConditions} allows to add prior conditions on the model\n",
       "parameters \\eqn{\\psi := (\\alpha_0 \\ \\alpha_1 \\ \\beta \\\n",
       "    \\nu)'}{}. The\n",
       "function must return \\code{TRUE} if the constraint holds and\n",
       "\\code{FALSE} otherwise.\n",
       "\n",
       "By default, the function is:\n",
       "\\begin{alltt}\n",
       "    addPriorConditions <- function(psi)\n",
       "    \\{\n",
       "      TRUE\n",
       "    \\}\n",
       "  \\end{alltt}\n",
       "\n",
       "and therefore does not add any other constraint than the positivity of\n",
       "the parameters which are obtained through the prior distribution\n",
       "for \\eqn{\\psi}{}. \n",
       "\n",
       "You simply need to modify \\code{addPriorConditions} in order to add\n",
       "constraints on the model parameters \\eqn{\\psi}{}. For instance, to impose the\n",
       "covariance-stationary conditions to hold,\n",
       "i.e. \\eqn{\\alpha_1 + \\beta < 1}{}, just define\n",
       "the function \\code{addPriorConditions} as follows:\n",
       "\\begin{alltt}\n",
       "    addPriorConditions <- function(psi)\n",
       "    \\{\n",
       "      psi[2] + psi[3] < 1\n",
       "    \\}\n",
       "  \\end{alltt}\n",
       "\n",
       "\n",
       "Note that adding prior constraints on the model parameters\n",
       "can diminish the acceptance rate and therefore\n",
       "lead to a very inefficient sampler. This would however indicate that the\n",
       "condition is not supported by the data.\n",
       "\n",
       "The estimation strategy implemented in \\code{bayesGARCH} is fully automatic and does not require \n",
       "any tuning of the MCMC sampler. The generation of the Markov chains is however time\n",
       "consuming and estimating the model over several datasets on a daily basis can therefore take a significant amount\n",
       "of time. In this case, the algorithm can be easily parallelized, by running a single chain on several processors.\n",
       "Also, when the estimation is repeated over updated time series (i.e. time series with more recent \n",
       "observations), it is wise to start the algorithm using the posterior mean or median of the parameters \n",
       "obtained at the previous estimation step. The impact of the starting values (burn-in phase) is likely to be \n",
       "smaller and thus the convergence faster.\n",
       "\n",
       "Finally, note that as any MH algorithm, the sampler can get stuck to a given value, so that the chain does not move\n",
       "anymore. However, the sampler uses Taylor-made candidate densities that are especially `constructed' at each step,\n",
       "so it is almost impossible for this MCMC sampler to get stuck at a given value for many subsequent draws.\n",
       "In the unlikely case that such ill behavior would occur, one could scale the data (to have standard deviation 1),\n",
       "or run the algorithm with different initial values or a different random seed.\n",
       "\n",
       "Please cite the package in publications. Use \\code{citation(\"bayesGARCH\")}.\n",
       "\\end{Note}\n",
       "%\n",
       "\\begin{Author}\\relax\n",
       "\n",
       "David Ardia \\email{david.ardia.ch@gmail.com}\n",
       "\\end{Author}\n",
       "%\n",
       "\\begin{References}\\relax\n",
       "\n",
       "Ardia, D. (2009)\n",
       "Bayesian Estimation of a Markov-Switching Threshold Asymmetric GARCH Model with Student-t Innovations.\n",
       "\\emph{Econometrics Journal} \\bold{12}(1), pp. 105-126. \n",
       "\\Rhref{http://doi.org/10.1111/j.1368-423X.2008.00253.x}{doi:~10.1111/j.1368-423X.2008.00253.x}\n",
       "\n",
       "Ardia, D., Hoogerheide, L.F. (2010)\n",
       "Bayesian Estimation of the GARCH(1,1) Model with Student-t Innovations.\n",
       "\\emph{The R Journal} \\bold{2}(2), pp.41-47. \n",
       "\\url{https://journal.r-project.org/archive/2010-2/}\n",
       "\n",
       "Ardia, D. (2008) \n",
       "Financial Risk Management with Bayesian Estimation of GARCH Models. \n",
       "Lecture Notes in Economics and Mathematical Systems \\bold{612}. Springer-Verlag, Berlin, Germany.\n",
       "ISBN 978-3-540-78656-6, e-ISBN 978-3-540-78657-3, \n",
       "\\Rhref{http://doi.org/10.1007/978-3-540-78657-3}{doi:~10.1007/978-3-540-78657-3}\n",
       "\\url{http://www.springer.com/de/book/9783540786566}\n",
       "\n",
       "Deschamps, P.J. (2006) \n",
       "A Flexible Prior Distribution for Markov Switching Autoregressions with Student-t Errors. \n",
       "\\emph{Journal of Econometrics} \\bold{133}, pp.153-190.\n",
       "\\Rhref{http://doi.org/10.1016/j.jeconom.2005.03.012}{doi:~10.1016/j.jeconom.2005.03.012}\n",
       "\n",
       "Geweke, J.F. (1993)\n",
       "Bayesian Treatment of the Independent Student-t Linear Model. \n",
       "\\emph{Journal of Applied Econometrics} \\bold{8}, pp.19-40.\n",
       "\\Rhref{http://doi.org/10.1002/jae.3950080504}{doi:~10.1002/jae.3950080504}\n",
       "\n",
       "Nakatsuma, T. (2000)\n",
       "Bayesian Analysis of ARMA-GARCH Models: A Markov Chain Sampling Approach. \n",
       "\\emph{Journal of Econometrics} \\bold{95}(1), pp.57-69.\n",
       "\\Rhref{http://doi.org/10.1016/S0304-4076(99)00029-9}{doi:~10.1016/S0304-4076(99)00029-9}\n",
       "\n",
       "Nakatsuma, T. (1998)\n",
       "A Markov-Chain Sampling Algorithm for GARCH Models. \n",
       "\\emph{Studies in Nonlinear Dynamics and Econometrics} \\bold{3}(2), pp.107-117.\n",
       "\\Rhref{http://doi.org/10.2202/1558-3708.1043}{doi:~10.2202/1558-3708.1043}\n",
       "\\end{References}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\n",
       "\\code{\\LinkA{garchFit}{garchFit}} (\\R{} package \\pkg{fGarch}) for the classical\n",
       "Maximum Likelihood estimation of GARCH models.\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "\n",
       "  ## !!! INCREASE THE NUMBER OF MCMC ITERATIONS !!!\n",
       "\n",
       "  ## LOAD DATA\n",
       "  data(dem2gbp)\n",
       "  y <- dem2gbp[1:750]\n",
       "\n",
       "  ## RUN THE SAMPLER (2 chains)\n",
       "  MCMC <- bayesGARCH(y, control = list(n.chain = 2, l.chain = 200))\n",
       "\n",
       "  ## MCMC ANALYSIS (using coda)\n",
       "  plot(MCMC)\n",
       "  \n",
       "  ## FORM THE POSTERIOR SAMPLE\n",
       "  smpl <- formSmpl(MCMC, l.bi = 50)\n",
       "\n",
       "  ## POSTERIOR STATISTICS\n",
       "  summary(smpl)\n",
       "  smpl <- as.matrix(smpl)\n",
       "  pairs(smpl)\n",
       "\n",
       "  ## GARCH(1,1) WITH NORMAL INNOVATIONS\n",
       "  MCMC <- bayesGARCH(y, lambda = 100, delta = 500,\n",
       "                     control = list(n.chain = 2, l.chain = 200))\n",
       "\n",
       "  ## GARCH(1,1) WITH NORMAL INNOVATIONS AND \n",
       "  ## WITH COVARIANCE STATIONARITY CONDITION\n",
       "  addPriorConditions <- function(psi){psi[2] + psi[3] < 1}\n",
       "  MCMC <- bayesGARCH(y, lambda = 100, delta = 500,\n",
       "                     control = list(n.chain = 2, l.chain = 200, \n",
       "                     addPriorConditions = addPriorConditions))\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "bayesGARCH             package:bayesGARCH              R Documentation\n",
       "\n",
       "_\bB_\ba_\by_\be_\bs_\bi_\ba_\bn _\bE_\bs_\bt_\bi_\bm_\ba_\bt_\bi_\bo_\bn _\bo_\bf _\bt_\bh_\be _\bG_\bA_\bR_\bC_\bH(_\b1,_\b1) _\bM_\bo_\bd_\be_\bl _\bw_\bi_\bt_\bh _\bS_\bt_\bu_\bd_\be_\bn_\bt-_\bt _\bI_\bn_\bn_\bo_\bv_\ba_\bt_\bi_\bo_\bn_\bs\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     Performs the Bayesian estimation of the GARCH(1,1) model with\n",
       "     Student-t innovations.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "       bayesGARCH(y, mu.alpha = c(0,0), Sigma.alpha = 1000 * diag(1,2), \n",
       "                  mu.beta = 0, Sigma.beta = 1000,\n",
       "                  lambda = 0.01, delta = 2, control = list())\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "       y: vector of observations of size T. NA values are not\n",
       "          allowed.\n",
       "\n",
       "mu.alpha: hyper-parameter mu_alpha (prior mean) for the truncated\n",
       "          Normal prior on parameter alpha:=(alpha0 alpha1)'. Default: a\n",
       "          2x1 vector of zeros.\n",
       "\n",
       "Sigma.alpha: hyper-parameter Sigma_alpha (prior covariance matrix) for\n",
       "          the truncated Normal prior on parameter alpha. Default: a 2x2\n",
       "          diagonal matrix whose variances are set to 1'000, i.e., a\n",
       "          diffuse prior. Note that the matrix must be symmetric\n",
       "          positive definite.\n",
       "\n",
       " mu.beta: hyper-parameter mu_beta (prior mean) for the truncated Normal\n",
       "          prior on parameter beta. Default: zero.\n",
       "\n",
       "Sigma.beta: hyper-parameter Sigma_beta>0 (prior variance) for the\n",
       "          truncated Normal prior on parameter beta. Default: 1'000,\n",
       "          i.e., a diffuse prior.\n",
       "\n",
       "  lambda: hyper-parameter lambda>0 for the translated Exponential\n",
       "          distribution on parameter nu. Default: 0.01.\n",
       "\n",
       "   delta: hyper-parameter delta>=2 for the translated Exponential\n",
       "          distribution on parameter nu. Default: 2 (to ensure the\n",
       "          existence of the conditional variance).\n",
       "\n",
       " control: list of control parameters (See *Details*).\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     The function bayesGARCH performs the Bayesian estimation of the\n",
       "     GARCH(1,1) model with Student-t innovations. The underlying\n",
       "     algorithm is based on Nakatsuma (1998, 2000) for generating the\n",
       "     parameters of the GARCH(1,1) scedastic function alpha:=(alpha0\n",
       "     alpha1)' and beta and on Geweke (1993) and Deschamps (2006) for\n",
       "     the generating the degrees of freedom parameter nu. Further\n",
       "     details and examples can be found in Ardia (2008) and Ardia and\n",
       "     Hoogerheide (2010). See also the package vignette by typing\n",
       "     vignette(\"bayesGARCH\"). Finally, we refer to Ardia (2009) for an\n",
       "     extension of the algorithm to Markov-switching GARCH models.\n",
       "\n",
       "     The control argument is a list that can supply any of the\n",
       "     following components:\n",
       "\n",
       "     n.chain number of MCMC chain(s) to be generated. Default:\n",
       "          n.chain=1.\n",
       "\n",
       "     l.chain length of each MCMC chain. Default: l.chain=10000.\n",
       "\n",
       "     start.val vector of starting values of chain(s). Default:\n",
       "          start.val=c(0.01,0.1,0.7,20). A matrix of size nx4\n",
       "          containing starting values in rows can also be provided. This\n",
       "          will generate n chains starting at the different row values.\n",
       "\n",
       "     addPriorConditions function which allows the user to add\n",
       "          constraints on the model parameters.  Default: NULL, i.e.\n",
       "          not additional constraints are imposed (see below).\n",
       "\n",
       "     refresh frequency of reports. Default: refresh=10 iterations.\n",
       "\n",
       "     digits number of printed digits in the reports. Default:\n",
       "          digits=4.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     A list of class mcmc.list (R package coda).\n",
       "\n",
       "_\bN_\bo_\bt_\be:\n",
       "\n",
       "     The GARCH(1,1) model with Student-t innovations may be written as\n",
       "     follows:\n",
       "\n",
       "                      y(t) = e(t)*(varrho * h(t))^(1/2)                 \n",
       "     \n",
       "     for t=1,...,T, where the conditional variance equation is defined\n",
       "     as:\n",
       "\n",
       "              h(t) := alpha0 + alpha1 * y(t-1)^2 + beta * h(t-1)        \n",
       "     \n",
       "     where alpha0>0,alpha1,beta>=0 to ensure a positive conditional\n",
       "     variance. We set the initial variance to h(0):=0 for convenience.\n",
       "     The parameter varrho:=(nu-2)/nu is a scaling factor which ensures\n",
       "     the conditional variance of y(t) to be h(t). Finally, e(t) follows\n",
       "     a Student-t distribution with nu degrees of freedom.\n",
       "\n",
       "     The prior distributions on alpha is a bivariate truncated Normal\n",
       "     distribution:\n",
       "\n",
       "          p(alpha) prop N2(alpha | mu_alpha, Sigma_alpha) I[alpha>0]    \n",
       "     \n",
       "     where mu_alpha is the prior mean vector, Sigma_alpha is the prior\n",
       "     covariance matrix and I[alpha>0] is the indicator function.\n",
       "\n",
       "     The prior distribution on beta is a univariate truncated Normal\n",
       "     distribution:\n",
       "\n",
       "             p(theta) prop N(beta | mu_beta, Sigma_beta) I[beta>0]      \n",
       "     \n",
       "     where mu_beta is the prior mean and Sigma_beta is the prior\n",
       "     variance.\n",
       "\n",
       "     The prior distribution on nu is a translated Exponential\n",
       "     distribution:\n",
       "\n",
       "              p(nu) = lambda * exp(-lambda(nu-delta)) I[nu>delta]       \n",
       "     \n",
       "     where lambda>0 and delta>=2. The prior mean for nu is delta +\n",
       "     1/lambda.\n",
       "\n",
       "     The joint prior on parameter psi:=(alpha,beta,nu) is obtained by\n",
       "     assuming prior independence:\n",
       "\n",
       "                     p(psi) = p(alpha) * p(beta) * p(nu).               \n",
       "     \n",
       "     The default hyperparameters mu_alpha, Sigma_alpha, mu_beta,\n",
       "     Sigma_beta and lambda define a rather vague prior. The\n",
       "     hyper-parameter delta>=2 ensures the existence of the conditional\n",
       "     variance. The kth conditional moment for e(t) is guaranteed by\n",
       "     setting delta>=k.\n",
       "\n",
       "     The Bayesian estimation of the GARCH(1,1) model with Normal\n",
       "     innovations is obtained as a special case by setting lambda=100\n",
       "     and delta=500. In this case, the generated values for nu are\n",
       "     centered around 500 which ensure approximate Normality for the\n",
       "     innovations.\n",
       "\n",
       "     The function addPriorConditions allows to add prior conditions\n",
       "     on the model parameters psi:=(alpha0 alpha1 beta nu)'. The\n",
       "     function must return TRUE if the constraint holds and FALSE\n",
       "     otherwise.\n",
       "\n",
       "     By default, the function is:\n",
       "\n",
       "     \n",
       "     \n",
       "         addPriorConditions <- function(psi)\n",
       "         {\n",
       "           TRUE\n",
       "         }\n",
       "       \n",
       "\n",
       "     and therefore does not add any other constraint than the\n",
       "     positivity of the parameters which are obtained through the prior\n",
       "     distribution for psi.\n",
       "\n",
       "     You simply need to modify addPriorConditions in order to add\n",
       "     constraints on the model parameters psi. For instance, to impose\n",
       "     the covariance-stationary conditions to hold, i.e. alpha_1 + beta\n",
       "     < 1, just define the function addPriorConditions as follows:\n",
       "\n",
       "     \n",
       "     \n",
       "         addPriorConditions <- function(psi)\n",
       "         {\n",
       "           psi[2] + psi[3] < 1\n",
       "         }\n",
       "       \n",
       "\n",
       "     Note that adding prior constraints on the model parameters can\n",
       "     diminish the acceptance rate and therefore lead to a very\n",
       "     inefficient sampler. This would however indicate that the\n",
       "     condition is not supported by the data.\n",
       "\n",
       "     The estimation strategy implemented in bayesGARCH is fully\n",
       "     automatic and does not require any tuning of the MCMC sampler. The\n",
       "     generation of the Markov chains is however time consuming and\n",
       "     estimating the model over several datasets on a daily basis can\n",
       "     therefore take a significant amount of time. In this case, the\n",
       "     algorithm can be easily parallelized, by running a single chain on\n",
       "     several processors.  Also, when the estimation is repeated over\n",
       "     updated time series (i.e. time series with more recent\n",
       "     observations), it is wise to start the algorithm using the\n",
       "     posterior mean or median of the parameters obtained at the\n",
       "     previous estimation step. The impact of the starting values\n",
       "     (burn-in phase) is likely to be smaller and thus the convergence\n",
       "     faster.\n",
       "\n",
       "     Finally, note that as any MH algorithm, the sampler can get stuck\n",
       "     to a given value, so that the chain does not move anymore.\n",
       "     However, the sampler uses Taylor-made candidate densities that are\n",
       "     especially `constructed' at each step, so it is almost impossible\n",
       "     for this MCMC sampler to get stuck at a given value for many\n",
       "     subsequent draws.  In the unlikely case that such ill behavior\n",
       "     would occur, one could scale the data (to have standard deviation\n",
       "     1), or run the algorithm with different initial values or a\n",
       "     different random seed.\n",
       "\n",
       "     Please cite the package in publications. Use\n",
       "     citation(\"bayesGARCH\").\n",
       "\n",
       "_\bA_\bu_\bt_\bh_\bo_\br(_\bs):\n",
       "\n",
       "     David Ardia <email: david.ardia.ch@gmail.com>\n",
       "\n",
       "_\bR_\be_\bf_\be_\br_\be_\bn_\bc_\be_\bs:\n",
       "\n",
       "     Ardia, D. (2009) Bayesian Estimation of a Markov-Switching\n",
       "     Threshold Asymmetric GARCH Model with Student-t Innovations.\n",
       "     _Econometrics Journal_ *12*(1), pp. 105-126.  doi:\n",
       "     10.1111/j.1368-423X.2008.00253.x (URL:\n",
       "     http://doi.org/10.1111/j.1368-423X.2008.00253.x)\n",
       "\n",
       "     Ardia, D., Hoogerheide, L.F. (2010) Bayesian Estimation of the\n",
       "     GARCH(1,1) Model with Student-t Innovations.  _The R Journal_\n",
       "     *2*(2), pp.41-47.  <URL:\n",
       "     https://journal.r-project.org/archive/2010-2/>\n",
       "\n",
       "     Ardia, D. (2008) Financial Risk Management with Bayesian\n",
       "     Estimation of GARCH Models.  Lecture Notes in Economics and\n",
       "     Mathematical Systems *612*. Springer-Verlag, Berlin, Germany.\n",
       "     ISBN 978-3-540-78656-6, e-ISBN 978-3-540-78657-3, doi:\n",
       "     10.1007/978-3-540-78657-3 (URL:\n",
       "     http://doi.org/10.1007/978-3-540-78657-3) <URL:\n",
       "     http://www.springer.com/de/book/9783540786566>\n",
       "\n",
       "     Deschamps, P.J. (2006) A Flexible Prior Distribution for Markov\n",
       "     Switching Autoregressions with Student-t Errors.  _Journal of\n",
       "     Econometrics_ *133*, pp.153-190.  doi:\n",
       "     10.1016/j.jeconom.2005.03.012 (URL:\n",
       "     http://doi.org/10.1016/j.jeconom.2005.03.012)\n",
       "\n",
       "     Geweke, J.F. (1993) Bayesian Treatment of the Independent\n",
       "     Student-t Linear Model.  _Journal of Applied Econometrics_ *8*,\n",
       "     pp.19-40.  doi: 10.1002/jae.3950080504 (URL:\n",
       "     http://doi.org/10.1002/jae.3950080504)\n",
       "\n",
       "     Nakatsuma, T. (2000) Bayesian Analysis of ARMA-GARCH Models: A\n",
       "     Markov Chain Sampling Approach.  _Journal of Econometrics_\n",
       "     *95*(1), pp.57-69.  doi: 10.1016/S0304-4076(99)00029-9 (URL:\n",
       "     http://doi.org/10.1016/S0304-4076(99)00029-9)\n",
       "\n",
       "     Nakatsuma, T. (1998) A Markov-Chain Sampling Algorithm for GARCH\n",
       "     Models.  _Studies in Nonlinear Dynamics and Econometrics_ *3*(2),\n",
       "     pp.107-117.  doi: 10.2202/1558-3708.1043 (URL:\n",
       "     http://doi.org/10.2202/1558-3708.1043)\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     garchFit (R package fGarch) for the classical Maximum\n",
       "     Likelihood estimation of GARCH models.\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "       ## !!! INCREASE THE NUMBER OF MCMC ITERATIONS !!!\n",
       "     \n",
       "       ## LOAD DATA\n",
       "       data(dem2gbp)\n",
       "       y <- dem2gbp[1:750]\n",
       "     \n",
       "       ## RUN THE SAMPLER (2 chains)\n",
       "       MCMC <- bayesGARCH(y, control = list(n.chain = 2, l.chain = 200))\n",
       "     \n",
       "       ## MCMC ANALYSIS (using coda)\n",
       "       plot(MCMC)\n",
       "       \n",
       "       ## FORM THE POSTERIOR SAMPLE\n",
       "       smpl <- formSmpl(MCMC, l.bi = 50)\n",
       "     \n",
       "       ## POSTERIOR STATISTICS\n",
       "       summary(smpl)\n",
       "       smpl <- as.matrix(smpl)\n",
       "       pairs(smpl)\n",
       "     \n",
       "       ## GARCH(1,1) WITH NORMAL INNOVATIONS\n",
       "       MCMC <- bayesGARCH(y, lambda = 100, delta = 500,\n",
       "                          control = list(n.chain = 2, l.chain = 200))\n",
       "     \n",
       "       ## GARCH(1,1) WITH NORMAL INNOVATIONS AND \n",
       "       ## WITH COVARIANCE STATIONARITY CONDITION\n",
       "       addPriorConditions <- function(psi){psi[2] + psi[3] < 1}\n",
       "       MCMC <- bayesGARCH(y, lambda = 100, delta = 500,\n",
       "                          control = list(n.chain = 2, l.chain = 200, \n",
       "                          addPriorConditions = addPriorConditions))\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "help(bayesGARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre class=language-r><code>function (y, mu.alpha = c(0, 0), Sigma.alpha = 1000 * diag(1, \n",
       "<span style=white-space:pre-wrap>    2), mu.beta = 0, Sigma.beta = 1000, lambda = 0.01, delta = 2, </span>\n",
       "<span style=white-space:pre-wrap>    control = list()) </span>\n",
       "NULL</code></pre>"
      ],
      "text/latex": [
       "\\begin{minted}{r}\n",
       "function (y, mu.alpha = c(0, 0), Sigma.alpha = 1000 * diag(1, \n",
       "    2), mu.beta = 0, Sigma.beta = 1000, lambda = 0.01, delta = 2, \n",
       "    control = list()) \n",
       "NULL\n",
       "\\end{minted}"
      ],
      "text/markdown": [
       "```r\n",
       "function (y, mu.alpha = c(0, 0), Sigma.alpha = 1000 * diag(1, \n",
       "    2), mu.beta = 0, Sigma.beta = 1000, lambda = 0.01, delta = 2, \n",
       "    control = list()) \n",
       "NULL\n",
       "```"
      ],
      "text/plain": [
       "function (y, mu.alpha = c(0, 0), Sigma.alpha = 1000 * diag(1, \n",
       "    2), mu.beta = 0, Sigma.beta = 1000, lambda = 0.01, delta = 2, \n",
       "    control = list()) \n",
       "NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args(bayesGARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chain:  1  iteration:  10  parameters:  0.0442 0.2187 0.6602 139.0167 \n",
      "chain:  1  iteration:  20  parameters:  0.0471 0.2783 0.6194 161.1971 \n",
      "chain:  1  iteration:  30  parameters:  0.0407 0.1958 0.6797 139.4946 \n",
      "chain:  1  iteration:  40  parameters:  0.048 0.2301 0.604 103.8871 \n",
      "chain:  1  iteration:  50  parameters:  0.0522 0.2655 0.6333 91.9184 \n",
      "chain:  1  iteration:  60  parameters:  0.0427 0.2933 0.6312 121.591 \n",
      "chain:  1  iteration:  70  parameters:  0.0588 0.2086 0.6154 135.2841 \n",
      "chain:  1  iteration:  80  parameters:  0.0511 0.305 0.5449 112.0506 \n",
      "chain:  1  iteration:  90  parameters:  0.0514 0.2942 0.5721 84.3086 \n",
      "chain:  1  iteration:  100  parameters:  0.0661 0.2563 0.5687 66.592 \n",
      "chain:  1  iteration:  110  parameters:  0.0525 0.3569 0.5363 87.9399 \n",
      "chain:  1  iteration:  120  parameters:  0.0644 0.2281 0.5209 81.6146 \n",
      "chain:  1  iteration:  130  parameters:  0.0847 0.2155 0.474 75.9239 \n",
      "chain:  1  iteration:  140  parameters:  0.0531 0.2758 0.5749 70.4872 \n",
      "chain:  1  iteration:  150  parameters:  0.048 0.2576 0.6054 72.6891 \n",
      "chain:  1  iteration:  160  parameters:  0.0417 0.1574 0.7148 94.0177 \n",
      "chain:  1  iteration:  170  parameters:  0.0495 0.221 0.6387 81.0557 \n",
      "chain:  1  iteration:  180  parameters:  0.0347 0.2006 0.7003 73.7872 \n",
      "chain:  1  iteration:  190  parameters:  0.0271 0.1768 0.7653 74.8208 \n",
      "chain:  1  iteration:  200  parameters:  0.0368 0.1353 0.7247 65.9537 \n",
      "chain:  1  iteration:  210  parameters:  0.0354 0.1458 0.7028 51.4799 \n",
      "chain:  1  iteration:  220  parameters:  0.0188 0.1828 0.781 54.0682 \n",
      "chain:  1  iteration:  230  parameters:  0.0427 0.2186 0.6515 48.0293 \n",
      "chain:  1  iteration:  240  parameters:  0.0244 0.259 0.7198 45.261 \n",
      "chain:  1  iteration:  250  parameters:  0.0449 0.2159 0.6404 41.7723 \n",
      "chain:  1  iteration:  260  parameters:  0.05 0.202 0.6337 36.4122 \n",
      "chain:  1  iteration:  270  parameters:  0.0665 0.3155 0.5079 40.874 \n",
      "chain:  1  iteration:  280  parameters:  0.0492 0.3358 0.5288 38.5803 \n",
      "chain:  1  iteration:  290  parameters:  0.0473 0.227 0.5811 42.0446 \n",
      "chain:  1  iteration:  300  parameters:  0.0439 0.2466 0.5959 37.9226 \n",
      "chain:  1  iteration:  310  parameters:  0.0522 0.2579 0.5986 31.8391 \n",
      "chain:  1  iteration:  320  parameters:  0.0368 0.2144 0.6608 32.9466 \n",
      "chain:  1  iteration:  330  parameters:  0.0459 0.1985 0.6336 21.6564 \n",
      "chain:  1  iteration:  340  parameters:  0.0368 0.2315 0.6841 28.3902 \n",
      "chain:  1  iteration:  350  parameters:  0.034 0.2551 0.6485 24.5764 \n",
      "chain:  1  iteration:  360  parameters:  0.0364 0.2057 0.6924 24.028 \n",
      "chain:  1  iteration:  370  parameters:  0.0403 0.202 0.6738 18.6507 \n",
      "chain:  1  iteration:  380  parameters:  0.0354 0.264 0.6274 15.6223 \n",
      "chain:  1  iteration:  390  parameters:  0.0426 0.2001 0.6859 12.7445 \n",
      "chain:  1  iteration:  400  parameters:  0.0421 0.228 0.6165 9.9344 \n",
      "chain:  1  iteration:  410  parameters:  0.0379 0.2391 0.646 11.4244 \n",
      "chain:  1  iteration:  420  parameters:  0.0538 0.1843 0.6279 9.1231 \n",
      "chain:  1  iteration:  430  parameters:  0.0446 0.279 0.6183 8.6239 \n",
      "chain:  1  iteration:  440  parameters:  0.0378 0.256 0.6612 6.4227 \n",
      "chain:  1  iteration:  450  parameters:  0.0391 0.1847 0.6879 6.3307 \n",
      "chain:  1  iteration:  460  parameters:  0.0277 0.2 0.6969 7.5687 \n",
      "chain:  1  iteration:  470  parameters:  0.04 0.1818 0.6901 7.7398 \n",
      "chain:  1  iteration:  480  parameters:  0.0234 0.2686 0.7073 6.3617 \n",
      "chain:  1  iteration:  490  parameters:  0.0355 0.2276 0.699 5.5339 \n",
      "chain:  1  iteration:  500  parameters:  0.0433 0.2519 0.6714 5.4301 \n",
      "chain:  1  iteration:  510  parameters:  0.0286 0.2609 0.6725 6.2542 \n",
      "chain:  1  iteration:  520  parameters:  0.0372 0.2267 0.6938 5.4212 \n",
      "chain:  1  iteration:  530  parameters:  0.0355 0.2623 0.6387 6.2932 \n",
      "chain:  1  iteration:  540  parameters:  0.0433 0.2011 0.6557 4.7313 \n",
      "chain:  1  iteration:  550  parameters:  0.0419 0.2296 0.6699 4.5019 \n",
      "chain:  1  iteration:  560  parameters:  0.0296 0.3173 0.6791 5.2588 \n",
      "chain:  1  iteration:  570  parameters:  0.031 0.3033 0.6561 5.0852 \n",
      "chain:  1  iteration:  580  parameters:  0.0603 0.3617 0.5071 5.4823 \n",
      "chain:  1  iteration:  590  parameters:  0.0398 0.4371 0.5593 4.9151 \n",
      "chain:  1  iteration:  600  parameters:  0.0525 0.377 0.5202 5.8086 \n",
      "chain:  1  iteration:  610  parameters:  0.0466 0.3666 0.5805 5.5554 \n",
      "chain:  1  iteration:  620  parameters:  0.0422 0.2762 0.6207 7.5763 \n",
      "chain:  1  iteration:  630  parameters:  0.0484 0.2097 0.6499 6.9963 \n",
      "chain:  1  iteration:  640  parameters:  0.0412 0.2886 0.6229 6.8478 \n",
      "chain:  1  iteration:  650  parameters:  0.0359 0.2197 0.6832 7.7205 \n",
      "chain:  1  iteration:  660  parameters:  0.0304 0.2314 0.7085 7.4559 \n",
      "chain:  1  iteration:  670  parameters:  0.0447 0.2311 0.6478 7.9199 \n",
      "chain:  1  iteration:  680  parameters:  0.0297 0.2027 0.7286 6.9201 \n",
      "chain:  1  iteration:  690  parameters:  0.0226 0.1724 0.78 5.3521 \n",
      "chain:  1  iteration:  700  parameters:  0.0133 0.1881 0.8013 5.2769 \n",
      "chain:  1  iteration:  710  parameters:  0.0284 0.1259 0.7887 5.9273 \n",
      "chain:  1  iteration:  720  parameters:  0.0229 0.1332 0.7983 8.3184 \n",
      "chain:  1  iteration:  730  parameters:  0.0309 0.1815 0.7166 9.1032 \n",
      "chain:  1  iteration:  740  parameters:  0.0282 0.1989 0.7104 7.2357 \n",
      "chain:  1  iteration:  750  parameters:  0.0274 0.1711 0.7337 6.9633 \n",
      "chain:  1  iteration:  760  parameters:  0.0176 0.171 0.8027 6.6145 \n",
      "chain:  1  iteration:  770  parameters:  0.0183 0.1951 0.7739 6.116 \n",
      "chain:  1  iteration:  780  parameters:  0.0234 0.2057 0.7567 5.4272 \n",
      "chain:  1  iteration:  790  parameters:  0.0336 0.2007 0.7015 5.9302 \n",
      "chain:  1  iteration:  800  parameters:  0.0218 0.2334 0.6821 7.0681 \n",
      "chain:  1  iteration:  810  parameters:  0.0345 0.2366 0.6236 6.6615 \n",
      "chain:  1  iteration:  820  parameters:  0.0448 0.285 0.6338 6.562 \n",
      "chain:  1  iteration:  830  parameters:  0.0395 0.3057 0.59 6.9475 \n",
      "chain:  1  iteration:  840  parameters:  0.03 0.3553 0.5941 7.23 \n",
      "chain:  1  iteration:  850  parameters:  0.0654 0.3435 0.4716 7.7061 \n",
      "chain:  1  iteration:  860  parameters:  0.1015 0.5 0.2779 7.9918 \n",
      "chain:  1  iteration:  870  parameters:  0.1027 0.4365 0.3618 8.3872 \n",
      "chain:  1  iteration:  880  parameters:  0.0379 0.3139 0.6125 7.3773 \n",
      "chain:  1  iteration:  890  parameters:  0.0347 0.3189 0.5996 5.7993 \n",
      "chain:  1  iteration:  900  parameters:  0.0247 0.2168 0.7168 5.2748 \n",
      "chain:  1  iteration:  910  parameters:  0.047 0.2394 0.6278 5.9922 \n",
      "chain:  1  iteration:  920  parameters:  0.0279 0.215 0.7177 4.8909 \n",
      "chain:  1  iteration:  930  parameters:  0.0229 0.2408 0.7129 5.2481 \n",
      "chain:  1  iteration:  940  parameters:  0.0309 0.2416 0.6971 5.5158 \n",
      "chain:  1  iteration:  950  parameters:  0.0365 0.2451 0.6705 6.4695 \n",
      "chain:  1  iteration:  960  parameters:  0.038 0.2815 0.6192 7.3582 \n",
      "chain:  1  iteration:  970  parameters:  0.0374 0.2221 0.6784 6.1962 \n",
      "chain:  1  iteration:  980  parameters:  0.0405 0.1738 0.7424 6.4146 \n",
      "chain:  1  iteration:  990  parameters:  0.0225 0.2071 0.738 7.0756 \n",
      "chain:  1  iteration:  1000  parameters:  0.0195 0.1691 0.7814 5.8973 \n",
      "chain:  1  iteration:  1010  parameters:  0.0176 0.1378 0.8207 5.3255 \n",
      "chain:  1  iteration:  1020  parameters:  0.0215 0.125 0.7915 5.2167 \n",
      "chain:  1  iteration:  1030  parameters:  0.0221 0.1475 0.7802 6.352 \n",
      "chain:  1  iteration:  1040  parameters:  0.0114 0.2012 0.7881 5.1664 \n",
      "chain:  1  iteration:  1050  parameters:  0.0236 0.1051 0.8237 5.1931 \n",
      "chain:  1  iteration:  1060  parameters:  0.0153 0.1279 0.8232 5.5786 \n",
      "chain:  1  iteration:  1070  parameters:  0.0169 0.1796 0.769 5.2671 \n",
      "chain:  1  iteration:  1080  parameters:  0.0245 0.1843 0.7395 5.2332 \n",
      "chain:  1  iteration:  1090  parameters:  0.0206 0.18 0.7852 4.6296 \n",
      "chain:  1  iteration:  1100  parameters:  0.0267 0.1552 0.7878 5.1021 \n",
      "chain:  1  iteration:  1110  parameters:  0.0306 0.224 0.7254 4.5586 \n",
      "chain:  1  iteration:  1120  parameters:  0.0221 0.2594 0.7281 4.0349 \n",
      "chain:  1  iteration:  1130  parameters:  0.0255 0.2688 0.727 4.3054 \n",
      "chain:  1  iteration:  1140  parameters:  0.0228 0.2326 0.7154 5.1317 \n",
      "chain:  1  iteration:  1150  parameters:  0.0318 0.2938 0.6427 5.3573 \n",
      "chain:  1  iteration:  1160  parameters:  0.0283 0.2328 0.7039 5.3501 \n",
      "chain:  1  iteration:  1170  parameters:  0.0214 0.2024 0.7484 7.2036 \n",
      "chain:  1  iteration:  1180  parameters:  0.0371 0.1855 0.7 6.5226 \n",
      "chain:  1  iteration:  1190  parameters:  0.0318 0.2043 0.6753 6.2721 \n",
      "chain:  1  iteration:  1200  parameters:  0.038 0.2189 0.6819 7.159 \n",
      "chain:  1  iteration:  1210  parameters:  0.0437 0.2535 0.6395 7.1398 \n",
      "chain:  1  iteration:  1220  parameters:  0.0427 0.2516 0.6458 7.7538 \n",
      "chain:  1  iteration:  1230  parameters:  0.042 0.306 0.6075 6.6241 \n",
      "chain:  1  iteration:  1240  parameters:  0.0348 0.2191 0.6996 5.7119 \n",
      "chain:  1  iteration:  1250  parameters:  0.044 0.2212 0.6849 5.0892 \n",
      "chain:  1  iteration:  1260  parameters:  0.0535 0.2268 0.6062 6.0052 \n",
      "chain:  1  iteration:  1270  parameters:  0.0425 0.2487 0.6408 4.3775 \n",
      "chain:  1  iteration:  1280  parameters:  0.0543 0.2698 0.6192 4.6326 \n",
      "chain:  1  iteration:  1290  parameters:  0.0567 0.3468 0.564 4.3963 \n",
      "chain:  1  iteration:  1300  parameters:  0.0807 0.2449 0.5454 4.6508 \n",
      "chain:  1  iteration:  1310  parameters:  0.0603 0.393 0.5146 4.2369 \n",
      "chain:  1  iteration:  1320  parameters:  0.062 0.3692 0.6243 3.5358 \n",
      "chain:  1  iteration:  1330  parameters:  0.0333 0.3528 0.6787 3.3594 \n",
      "chain:  1  iteration:  1340  parameters:  0.036 0.3499 0.6643 3.3812 \n",
      "chain:  1  iteration:  1350  parameters:  0.0353 0.249 0.7177 3.6142 \n",
      "chain:  1  iteration:  1360  parameters:  0.0429 0.2503 0.7204 3.6102 \n",
      "chain:  1  iteration:  1370  parameters:  0.0395 0.2746 0.6756 4.3476 \n",
      "chain:  1  iteration:  1380  parameters:  0.0332 0.1594 0.7079 6.2564 \n",
      "chain:  1  iteration:  1390  parameters:  0.0455 0.1962 0.6924 6.8752 \n",
      "chain:  1  iteration:  1400  parameters:  0.04 0.3183 0.6287 6.6406 \n",
      "chain:  1  iteration:  1410  parameters:  0.0398 0.3053 0.6107 5.5508 \n",
      "chain:  1  iteration:  1420  parameters:  0.0527 0.1921 0.6481 6.9102 \n",
      "chain:  1  iteration:  1430  parameters:  0.038 0.3444 0.6275 7.1076 \n",
      "chain:  1  iteration:  1440  parameters:  0.0558 0.1921 0.619 6.4506 \n",
      "chain:  1  iteration:  1450  parameters:  0.0602 0.3583 0.4636 5.7562 \n",
      "chain:  1  iteration:  1460  parameters:  0.0497 0.3155 0.557 6.4759 \n",
      "chain:  1  iteration:  1470  parameters:  0.0557 0.2779 0.5797 6.3812 \n",
      "chain:  1  iteration:  1480  parameters:  0.0591 0.2627 0.5897 5.648 \n",
      "chain:  1  iteration:  1490  parameters:  0.0686 0.3004 0.5638 5.3119 \n",
      "chain:  1  iteration:  1500  parameters:  0.0393 0.3477 0.5831 4.4294 \n",
      "chain:  1  iteration:  1510  parameters:  0.0427 0.2902 0.6306 4.9476 \n",
      "chain:  1  iteration:  1520  parameters:  0.0329 0.3281 0.6469 5.8713 \n",
      "chain:  1  iteration:  1530  parameters:  0.0517 0.2247 0.623 5.1135 \n",
      "chain:  1  iteration:  1540  parameters:  0.0433 0.289 0.5901 5.7621 \n",
      "chain:  1  iteration:  1550  parameters:  0.073 0.4236 0.3906 4.6185 \n",
      "chain:  1  iteration:  1560  parameters:  0.086 0.446 0.4333 4.6738 \n",
      "chain:  1  iteration:  1570  parameters:  0.0578 0.479 0.5056 4.8194 \n",
      "chain:  1  iteration:  1580  parameters:  0.06 0.5097 0.4873 4.7141 \n",
      "chain:  1  iteration:  1590  parameters:  0.055 0.2991 0.5823 4.396 \n",
      "chain:  1  iteration:  1600  parameters:  0.0304 0.3095 0.6629 4.819 \n",
      "chain:  1  iteration:  1610  parameters:  0.0406 0.2689 0.6476 5.5391 \n",
      "chain:  1  iteration:  1620  parameters:  0.0431 0.228 0.6745 7.738 \n",
      "chain:  1  iteration:  1630  parameters:  0.0429 0.2767 0.6049 6.8099 \n",
      "chain:  1  iteration:  1640  parameters:  0.0395 0.3398 0.5848 5.5138 \n",
      "chain:  1  iteration:  1650  parameters:  0.0482 0.259 0.6123 6.3151 \n",
      "chain:  1  iteration:  1660  parameters:  0.0533 0.2629 0.64 6.4844 \n",
      "chain:  1  iteration:  1670  parameters:  0.0181 0.2577 0.7302 6.0021 \n",
      "chain:  1  iteration:  1680  parameters:  0.04 0.1818 0.683 5.9556 \n",
      "chain:  1  iteration:  1690  parameters:  0.0407 0.1843 0.6493 7.511 \n",
      "chain:  1  iteration:  1700  parameters:  0.0349 0.3335 0.6085 7.8367 \n",
      "chain:  1  iteration:  1710  parameters:  0.0406 0.2902 0.5965 6.5865 \n",
      "chain:  1  iteration:  1720  parameters:  0.0246 0.2867 0.6743 5.6934 \n",
      "chain:  1  iteration:  1730  parameters:  0.0483 0.1931 0.652 6.5218 \n",
      "chain:  1  iteration:  1740  parameters:  0.0358 0.2628 0.6472 6.8573 \n",
      "chain:  1  iteration:  1750  parameters:  0.0392 0.2509 0.6693 9.0331 \n",
      "chain:  1  iteration:  1760  parameters:  0.046 0.2574 0.6092 11.0974 \n",
      "chain:  1  iteration:  1770  parameters:  0.0371 0.2903 0.6378 11.6046 \n",
      "chain:  1  iteration:  1780  parameters:  0.0339 0.286 0.593 8.9551 \n",
      "chain:  1  iteration:  1790  parameters:  0.0303 0.21 0.6879 9.3221 \n",
      "chain:  1  iteration:  1800  parameters:  0.0301 0.1905 0.707 7.9325 \n",
      "chain:  1  iteration:  1810  parameters:  0.0239 0.1834 0.7545 6.7043 \n",
      "chain:  1  iteration:  1820  parameters:  0.0256 0.1658 0.7479 7.6686 \n",
      "chain:  1  iteration:  1830  parameters:  0.0226 0.1614 0.7761 8.2494 \n",
      "chain:  1  iteration:  1840  parameters:  0.0286 0.1258 0.7516 6.6456 \n",
      "chain:  1  iteration:  1850  parameters:  0.0352 0.2305 0.6885 5.4462 \n",
      "chain:  1  iteration:  1860  parameters:  0.0393 0.1849 0.7295 4.742 \n",
      "chain:  1  iteration:  1870  parameters:  0.0306 0.2048 0.7198 4.6795 \n",
      "chain:  1  iteration:  1880  parameters:  0.036 0.209 0.705 4.2818 \n",
      "chain:  1  iteration:  1890  parameters:  0.0313 0.2595 0.6974 4.3828 \n",
      "chain:  1  iteration:  1900  parameters:  0.0378 0.2377 0.707 4.0629 \n",
      "chain:  1  iteration:  1910  parameters:  0.04 0.2647 0.6583 4.6364 \n",
      "chain:  1  iteration:  1920  parameters:  0.0371 0.2657 0.6689 5.4775 \n",
      "chain:  1  iteration:  1930  parameters:  0.0265 0.3005 0.6606 5.3176 \n",
      "chain:  1  iteration:  1940  parameters:  0.0308 0.2371 0.716 5.5211 \n",
      "chain:  1  iteration:  1950  parameters:  0.0347 0.1775 0.7114 5.4832 \n",
      "chain:  1  iteration:  1960  parameters:  0.0277 0.1619 0.7765 4.9212 \n",
      "chain:  1  iteration:  1970  parameters:  0.0191 0.1684 0.794 5.6562 \n",
      "chain:  1  iteration:  1980  parameters:  0.0147 0.1857 0.8083 5.4723 \n",
      "chain:  1  iteration:  1990  parameters:  0.0276 0.137 0.7817 5.2778 \n",
      "chain:  1  iteration:  2000  parameters:  0.0251 0.2457 0.6761 6.6449 \n",
      "chain:  1  iteration:  2010  parameters:  0.0399 0.2302 0.6446 6.4734 \n",
      "chain:  1  iteration:  2020  parameters:  0.0359 0.1871 0.7148 6.0827 \n",
      "chain:  1  iteration:  2030  parameters:  0.018 0.1647 0.7845 7.4835 \n",
      "chain:  1  iteration:  2040  parameters:  0.0182 0.133 0.8055 7.6755 \n",
      "chain:  1  iteration:  2050  parameters:  0.0085 0.1313 0.8412 6.6367 \n",
      "chain:  1  iteration:  2060  parameters:  0.0132 0.1243 0.8355 7.1461 \n",
      "chain:  1  iteration:  2070  parameters:  0.0166 0.1396 0.7929 8.0012 \n",
      "chain:  1  iteration:  2080  parameters:  0.0181 0.1454 0.8114 6.1821 \n",
      "chain:  1  iteration:  2090  parameters:  0.0241 0.1545 0.7854 6.6596 \n",
      "chain:  1  iteration:  2100  parameters:  0.0168 0.2061 0.7489 6.2115 \n",
      "chain:  1  iteration:  2110  parameters:  0.0324 0.2264 0.7036 7.0442 \n",
      "chain:  1  iteration:  2120  parameters:  0.0238 0.2189 0.759 5.0465 \n",
      "chain:  1  iteration:  2130  parameters:  0.0255 0.1925 0.7404 6.1788 \n",
      "chain:  1  iteration:  2140  parameters:  0.039 0.2315 0.6925 5.5676 \n",
      "chain:  1  iteration:  2150  parameters:  0.0333 0.2463 0.6792 5.5734 \n",
      "chain:  1  iteration:  2160  parameters:  0.024 0.1892 0.7452 5.7003 \n",
      "chain:  1  iteration:  2170  parameters:  0.0194 0.3269 0.6973 6.6956 \n",
      "chain:  1  iteration:  2180  parameters:  0.0314 0.2348 0.6957 5.5634 \n",
      "chain:  1  iteration:  2190  parameters:  0.0201 0.247 0.732 6.1396 \n",
      "chain:  1  iteration:  2200  parameters:  0.0137 0.2187 0.7783 6.783 \n",
      "chain:  1  iteration:  2210  parameters:  0.0275 0.2424 0.6671 5.886 \n",
      "chain:  1  iteration:  2220  parameters:  0.0285 0.2272 0.7242 6.7857 \n",
      "chain:  1  iteration:  2230  parameters:  0.0446 0.1792 0.712 5.8677 \n",
      "chain:  1  iteration:  2240  parameters:  0.0223 0.1803 0.7484 6.5656 \n",
      "chain:  1  iteration:  2250  parameters:  0.0275 0.1433 0.7792 7.4571 \n",
      "chain:  1  iteration:  2260  parameters:  0.0155 0.1809 0.804 6.7334 \n",
      "chain:  1  iteration:  2270  parameters:  0.0154 0.1261 0.8267 8.1565 \n",
      "chain:  1  iteration:  2280  parameters:  0.0138 0.126 0.8171 6.5406 \n",
      "chain:  1  iteration:  2290  parameters:  0.0101 0.1704 0.8239 6.1346 \n",
      "chain:  1  iteration:  2300  parameters:  0.0154 0.1456 0.8404 5.5844 \n",
      "chain:  1  iteration:  2310  parameters:  0.0078 0.1702 0.8244 5.1942 \n",
      "chain:  1  iteration:  2320  parameters:  0.0239 0.1232 0.7752 6.262 \n",
      "chain:  1  iteration:  2330  parameters:  0.0175 0.1692 0.8042 5.1178 \n",
      "chain:  1  iteration:  2340  parameters:  0.023 0.1443 0.7873 5.726 \n",
      "chain:  1  iteration:  2350  parameters:  0.012 0.1869 0.8052 7.5101 \n",
      "chain:  1  iteration:  2360  parameters:  0.0246 0.1991 0.7158 6.3698 \n",
      "chain:  1  iteration:  2370  parameters:  0.0293 0.1487 0.768 5.4875 \n",
      "chain:  1  iteration:  2380  parameters:  0.0175 0.1804 0.7623 7.2905 \n",
      "chain:  1  iteration:  2390  parameters:  0.0346 0.2027 0.6903 8.8203 \n",
      "chain:  1  iteration:  2400  parameters:  0.0204 0.2477 0.7132 8.2752 \n",
      "chain:  1  iteration:  2410  parameters:  0.0327 0.1802 0.6933 7.6245 \n",
      "chain:  1  iteration:  2420  parameters:  0.0309 0.2112 0.6932 8.1306 \n",
      "chain:  1  iteration:  2430  parameters:  0.0464 0.1922 0.7006 7.0382 \n",
      "chain:  1  iteration:  2440  parameters:  0.0299 0.2353 0.7077 6.7395 \n",
      "chain:  1  iteration:  2450  parameters:  0.0233 0.213 0.7316 8.1646 \n",
      "chain:  1  iteration:  2460  parameters:  0.0256 0.1725 0.7477 7.8831 \n",
      "chain:  1  iteration:  2470  parameters:  0.0237 0.1898 0.7365 5.9712 \n",
      "chain:  1  iteration:  2480  parameters:  0.0404 0.2058 0.6943 5.3783 \n",
      "chain:  1  iteration:  2490  parameters:  0.045 0.228 0.643 5.9544 \n",
      "chain:  1  iteration:  2500  parameters:  0.0419 0.1593 0.6791 7.4482 \n",
      "chain:  1  iteration:  2510  parameters:  0.0382 0.2286 0.6539 6.442 \n",
      "chain:  1  iteration:  2520  parameters:  0.0336 0.2496 0.711 6.0521 \n",
      "chain:  1  iteration:  2530  parameters:  0.0272 0.2679 0.6935 5.4001 \n",
      "chain:  1  iteration:  2540  parameters:  0.0311 0.2565 0.6871 4.3629 \n",
      "chain:  1  iteration:  2550  parameters:  0.0334 0.3525 0.6613 4.5556 \n",
      "chain:  1  iteration:  2560  parameters:  0.0435 0.3236 0.619 4.7493 \n",
      "chain:  1  iteration:  2570  parameters:  0.0365 0.2489 0.6626 4.7965 \n",
      "chain:  1  iteration:  2580  parameters:  0.0439 0.3512 0.5888 4.9265 \n",
      "chain:  1  iteration:  2590  parameters:  0.0415 0.2245 0.6495 4.654 \n",
      "chain:  1  iteration:  2600  parameters:  0.0343 0.2029 0.712 5.4549 \n",
      "chain:  1  iteration:  2610  parameters:  0.0335 0.2422 0.7028 5.3864 \n",
      "chain:  1  iteration:  2620  parameters:  0.0322 0.2221 0.7141 5.6984 \n",
      "chain:  1  iteration:  2630  parameters:  0.0326 0.2648 0.6656 5.2499 \n",
      "chain:  1  iteration:  2640  parameters:  0.0204 0.266 0.7366 4.5289 \n",
      "chain:  1  iteration:  2650  parameters:  0.0222 0.1915 0.7776 4.2652 \n",
      "chain:  1  iteration:  2660  parameters:  0.0273 0.2629 0.7138 4.3706 \n",
      "chain:  1  iteration:  2670  parameters:  0.0132 0.2342 0.7685 5.1048 \n",
      "chain:  1  iteration:  2680  parameters:  0.018 0.2472 0.7332 4.6964 \n",
      "chain:  1  iteration:  2690  parameters:  0.0197 0.2475 0.7576 4.7761 \n",
      "chain:  1  iteration:  2700  parameters:  0.0221 0.221 0.7488 5.3776 \n",
      "chain:  1  iteration:  2710  parameters:  0.023 0.1602 0.8002 5.065 \n",
      "chain:  1  iteration:  2720  parameters:  0.0262 0.1814 0.7636 5.4526 \n",
      "chain:  1  iteration:  2730  parameters:  0.0195 0.2072 0.7575 6.1366 \n",
      "chain:  1  iteration:  2740  parameters:  0.0252 0.1599 0.75 6.3538 \n",
      "chain:  1  iteration:  2750  parameters:  0.0098 0.1725 0.8321 5.7518 \n",
      "chain:  1  iteration:  2760  parameters:  0.0135 0.123 0.847 6.3668 \n",
      "chain:  1  iteration:  2770  parameters:  0.0121 0.1525 0.8082 6.1786 \n",
      "chain:  1  iteration:  2780  parameters:  0.0251 0.1257 0.8053 7.1463 \n",
      "chain:  1  iteration:  2790  parameters:  0.0166 0.1566 0.8017 7.52 \n",
      "chain:  1  iteration:  2800  parameters:  0.0254 0.1508 0.7582 8.338 \n",
      "chain:  1  iteration:  2810  parameters:  0.0282 0.2043 0.7242 10.914 \n",
      "chain:  1  iteration:  2820  parameters:  0.0311 0.1636 0.7113 9.3634 \n",
      "chain:  1  iteration:  2830  parameters:  0.034 0.1737 0.7293 6.1254 \n",
      "chain:  1  iteration:  2840  parameters:  0.0115 0.1701 0.7859 6.9102 \n",
      "chain:  1  iteration:  2850  parameters:  0.0151 0.1945 0.7665 5.529 \n",
      "chain:  1  iteration:  2860  parameters:  0.0336 0.2009 0.6999 7.4598 \n",
      "chain:  1  iteration:  2870  parameters:  0.0283 0.2213 0.6893 8.3815 \n",
      "chain:  1  iteration:  2880  parameters:  0.0229 0.2616 0.733 5.5195 \n",
      "chain:  1  iteration:  2890  parameters:  0.0296 0.1421 0.7574 6.3803 \n",
      "chain:  1  iteration:  2900  parameters:  0.0254 0.1901 0.7228 9.2204 \n",
      "chain:  1  iteration:  2910  parameters:  0.0334 0.2495 0.66 9.9341 \n",
      "chain:  1  iteration:  2920  parameters:  0.0361 0.2553 0.6618 9.7879 \n",
      "chain:  1  iteration:  2930  parameters:  0.0448 0.1879 0.6487 10.3442 \n",
      "chain:  1  iteration:  2940  parameters:  0.0404 0.29 0.6226 8.053 \n",
      "chain:  1  iteration:  2950  parameters:  0.0369 0.3307 0.6197 8.0376 \n",
      "chain:  1  iteration:  2960  parameters:  0.0319 0.2649 0.6746 7.4926 \n",
      "chain:  1  iteration:  2970  parameters:  0.0261 0.2234 0.6899 8.2533 \n",
      "chain:  1  iteration:  2980  parameters:  0.0384 0.2051 0.694 8.7774 \n",
      "chain:  1  iteration:  2990  parameters:  0.0402 0.2436 0.6445 10.1722 \n",
      "chain:  1  iteration:  3000  parameters:  0.0362 0.261 0.6535 9.0661 \n",
      "chain:  1  iteration:  3010  parameters:  0.0329 0.2875 0.6445 7.728 \n",
      "chain:  1  iteration:  3020  parameters:  0.0302 0.2206 0.7051 8.2192 \n",
      "chain:  1  iteration:  3030  parameters:  0.0314 0.157 0.7248 8.5655 \n",
      "chain:  1  iteration:  3040  parameters:  0.0287 0.223 0.7046 7.358 \n",
      "chain:  1  iteration:  3050  parameters:  0.0312 0.288 0.6584 7.1427 \n",
      "chain:  1  iteration:  3060  parameters:  0.0387 0.1927 0.6597 7.774 \n",
      "chain:  1  iteration:  3070  parameters:  0.0407 0.1982 0.6548 8.4607 \n",
      "chain:  1  iteration:  3080  parameters:  0.0307 0.2267 0.6823 7.2229 \n",
      "chain:  1  iteration:  3090  parameters:  0.0445 0.2627 0.6059 6.2538 \n",
      "chain:  1  iteration:  3100  parameters:  0.0302 0.282 0.6711 5.6228 \n",
      "chain:  1  iteration:  3110  parameters:  0.0295 0.1682 0.718 5.9532 \n",
      "chain:  1  iteration:  3120  parameters:  0.0316 0.2312 0.7293 6.8188 \n",
      "chain:  1  iteration:  3130  parameters:  0.0224 0.2003 0.752 7.7952 \n",
      "chain:  1  iteration:  3140  parameters:  0.0148 0.1483 0.7983 9.0868 \n",
      "chain:  1  iteration:  3150  parameters:  0.0147 0.0955 0.8502 8.1632 \n",
      "chain:  1  iteration:  3160  parameters:  0.0167 0.1219 0.8112 8.5387 \n",
      "chain:  1  iteration:  3170  parameters:  0.0194 0.1381 0.8132 7.386 \n",
      "chain:  1  iteration:  3180  parameters:  0.0188 0.1477 0.8093 6.7351 \n",
      "chain:  1  iteration:  3190  parameters:  0.021 0.2196 0.7277 7.28 \n",
      "chain:  1  iteration:  3200  parameters:  0.0352 0.1846 0.7133 7.7945 \n",
      "chain:  1  iteration:  3210  parameters:  0.0388 0.2236 0.6657 8.3042 \n",
      "chain:  1  iteration:  3220  parameters:  0.0307 0.2072 0.7029 6.8158 \n",
      "chain:  1  iteration:  3230  parameters:  0.033 0.2173 0.6903 6.0423 \n",
      "chain:  1  iteration:  3240  parameters:  0.0382 0.2006 0.6547 6.6751 \n",
      "chain:  1  iteration:  3250  parameters:  0.0301 0.2442 0.6481 7.324 \n",
      "chain:  1  iteration:  3260  parameters:  0.032 0.2735 0.6656 6.4162 \n",
      "chain:  1  iteration:  3270  parameters:  0.0416 0.1861 0.6641 8.8481 \n",
      "chain:  1  iteration:  3280  parameters:  0.0439 0.2282 0.6398 8.611 \n",
      "chain:  1  iteration:  3290  parameters:  0.0448 0.2433 0.6286 9.5288 \n",
      "chain:  1  iteration:  3300  parameters:  0.0666 0.1788 0.6151 7.3077 \n",
      "chain:  1  iteration:  3310  parameters:  0.0372 0.3237 0.6068 5.8366 \n",
      "chain:  1  iteration:  3320  parameters:  0.0602 0.3499 0.5279 6.9417 \n",
      "chain:  1  iteration:  3330  parameters:  0.0448 0.237 0.6125 9.8578 \n",
      "chain:  1  iteration:  3340  parameters:  0.0386 0.2608 0.644 8.5075 \n",
      "chain:  1  iteration:  3350  parameters:  0.0352 0.2552 0.6869 10.5389 \n",
      "chain:  1  iteration:  3360  parameters:  0.021 0.2162 0.7504 9.0999 \n",
      "chain:  1  iteration:  3370  parameters:  0.0325 0.1932 0.6792 8.5233 \n",
      "chain:  1  iteration:  3380  parameters:  0.0456 0.2154 0.6008 6.9193 \n",
      "chain:  1  iteration:  3390  parameters:  0.0523 0.3136 0.6019 7.1599 \n",
      "chain:  1  iteration:  3400  parameters:  0.0502 0.2603 0.6028 6.0527 \n",
      "chain:  1  iteration:  3410  parameters:  0.0461 0.4473 0.551 7.0527 \n",
      "chain:  1  iteration:  3420  parameters:  0.0398 0.2477 0.6515 6.6855 \n",
      "chain:  1  iteration:  3430  parameters:  0.0406 0.2267 0.6611 6.6711 \n",
      "chain:  1  iteration:  3440  parameters:  0.0385 0.1738 0.7104 5.6431 \n",
      "chain:  1  iteration:  3450  parameters:  0.0387 0.2856 0.6496 4.7696 \n",
      "chain:  1  iteration:  3460  parameters:  0.0427 0.3634 0.5431 5.6658 \n",
      "chain:  1  iteration:  3470  parameters:  0.0715 0.3684 0.4638 5.2736 \n",
      "chain:  1  iteration:  3480  parameters:  0.063 0.3124 0.513 6.2298 \n",
      "chain:  1  iteration:  3490  parameters:  0.0392 0.2095 0.6756 6.9303 \n",
      "chain:  1  iteration:  3500  parameters:  0.0393 0.2595 0.6015 6.5655 \n",
      "chain:  1  iteration:  3510  parameters:  0.0663 0.3092 0.5392 4.9171 \n",
      "chain:  1  iteration:  3520  parameters:  0.0655 0.3011 0.5606 4.5923 \n",
      "chain:  1  iteration:  3530  parameters:  0.0328 0.327 0.6446 5.0565 \n",
      "chain:  1  iteration:  3540  parameters:  0.046 0.2687 0.6488 5.1744 \n",
      "chain:  1  iteration:  3550  parameters:  0.0362 0.244 0.6553 4.9404 \n",
      "chain:  1  iteration:  3560  parameters:  0.0484 0.2431 0.6493 5.1353 \n",
      "chain:  1  iteration:  3570  parameters:  0.047 0.2456 0.626 4.6331 \n",
      "chain:  1  iteration:  3580  parameters:  0.0385 0.3357 0.6052 5.311 \n",
      "chain:  1  iteration:  3590  parameters:  0.0599 0.2382 0.5515 5.6227 \n",
      "chain:  1  iteration:  3600  parameters:  0.0473 0.2978 0.5845 5.5875 \n",
      "chain:  1  iteration:  3610  parameters:  0.0443 0.3549 0.5933 5.7967 \n",
      "chain:  1  iteration:  3620  parameters:  0.0572 0.371 0.5255 6.2815 \n",
      "chain:  1  iteration:  3630  parameters:  0.0637 0.3324 0.533 6.818 \n",
      "chain:  1  iteration:  3640  parameters:  0.0515 0.2998 0.5211 7.4633 \n",
      "chain:  1  iteration:  3650  parameters:  0.0555 0.2235 0.6389 6.4149 \n",
      "chain:  1  iteration:  3660  parameters:  0.0369 0.2599 0.6277 6.6237 \n",
      "chain:  1  iteration:  3670  parameters:  0.0372 0.187 0.7027 6.8889 \n",
      "chain:  1  iteration:  3680  parameters:  0.0332 0.2252 0.6737 7.8908 \n",
      "chain:  1  iteration:  3690  parameters:  0.0206 0.1872 0.7517 8.7622 \n",
      "chain:  1  iteration:  3700  parameters:  0.0217 0.227 0.7342 7.7433 \n",
      "chain:  1  iteration:  3710  parameters:  0.0335 0.1946 0.717 6.4035 \n",
      "chain:  1  iteration:  3720  parameters:  0.0153 0.2913 0.7298 4.9356 \n",
      "chain:  1  iteration:  3730  parameters:  0.0238 0.1639 0.7892 5.1429 \n",
      "chain:  1  iteration:  3740  parameters:  0.0232 0.2097 0.7238 5.7519 \n",
      "chain:  1  iteration:  3750  parameters:  0.0337 0.2214 0.6566 6.4698 \n",
      "chain:  1  iteration:  3760  parameters:  0.0211 0.2506 0.7043 5.5766 \n",
      "chain:  1  iteration:  3770  parameters:  0.05 0.3034 0.5839 5.7591 \n",
      "chain:  1  iteration:  3780  parameters:  0.0652 0.3402 0.4951 5.5898 \n",
      "chain:  1  iteration:  3790  parameters:  0.0458 0.3002 0.6319 5.2134 \n",
      "chain:  1  iteration:  3800  parameters:  0.0538 0.1871 0.6493 4.8546 \n",
      "chain:  1  iteration:  3810  parameters:  0.0618 0.3608 0.5424 4.5776 \n",
      "chain:  1  iteration:  3820  parameters:  0.0433 0.2866 0.6582 3.8918 \n",
      "chain:  1  iteration:  3830  parameters:  0.0418 0.3247 0.6195 4.9991 \n",
      "chain:  1  iteration:  3840  parameters:  0.0423 0.2869 0.6265 4.55 \n",
      "chain:  1  iteration:  3850  parameters:  0.0501 0.3121 0.6147 4.6052 \n",
      "chain:  1  iteration:  3860  parameters:  0.0497 0.4028 0.5516 4.8043 \n",
      "chain:  1  iteration:  3870  parameters:  0.0398 0.2334 0.6536 5.859 \n",
      "chain:  1  iteration:  3880  parameters:  0.0687 0.2156 0.5701 5.7826 \n",
      "chain:  1  iteration:  3890  parameters:  0.0534 0.3543 0.5423 5.1575 \n",
      "chain:  1  iteration:  3900  parameters:  0.0799 0.3459 0.458 4.826 \n",
      "chain:  1  iteration:  3910  parameters:  0.0629 0.2581 0.6385 4.4393 \n",
      "chain:  1  iteration:  3920  parameters:  0.0318 0.2136 0.7486 4.5677 \n",
      "chain:  1  iteration:  3930  parameters:  0.0357 0.1973 0.707 5.5207 \n",
      "chain:  1  iteration:  3940  parameters:  0.0397 0.1827 0.7013 5.2978 \n",
      "chain:  1  iteration:  3950  parameters:  0.0336 0.2291 0.7202 4.7704 \n",
      "chain:  1  iteration:  3960  parameters:  0.0216 0.217 0.7318 4.7393 \n",
      "chain:  1  iteration:  3970  parameters:  0.0307 0.1995 0.7323 4.3214 \n",
      "chain:  1  iteration:  3980  parameters:  0.0349 0.3042 0.6971 4.0393 \n",
      "chain:  1  iteration:  3990  parameters:  0.0409 0.2623 0.6754 4.3111 \n",
      "chain:  1  iteration:  4000  parameters:  0.0419 0.2347 0.6905 4.3003 \n",
      "chain:  1  iteration:  4010  parameters:  0.0194 0.2783 0.7511 3.7057 \n",
      "chain:  1  iteration:  4020  parameters:  0.0264 0.1812 0.7685 4.2622 \n",
      "chain:  1  iteration:  4030  parameters:  0.0257 0.239 0.7769 3.8564 \n",
      "chain:  1  iteration:  4040  parameters:  0.0335 0.2228 0.7356 3.7057 \n",
      "chain:  1  iteration:  4050  parameters:  0.0328 0.2559 0.7076 4.6224 \n",
      "chain:  1  iteration:  4060  parameters:  0.0409 0.2674 0.645 4.1795 \n",
      "chain:  1  iteration:  4070  parameters:  0.07 0.4217 0.4793 4.5523 \n",
      "chain:  1  iteration:  4080  parameters:  0.076 0.2881 0.5777 4.0266 \n",
      "chain:  1  iteration:  4090  parameters:  0.027 0.3172 0.6655 4.1246 \n",
      "chain:  1  iteration:  4100  parameters:  0.0273 0.2402 0.6865 4.5177 \n",
      "chain:  1  iteration:  4110  parameters:  0.0308 0.3164 0.6934 4.2277 \n",
      "chain:  1  iteration:  4120  parameters:  0.031 0.1882 0.7671 3.8856 \n",
      "chain:  1  iteration:  4130  parameters:  0.021 0.1857 0.7993 4.5357 \n",
      "chain:  1  iteration:  4140  parameters:  0.0292 0.184 0.7713 4.804 \n",
      "chain:  1  iteration:  4150  parameters:  0.0189 0.1649 0.787 4.8129 \n",
      "chain:  1  iteration:  4160  parameters:  0.0283 0.2032 0.7317 6.6414 \n",
      "chain:  1  iteration:  4170  parameters:  0.0284 0.2219 0.7221 6.8596 \n",
      "chain:  1  iteration:  4180  parameters:  0.0277 0.195 0.7338 6.5277 \n",
      "chain:  1  iteration:  4190  parameters:  0.0278 0.173 0.7388 6.5622 \n",
      "chain:  1  iteration:  4200  parameters:  0.0332 0.2453 0.6732 6.8395 \n",
      "chain:  1  iteration:  4210  parameters:  0.0368 0.1801 0.7085 5.8679 \n",
      "chain:  1  iteration:  4220  parameters:  0.0273 0.2346 0.7123 5.9018 \n",
      "chain:  1  iteration:  4230  parameters:  0.0317 0.2439 0.6736 6.4454 \n",
      "chain:  1  iteration:  4240  parameters:  0.0376 0.3232 0.6038 6.6506 \n",
      "chain:  1  iteration:  4250  parameters:  0.0492 0.2582 0.6323 5.249 \n",
      "chain:  1  iteration:  4260  parameters:  0.0514 0.239 0.635 5.6458 \n",
      "chain:  1  iteration:  4270  parameters:  0.0391 0.2423 0.6528 5.0163 \n",
      "chain:  1  iteration:  4280  parameters:  0.0237 0.1719 0.7754 5.6988 \n",
      "chain:  1  iteration:  4290  parameters:  0.0301 0.1821 0.7372 5.6054 \n",
      "chain:  1  iteration:  4300  parameters:  0.0316 0.2214 0.6989 6.0567 \n",
      "chain:  1  iteration:  4310  parameters:  0.0261 0.1893 0.7132 5.1948 \n",
      "chain:  1  iteration:  4320  parameters:  0.0237 0.1899 0.7191 7.4726 \n",
      "chain:  1  iteration:  4330  parameters:  0.0246 0.1637 0.7536 8.0533 \n",
      "chain:  1  iteration:  4340  parameters:  0.0326 0.1784 0.7332 8.9416 \n",
      "chain:  1  iteration:  4350  parameters:  0.0225 0.1598 0.7698 10.4864 \n",
      "chain:  1  iteration:  4360  parameters:  0.0217 0.1729 0.7389 11.1188 \n",
      "chain:  1  iteration:  4370  parameters:  0.0261 0.1669 0.7714 17.1726 \n",
      "chain:  1  iteration:  4380  parameters:  0.0182 0.1112 0.8227 14.3968 \n",
      "chain:  1  iteration:  4390  parameters:  0.0188 0.1455 0.7933 15.0093 \n",
      "chain:  1  iteration:  4400  parameters:  0.0123 0.1797 0.7943 8.7408 \n",
      "chain:  1  iteration:  4410  parameters:  0.0201 0.1741 0.7324 5.9872 \n",
      "chain:  1  iteration:  4420  parameters:  0.0284 0.2266 0.7093 5.8061 \n",
      "chain:  1  iteration:  4430  parameters:  0.0304 0.1935 0.7399 6.4918 \n",
      "chain:  1  iteration:  4440  parameters:  0.0382 0.2186 0.6319 6.2631 \n",
      "chain:  1  iteration:  4450  parameters:  0.0365 0.2347 0.6757 6.8208 \n",
      "chain:  1  iteration:  4460  parameters:  0.0309 0.26 0.7346 5.5123 \n",
      "chain:  1  iteration:  4470  parameters:  0.0216 0.1721 0.7547 4.862 \n",
      "chain:  1  iteration:  4480  parameters:  0.0241 0.2092 0.7367 5.6478 \n",
      "chain:  1  iteration:  4490  parameters:  0.0342 0.1336 0.7389 7.404 \n",
      "chain:  1  iteration:  4500  parameters:  0.0223 0.2926 0.684 9.7674 \n",
      "chain:  1  iteration:  4510  parameters:  0.0367 0.2644 0.6427 6.7477 \n",
      "chain:  1  iteration:  4520  parameters:  0.0299 0.256 0.7045 5.5251 \n",
      "chain:  1  iteration:  4530  parameters:  0.0458 0.1973 0.6435 6.0524 \n",
      "chain:  1  iteration:  4540  parameters:  0.031 0.3216 0.6491 5.2406 \n",
      "chain:  1  iteration:  4550  parameters:  0.0441 0.1894 0.6797 4.7775 \n",
      "chain:  1  iteration:  4560  parameters:  0.0429 0.2359 0.6735 4.5681 \n",
      "chain:  1  iteration:  4570  parameters:  0.0446 0.2298 0.6625 5.1484 \n",
      "chain:  1  iteration:  4580  parameters:  0.0332 0.2442 0.6593 7.5209 \n",
      "chain:  1  iteration:  4590  parameters:  0.0372 0.2784 0.6311 7.891 \n",
      "chain:  1  iteration:  4600  parameters:  0.038 0.2356 0.6515 6.4181 \n",
      "chain:  1  iteration:  4610  parameters:  0.0398 0.2339 0.6598 5.6731 \n",
      "chain:  1  iteration:  4620  parameters:  0.0725 0.2915 0.5164 6.2895 \n",
      "chain:  1  iteration:  4630  parameters:  0.0445 0.2409 0.6371 5.4057 \n",
      "chain:  1  iteration:  4640  parameters:  0.0469 0.247 0.6619 7.016 \n",
      "chain:  1  iteration:  4650  parameters:  0.0382 0.1768 0.666 8.6848 \n",
      "chain:  1  iteration:  4660  parameters:  0.0314 0.1789 0.7423 7.8993 \n",
      "chain:  1  iteration:  4670  parameters:  0.0257 0.2598 0.7034 10.4533 \n",
      "chain:  1  iteration:  4680  parameters:  0.027 0.2088 0.7146 8.8732 \n",
      "chain:  1  iteration:  4690  parameters:  0.0395 0.2579 0.6424 9.5509 \n",
      "chain:  1  iteration:  4700  parameters:  0.0323 0.2609 0.6423 8.4636 \n",
      "chain:  1  iteration:  4710  parameters:  0.0199 0.2705 0.7057 9.2946 \n",
      "chain:  1  iteration:  4720  parameters:  0.0346 0.1867 0.695 7.6842 \n",
      "chain:  1  iteration:  4730  parameters:  0.0281 0.1396 0.7653 7.0669 \n",
      "chain:  1  iteration:  4740  parameters:  0.0214 0.1793 0.7864 6.0619 \n",
      "chain:  1  iteration:  4750  parameters:  0.019 0.1481 0.7891 6.2234 \n",
      "chain:  1  iteration:  4760  parameters:  0.0157 0.2082 0.771 5.4333 \n",
      "chain:  1  iteration:  4770  parameters:  0.029 0.1436 0.7807 5.993 \n",
      "chain:  1  iteration:  4780  parameters:  0.0235 0.256 0.7189 5.0928 \n",
      "chain:  1  iteration:  4790  parameters:  0.028 0.2217 0.7079 5.7691 \n",
      "chain:  1  iteration:  4800  parameters:  0.0228 0.2013 0.7329 6.4013 \n",
      "chain:  1  iteration:  4810  parameters:  0.0254 0.166 0.738 6.4788 \n",
      "chain:  1  iteration:  4820  parameters:  0.0214 0.1811 0.7382 7.9616 \n",
      "chain:  1  iteration:  4830  parameters:  0.0159 0.1628 0.8176 6.5633 \n",
      "chain:  1  iteration:  4840  parameters:  0.0254 0.1201 0.7694 6.2042 \n",
      "chain:  1  iteration:  4850  parameters:  0.0151 0.1548 0.7947 6.4277 \n",
      "chain:  1  iteration:  4860  parameters:  0.0241 0.227 0.7405 4.6921 \n",
      "chain:  1  iteration:  4870  parameters:  0.0321 0.2532 0.6932 4.042 \n",
      "chain:  1  iteration:  4880  parameters:  0.0342 0.2342 0.6778 5.3399 \n",
      "chain:  1  iteration:  4890  parameters:  0.0408 0.2626 0.6478 4.9635 \n",
      "chain:  1  iteration:  4900  parameters:  0.0518 0.272 0.5961 5.2881 \n",
      "chain:  1  iteration:  4910  parameters:  0.0282 0.4637 0.5891 5.6797 \n",
      "chain:  1  iteration:  4920  parameters:  0.0303 0.2448 0.673 5.7985 \n",
      "chain:  1  iteration:  4930  parameters:  0.0363 0.2295 0.678 6.7895 \n",
      "chain:  1  iteration:  4940  parameters:  0.0274 0.1877 0.7365 7.0033 \n",
      "chain:  1  iteration:  4950  parameters:  0.0345 0.2017 0.7205 6.6303 \n",
      "chain:  1  iteration:  4960  parameters:  0.0417 0.3219 0.5958 6.5811 \n",
      "chain:  1  iteration:  4970  parameters:  0.0282 0.2976 0.6193 8.1937 \n",
      "chain:  1  iteration:  4980  parameters:  0.0506 0.2328 0.5945 6.5893 \n",
      "chain:  1  iteration:  4990  parameters:  0.0264 0.322 0.6678 6.6562 \n",
      "chain:  1  iteration:  5000  parameters:  0.0371 0.228 0.6412 8.8885 \n",
      "chain:  1  iteration:  5010  parameters:  0.0271 0.2301 0.7268 6.4583 \n",
      "chain:  1  iteration:  5020  parameters:  0.0156 0.1722 0.7943 6.3752 \n",
      "chain:  1  iteration:  5030  parameters:  0.0265 0.1096 0.7825 6.0654 \n",
      "chain:  1  iteration:  5040  parameters:  0.0063 0.1726 0.8361 5.7079 \n",
      "chain:  1  iteration:  5050  parameters:  0.0182 0.1271 0.8286 6.6604 \n",
      "chain:  1  iteration:  5060  parameters:  0.0165 0.1172 0.8168 7.5414 \n",
      "chain:  1  iteration:  5070  parameters:  0.0194 0.1677 0.7821 6.559 \n",
      "chain:  1  iteration:  5080  parameters:  0.0148 0.1464 0.8329 6.5249 \n",
      "chain:  1  iteration:  5090  parameters:  0.0183 0.1441 0.8133 6.6881 \n",
      "chain:  1  iteration:  5100  parameters:  0.0267 0.1773 0.754 6.2658 \n",
      "chain:  1  iteration:  5110  parameters:  0.0429 0.1542 0.7134 5.1155 \n",
      "chain:  1  iteration:  5120  parameters:  0.0427 0.2464 0.6783 5.7303 \n",
      "chain:  1  iteration:  5130  parameters:  0.0378 0.2436 0.6599 5.421 \n",
      "chain:  1  iteration:  5140  parameters:  0.036 0.3093 0.6141 6.2504 \n",
      "chain:  1  iteration:  5150  parameters:  0.0507 0.2227 0.6171 5.9364 \n",
      "chain:  1  iteration:  5160  parameters:  0.0368 0.2599 0.698 6.1209 \n",
      "chain:  1  iteration:  5170  parameters:  0.0224 0.2111 0.7489 5.9761 \n",
      "chain:  1  iteration:  5180  parameters:  0.0242 0.2194 0.6986 5.358 \n",
      "chain:  1  iteration:  5190  parameters:  0.0393 0.1856 0.7092 5.5865 \n",
      "chain:  1  iteration:  5200  parameters:  0.0223 0.2122 0.7354 5.6742 \n",
      "chain:  1  iteration:  5210  parameters:  0.0223 0.2105 0.7371 4.732 \n",
      "chain:  1  iteration:  5220  parameters:  0.0231 0.2424 0.7617 4.7631 \n",
      "chain:  1  iteration:  5230  parameters:  0.0308 0.3095 0.696 4.1435 \n",
      "chain:  1  iteration:  5240  parameters:  0.0385 0.3172 0.672 3.7038 \n",
      "chain:  1  iteration:  5250  parameters:  0.0295 0.3007 0.6871 3.6056 \n",
      "chain:  1  iteration:  5260  parameters:  0.0236 0.2593 0.7404 4.1247 \n",
      "chain:  1  iteration:  5270  parameters:  0.039 0.2864 0.6668 4.5729 \n",
      "chain:  1  iteration:  5280  parameters:  0.0377 0.3098 0.6407 4.3779 \n",
      "chain:  1  iteration:  5290  parameters:  0.0483 0.4454 0.5918 4.8081 \n",
      "chain:  1  iteration:  5300  parameters:  0.0464 0.3704 0.6228 4.7205 \n",
      "chain:  1  iteration:  5310  parameters:  0.0515 0.2677 0.5793 5.6626 \n",
      "chain:  1  iteration:  5320  parameters:  0.072 0.3037 0.5275 6.9671 \n",
      "chain:  1  iteration:  5330  parameters:  0.0436 0.2216 0.6816 6.1263 \n",
      "chain:  1  iteration:  5340  parameters:  0.0313 0.2228 0.6901 7.2807 \n",
      "chain:  1  iteration:  5350  parameters:  0.0294 0.2697 0.6839 6.967 \n",
      "chain:  1  iteration:  5360  parameters:  0.0374 0.2165 0.6701 6.4663 \n",
      "chain:  1  iteration:  5370  parameters:  0.0509 0.1777 0.6351 7.6205 \n",
      "chain:  1  iteration:  5380  parameters:  0.0576 0.2658 0.5658 6.0066 \n",
      "chain:  1  iteration:  5390  parameters:  0.033 0.2769 0.6784 6.0234 \n",
      "chain:  1  iteration:  5400  parameters:  0.0428 0.1914 0.6625 6.642 \n",
      "chain:  1  iteration:  5410  parameters:  0.0321 0.2562 0.6505 6.1636 \n",
      "chain:  1  iteration:  5420  parameters:  0.052 0.3095 0.589 5.8094 \n",
      "chain:  1  iteration:  5430  parameters:  0.0819 0.2229 0.4824 6.1842 \n",
      "chain:  1  iteration:  5440  parameters:  0.0547 0.379 0.5512 7.7819 \n",
      "chain:  1  iteration:  5450  parameters:  0.0474 0.2812 0.5755 6.3757 \n",
      "chain:  1  iteration:  5460  parameters:  0.0385 0.3807 0.5845 4.9625 \n",
      "chain:  1  iteration:  5470  parameters:  0.036 0.2381 0.6688 5.826 \n",
      "chain:  1  iteration:  5480  parameters:  0.0193 0.2684 0.7363 5.1713 \n",
      "chain:  1  iteration:  5490  parameters:  0.0283 0.1759 0.7585 5.6426 \n",
      "chain:  1  iteration:  5500  parameters:  0.0215 0.2828 0.7221 4.9107 \n",
      "chain:  1  iteration:  5510  parameters:  0.0269 0.2502 0.7239 4.1874 \n",
      "chain:  1  iteration:  5520  parameters:  0.0281 0.2346 0.7184 4.0308 \n",
      "chain:  1  iteration:  5530  parameters:  0.0288 0.1966 0.7801 4.2148 \n",
      "chain:  1  iteration:  5540  parameters:  0.0285 0.1712 0.7962 4.1587 \n",
      "chain:  1  iteration:  5550  parameters:  0.0232 0.1561 0.7977 4.1072 \n",
      "chain:  1  iteration:  5560  parameters:  0.0178 0.1508 0.832 4.1864 \n",
      "chain:  1  iteration:  5570  parameters:  0.0122 0.2208 0.7959 3.8682 \n",
      "chain:  1  iteration:  5580  parameters:  0.0205 0.1782 0.7696 4.1283 \n",
      "chain:  1  iteration:  5590  parameters:  0.0172 0.188 0.8003 4.872 \n",
      "chain:  1  iteration:  5600  parameters:  0.0208 0.1643 0.8048 4.7186 \n",
      "chain:  1  iteration:  5610  parameters:  0.0221 0.1271 0.8066 4.5509 \n",
      "chain:  1  iteration:  5620  parameters:  0.0158 0.1328 0.8296 5.1863 \n",
      "chain:  1  iteration:  5630  parameters:  0.0154 0.1359 0.829 4.8198 \n",
      "chain:  1  iteration:  5640  parameters:  0.0156 0.1345 0.8119 5.252 \n",
      "chain:  1  iteration:  5650  parameters:  0.0095 0.1617 0.8388 5.7779 \n",
      "chain:  1  iteration:  5660  parameters:  0.0105 0.1715 0.8235 6.8065 \n",
      "chain:  1  iteration:  5670  parameters:  0.0182 0.0979 0.8381 5.3396 \n",
      "chain:  1  iteration:  5680  parameters:  0.0183 0.1505 0.8231 4.259 \n",
      "chain:  1  iteration:  5690  parameters:  0.0196 0.2312 0.7425 4.4146 \n",
      "chain:  1  iteration:  5700  parameters:  0.0222 0.3113 0.6721 4.257 \n",
      "chain:  1  iteration:  5710  parameters:  0.0653 0.3735 0.5793 4.0902 \n",
      "chain:  1  iteration:  5720  parameters:  0.0617 0.3148 0.6194 4.1024 \n",
      "chain:  1  iteration:  5730  parameters:  0.043 0.2978 0.6767 4.2965 \n",
      "chain:  1  iteration:  5740  parameters:  0.0275 0.3065 0.671 5.1017 \n",
      "chain:  1  iteration:  5750  parameters:  0.0436 0.2867 0.6273 5.2356 \n",
      "chain:  1  iteration:  5760  parameters:  0.046 0.2159 0.6799 4.977 \n",
      "chain:  1  iteration:  5770  parameters:  0.0312 0.2428 0.6884 4.9459 \n",
      "chain:  1  iteration:  5780  parameters:  0.03 0.2541 0.6634 4.7196 \n",
      "chain:  1  iteration:  5790  parameters:  0.0405 0.3332 0.6102 4.7772 \n",
      "chain:  1  iteration:  5800  parameters:  0.0672 0.3665 0.5663 4.0283 \n",
      "chain:  1  iteration:  5810  parameters:  0.0455 0.3724 0.5794 3.9602 \n",
      "chain:  1  iteration:  5820  parameters:  0.0397 0.3149 0.6365 3.8849 \n",
      "chain:  1  iteration:  5830  parameters:  0.0601 0.3826 0.584 4.7408 \n",
      "chain:  1  iteration:  5840  parameters:  0.0482 0.5166 0.5422 3.8771 \n",
      "chain:  1  iteration:  5850  parameters:  0.0495 0.4404 0.536 4.0318 \n",
      "chain:  1  iteration:  5860  parameters:  0.049 0.4984 0.5125 4.6307 \n",
      "chain:  1  iteration:  5870  parameters:  0.0459 0.3113 0.6156 4.3267 \n",
      "chain:  1  iteration:  5880  parameters:  0.0335 0.3119 0.6704 4.2891 \n",
      "chain:  1  iteration:  5890  parameters:  0.0338 0.2996 0.6688 4.1598 \n",
      "chain:  1  iteration:  5900  parameters:  0.0519 0.2751 0.5983 5.2055 \n",
      "chain:  1  iteration:  5910  parameters:  0.0362 0.1809 0.6967 6.4664 \n",
      "chain:  1  iteration:  5920  parameters:  0.0405 0.3071 0.6571 4.893 \n",
      "chain:  1  iteration:  5930  parameters:  0.0454 0.2081 0.6754 4.8409 \n",
      "chain:  1  iteration:  5940  parameters:  0.0313 0.2586 0.652 4.9199 \n",
      "chain:  1  iteration:  5950  parameters:  0.0281 0.2586 0.7146 4.9203 \n",
      "chain:  1  iteration:  5960  parameters:  0.0296 0.2261 0.7507 4.1954 \n",
      "chain:  1  iteration:  5970  parameters:  0.0313 0.2518 0.7237 4.2514 \n",
      "chain:  1  iteration:  5980  parameters:  0.0325 0.1872 0.7414 5.0772 \n",
      "chain:  1  iteration:  5990  parameters:  0.0253 0.1836 0.7843 5.0562 \n",
      "chain:  1  iteration:  6000  parameters:  0.0132 0.163 0.821 4.8655 \n",
      "chain:  1  iteration:  6010  parameters:  0.0158 0.0838 0.8772 4.4933 \n",
      "chain:  1  iteration:  6020  parameters:  0.011 0.1083 0.8738 5.1957 \n",
      "chain:  1  iteration:  6030  parameters:  0.0115 0.103 0.8565 5.9731 \n",
      "chain:  1  iteration:  6040  parameters:  0.0087 0.1253 0.8665 7.1239 \n",
      "chain:  1  iteration:  6050  parameters:  0.0168 0.1061 0.8427 8.1875 \n",
      "chain:  1  iteration:  6060  parameters:  0.0106 0.2113 0.7675 6.8827 \n",
      "chain:  1  iteration:  6070  parameters:  0.0297 0.1598 0.7668 5.7206 \n",
      "chain:  1  iteration:  6080  parameters:  0.0166 0.1526 0.8105 6.3677 \n",
      "chain:  1  iteration:  6090  parameters:  0.0125 0.1593 0.7982 7.7595 \n",
      "chain:  1  iteration:  6100  parameters:  0.0196 0.1691 0.7824 5.4837 \n",
      "chain:  1  iteration:  6110  parameters:  0.0155 0.1973 0.7801 5.1036 \n",
      "chain:  1  iteration:  6120  parameters:  0.0283 0.1991 0.7727 5.1214 \n",
      "chain:  1  iteration:  6130  parameters:  0.0345 0.2089 0.6968 5.3127 \n",
      "chain:  1  iteration:  6140  parameters:  0.0254 0.2159 0.7288 7.9134 \n",
      "chain:  1  iteration:  6150  parameters:  0.0253 0.2315 0.6945 7.5414 \n",
      "chain:  1  iteration:  6160  parameters:  0.0356 0.1855 0.6773 9.0599 \n",
      "chain:  1  iteration:  6170  parameters:  0.0281 0.264 0.6748 7.4858 \n",
      "chain:  1  iteration:  6180  parameters:  0.0405 0.2275 0.5973 8.7656 \n",
      "chain:  1  iteration:  6190  parameters:  0.0396 0.2136 0.6767 7.8321 \n",
      "chain:  1  iteration:  6200  parameters:  0.0567 0.256 0.5926 7.4613 \n",
      "chain:  1  iteration:  6210  parameters:  0.0542 0.2594 0.5642 6.997 \n",
      "chain:  1  iteration:  6220  parameters:  0.0389 0.3465 0.5956 8.4915 \n",
      "chain:  1  iteration:  6230  parameters:  0.0366 0.3066 0.6054 9.0995 \n",
      "chain:  1  iteration:  6240  parameters:  0.0787 0.3276 0.4522 7.5136 \n",
      "chain:  1  iteration:  6250  parameters:  0.066 0.3892 0.4432 7.566 \n",
      "chain:  1  iteration:  6260  parameters:  0.0707 0.4177 0.4158 7.1176 \n",
      "chain:  1  iteration:  6270  parameters:  0.0657 0.2671 0.5456 6.5977 \n",
      "chain:  1  iteration:  6280  parameters:  0.0461 0.2436 0.6461 7.7278 \n",
      "chain:  1  iteration:  6290  parameters:  0.0479 0.2669 0.5882 7.7811 \n",
      "chain:  1  iteration:  6300  parameters:  0.0376 0.256 0.655 7.4521 \n",
      "chain:  1  iteration:  6310  parameters:  0.0311 0.1948 0.6956 7.2315 \n",
      "chain:  1  iteration:  6320  parameters:  0.0237 0.1498 0.7769 7.93 \n",
      "chain:  1  iteration:  6330  parameters:  0.0157 0.185 0.7699 8.8008 \n",
      "chain:  1  iteration:  6340  parameters:  0.0177 0.1577 0.802 6.8189 \n",
      "chain:  1  iteration:  6350  parameters:  0.0234 0.2225 0.7391 7.7552 \n",
      "chain:  1  iteration:  6360  parameters:  0.0247 0.1557 0.7723 6.7192 \n",
      "chain:  1  iteration:  6370  parameters:  0.0259 0.1986 0.7057 7.2457 \n",
      "chain:  1  iteration:  6380  parameters:  0.0555 0.2524 0.6009 7.1336 \n",
      "chain:  1  iteration:  6390  parameters:  0.0754 0.2738 0.4449 7.0129 \n",
      "chain:  1  iteration:  6400  parameters:  0.0632 0.3689 0.5489 7.2947 \n",
      "chain:  1  iteration:  6410  parameters:  0.0595 0.3586 0.5387 7.1688 \n",
      "chain:  1  iteration:  6420  parameters:  0.0471 0.3554 0.5671 6.17 \n",
      "chain:  1  iteration:  6430  parameters:  0.0547 0.3961 0.5155 5.5015 \n",
      "chain:  1  iteration:  6440  parameters:  0.0727 0.2664 0.5389 5.5885 \n",
      "chain:  1  iteration:  6450  parameters:  0.0218 0.2486 0.7287 5.3065 \n",
      "chain:  1  iteration:  6460  parameters:  0.017 0.2285 0.7686 5.954 \n",
      "chain:  1  iteration:  6470  parameters:  0.0327 0.2031 0.7185 7.1841 \n",
      "chain:  1  iteration:  6480  parameters:  0.047 0.2645 0.6185 6.0362 \n",
      "chain:  1  iteration:  6490  parameters:  0.0496 0.2201 0.6649 5.3587 \n",
      "chain:  1  iteration:  6500  parameters:  0.0296 0.2505 0.7002 5.5506 \n",
      "chain:  1  iteration:  6510  parameters:  0.0317 0.2284 0.6916 5.1284 \n",
      "chain:  1  iteration:  6520  parameters:  0.0207 0.1629 0.7871 5.5378 \n",
      "chain:  1  iteration:  6530  parameters:  0.0193 0.1819 0.7874 5.9006 \n",
      "chain:  1  iteration:  6540  parameters:  0.0099 0.1509 0.8293 5.8251 \n",
      "chain:  1  iteration:  6550  parameters:  0.0153 0.1699 0.8071 6.3892 \n",
      "chain:  1  iteration:  6560  parameters:  0.0138 0.1196 0.825 8.0065 \n",
      "chain:  1  iteration:  6570  parameters:  0.0118 0.1171 0.8399 6.4417 \n",
      "chain:  1  iteration:  6580  parameters:  0.0102 0.1463 0.8455 6.6914 \n",
      "chain:  1  iteration:  6590  parameters:  0.0083 0.1472 0.8564 7.3659 \n",
      "chain:  1  iteration:  6600  parameters:  0.0173 0.1144 0.8208 7.5448 \n",
      "chain:  1  iteration:  6610  parameters:  0.019 0.1036 0.8179 7.9625 \n",
      "chain:  1  iteration:  6620  parameters:  0.0185 0.1132 0.8225 7.161 \n",
      "chain:  1  iteration:  6630  parameters:  0.0191 0.1932 0.7504 8.3656 \n",
      "chain:  1  iteration:  6640  parameters:  0.0203 0.2251 0.7551 8.2324 \n",
      "chain:  1  iteration:  6650  parameters:  0.0224 0.1086 0.8201 8.513 \n",
      "chain:  1  iteration:  6660  parameters:  0.0183 0.1805 0.7664 6.4041 \n",
      "chain:  1  iteration:  6670  parameters:  0.0133 0.1373 0.8311 6.0026 \n",
      "chain:  1  iteration:  6680  parameters:  0.009 0.1822 0.8415 6.3989 \n",
      "chain:  1  iteration:  6690  parameters:  0.0169 0.1139 0.8332 6.7863 \n",
      "chain:  1  iteration:  6700  parameters:  0.0156 0.1757 0.7758 7.3525 \n",
      "chain:  1  iteration:  6710  parameters:  0.0194 0.1808 0.7589 8.4626 \n",
      "chain:  1  iteration:  6720  parameters:  0.0336 0.1734 0.7304 7.257 \n",
      "chain:  1  iteration:  6730  parameters:  0.0234 0.1308 0.7952 6.5569 \n",
      "chain:  1  iteration:  6740  parameters:  0.0247 0.1442 0.7837 6.1321 \n",
      "chain:  1  iteration:  6750  parameters:  0.017 0.1808 0.7953 5.5839 \n",
      "chain:  1  iteration:  6760  parameters:  0.0308 0.1979 0.7194 5.3624 \n",
      "chain:  1  iteration:  6770  parameters:  0.0377 0.2985 0.6277 6.2739 \n",
      "chain:  1  iteration:  6780  parameters:  0.0572 0.1988 0.5883 7.3917 \n",
      "chain:  1  iteration:  6790  parameters:  0.041 0.2815 0.6053 6.6037 \n",
      "chain:  1  iteration:  6800  parameters:  0.0568 0.2387 0.6007 5.954 \n",
      "chain:  1  iteration:  6810  parameters:  0.0552 0.266 0.582 5.6529 \n",
      "chain:  1  iteration:  6820  parameters:  0.0613 0.2678 0.5548 7.696 \n",
      "chain:  1  iteration:  6830  parameters:  0.0403 0.32 0.6152 6.885 \n",
      "chain:  1  iteration:  6840  parameters:  0.0409 0.1882 0.66 5.9921 \n",
      "chain:  1  iteration:  6850  parameters:  0.0377 0.3248 0.6482 4.9199 \n",
      "chain:  1  iteration:  6860  parameters:  0.0432 0.2943 0.5974 4.8378 \n",
      "chain:  1  iteration:  6870  parameters:  0.0626 0.3738 0.5219 5.0099 \n",
      "chain:  1  iteration:  6880  parameters:  0.0614 0.2981 0.5216 6.3596 \n",
      "chain:  1  iteration:  6890  parameters:  0.0447 0.2886 0.5798 6.9607 \n",
      "chain:  1  iteration:  6900  parameters:  0.0423 0.2655 0.624 6.4999 \n",
      "chain:  1  iteration:  6910  parameters:  0.0447 0.2249 0.637 6.9157 \n",
      "chain:  1  iteration:  6920  parameters:  0.0383 0.2766 0.604 7.4421 \n",
      "chain:  1  iteration:  6930  parameters:  0.0471 0.2163 0.6528 7.3924 \n",
      "chain:  1  iteration:  6940  parameters:  0.042 0.3017 0.5764 8.4408 \n",
      "chain:  1  iteration:  6950  parameters:  0.0708 0.1983 0.5896 9.5394 \n",
      "chain:  1  iteration:  6960  parameters:  0.0574 0.2313 0.5847 7.565 \n",
      "chain:  1  iteration:  6970  parameters:  0.0335 0.3686 0.5629 8.748 \n",
      "chain:  1  iteration:  6980  parameters:  0.0614 0.2727 0.4998 10.1683 \n",
      "chain:  1  iteration:  6990  parameters:  0.0503 0.228 0.5964 8.2187 \n",
      "chain:  1  iteration:  7000  parameters:  0.0557 0.2779 0.5563 8.2743 \n",
      "chain:  1  iteration:  7010  parameters:  0.0416 0.2719 0.6088 7.4006 \n",
      "chain:  1  iteration:  7020  parameters:  0.0432 0.2782 0.6254 6.1589 \n",
      "chain:  1  iteration:  7030  parameters:  0.0293 0.3378 0.6253 7.4557 \n",
      "chain:  1  iteration:  7040  parameters:  0.0576 0.2447 0.5974 5.704 \n",
      "chain:  1  iteration:  7050  parameters:  0.0502 0.287 0.6007 5.3568 \n",
      "chain:  1  iteration:  7060  parameters:  0.0371 0.2198 0.7116 4.708 \n",
      "chain:  1  iteration:  7070  parameters:  0.0286 0.2773 0.6708 4.7998 \n",
      "chain:  1  iteration:  7080  parameters:  0.0382 0.2207 0.7087 4.141 \n",
      "chain:  1  iteration:  7090  parameters:  0.043 0.2928 0.6488 4.4505 \n",
      "chain:  1  iteration:  7100  parameters:  0.048 0.2615 0.6636 4.3889 \n",
      "chain:  1  iteration:  7110  parameters:  0.038 0.2482 0.6873 3.8948 \n",
      "chain:  1  iteration:  7120  parameters:  0.0351 0.1969 0.7384 4.211 \n",
      "chain:  1  iteration:  7130  parameters:  0.0277 0.2198 0.7157 4.7949 \n",
      "chain:  1  iteration:  7140  parameters:  0.0367 0.2249 0.6986 4.3692 \n",
      "chain:  1  iteration:  7150  parameters:  0.0302 0.279 0.6692 5.2302 \n",
      "chain:  1  iteration:  7160  parameters:  0.0452 0.2369 0.6256 6.4557 \n",
      "chain:  1  iteration:  7170  parameters:  0.0339 0.2073 0.6921 8.1726 \n",
      "chain:  1  iteration:  7180  parameters:  0.0492 0.3066 0.5611 7.6225 \n",
      "chain:  1  iteration:  7190  parameters:  0.0516 0.2481 0.6023 8.6429 \n",
      "chain:  1  iteration:  7200  parameters:  0.0286 0.1988 0.7165 8.3079 \n",
      "chain:  1  iteration:  7210  parameters:  0.0422 0.1912 0.6833 8.9848 \n",
      "chain:  1  iteration:  7220  parameters:  0.0362 0.2147 0.6889 5.8586 \n",
      "chain:  1  iteration:  7230  parameters:  0.0204 0.2441 0.7439 4.929 \n",
      "chain:  1  iteration:  7240  parameters:  0.03 0.2959 0.7094 4.5667 \n",
      "chain:  1  iteration:  7250  parameters:  0.0337 0.2338 0.7011 4.4739 \n",
      "chain:  1  iteration:  7260  parameters:  0.0459 0.2735 0.6264 4.1378 \n",
      "chain:  1  iteration:  7270  parameters:  0.0254 0.3254 0.7115 3.9991 \n",
      "chain:  1  iteration:  7280  parameters:  0.0274 0.3195 0.7045 3.597 \n",
      "chain:  1  iteration:  7290  parameters:  0.0371 0.2415 0.7149 3.9683 \n",
      "chain:  1  iteration:  7300  parameters:  0.0214 0.2543 0.7379 4.4233 \n",
      "chain:  1  iteration:  7310  parameters:  0.0346 0.2215 0.7285 3.6588 \n",
      "chain:  1  iteration:  7320  parameters:  0.0256 0.161 0.8076 4.3545 \n",
      "chain:  1  iteration:  7330  parameters:  0.0273 0.125 0.8163 4.3139 \n",
      "chain:  1  iteration:  7340  parameters:  0.0065 0.1812 0.8345 4.2988 \n",
      "chain:  1  iteration:  7350  parameters:  0.0127 0.1632 0.8233 4.5705 \n",
      "chain:  1  iteration:  7360  parameters:  0.0214 0.1274 0.8281 4.3726 \n",
      "chain:  1  iteration:  7370  parameters:  0.0262 0.2103 0.7315 4.6525 \n",
      "chain:  1  iteration:  7380  parameters:  0.0207 0.1188 0.7889 5.9011 \n",
      "chain:  1  iteration:  7390  parameters:  0.0261 0.1905 0.7494 5.9061 \n",
      "chain:  1  iteration:  7400  parameters:  0.0296 0.2565 0.6748 6.6364 \n",
      "chain:  1  iteration:  7410  parameters:  0.0413 0.3002 0.6579 4.4365 \n",
      "chain:  1  iteration:  7420  parameters:  0.0668 0.269 0.542 4.1698 \n",
      "chain:  1  iteration:  7430  parameters:  0.0564 0.3662 0.5542 4.2993 \n",
      "chain:  1  iteration:  7440  parameters:  0.0533 0.314 0.5482 4.7255 \n",
      "chain:  1  iteration:  7450  parameters:  0.0397 0.2666 0.6773 4.5667 \n",
      "chain:  1  iteration:  7460  parameters:  0.0249 0.2789 0.7245 4.3751 \n",
      "chain:  1  iteration:  7470  parameters:  0.0322 0.2774 0.6407 4.555 \n",
      "chain:  1  iteration:  7480  parameters:  0.05 0.3526 0.5726 4.3479 \n",
      "chain:  1  iteration:  7490  parameters:  0.0373 0.3518 0.6304 4.1047 \n",
      "chain:  1  iteration:  7500  parameters:  0.0416 0.4326 0.5598 4.2256 \n",
      "chain:  1  iteration:  7510  parameters:  0.053 0.4029 0.503 5.0544 \n",
      "chain:  1  iteration:  7520  parameters:  0.0526 0.3906 0.5238 5.0774 \n",
      "chain:  1  iteration:  7530  parameters:  0.0469 0.4372 0.5435 4.452 \n",
      "chain:  1  iteration:  7540  parameters:  0.0547 0.2813 0.5777 5.5769 \n",
      "chain:  1  iteration:  7550  parameters:  0.0756 0.2132 0.602 6.0196 \n",
      "chain:  1  iteration:  7560  parameters:  0.0396 0.2725 0.629 6.8648 \n",
      "chain:  1  iteration:  7570  parameters:  0.0431 0.2066 0.6605 6.9469 \n",
      "chain:  1  iteration:  7580  parameters:  0.0337 0.256 0.6797 6.6321 \n",
      "chain:  1  iteration:  7590  parameters:  0.0312 0.2681 0.7 5.88 \n",
      "chain:  1  iteration:  7600  parameters:  0.0362 0.2172 0.6899 4.678 \n",
      "chain:  1  iteration:  7610  parameters:  0.0225 0.3142 0.6703 4.4896 \n",
      "chain:  1  iteration:  7620  parameters:  0.0311 0.2857 0.6867 4.5818 \n",
      "chain:  1  iteration:  7630  parameters:  0.035 0.2496 0.7083 4.1189 \n",
      "chain:  1  iteration:  7640  parameters:  0.0237 0.2737 0.7516 4.6164 \n",
      "chain:  1  iteration:  7650  parameters:  0.0309 0.2902 0.681 4.8495 \n",
      "chain:  1  iteration:  7660  parameters:  0.0306 0.199 0.7351 5.339 \n",
      "chain:  1  iteration:  7670  parameters:  0.022 0.2219 0.7535 5.9172 \n",
      "chain:  1  iteration:  7680  parameters:  0.0398 0.2006 0.6539 6.66 \n",
      "chain:  1  iteration:  7690  parameters:  0.0176 0.2782 0.7279 6.7062 \n",
      "chain:  1  iteration:  7700  parameters:  0.0254 0.259 0.6915 5.7381 \n",
      "chain:  1  iteration:  7710  parameters:  0.0282 0.1601 0.7524 6.1134 \n",
      "chain:  1  iteration:  7720  parameters:  0.0227 0.167 0.7522 6.165 \n",
      "chain:  1  iteration:  7730  parameters:  0.0257 0.1426 0.799 5.2741 \n",
      "chain:  1  iteration:  7740  parameters:  0.0205 0.1385 0.8127 5.0776 \n",
      "chain:  1  iteration:  7750  parameters:  0.0208 0.084 0.8495 6.0533 \n",
      "chain:  1  iteration:  7760  parameters:  0.0087 0.1212 0.8514 4.9472 \n",
      "chain:  1  iteration:  7770  parameters:  0.017 0.1172 0.8279 6.1348 \n",
      "chain:  1  iteration:  7780  parameters:  0.0063 0.1556 0.8493 5.7827 \n",
      "chain:  1  iteration:  7790  parameters:  0.0114 0.16 0.8036 5.1748 \n",
      "chain:  1  iteration:  7800  parameters:  0.0153 0.1105 0.8485 6.569 \n",
      "chain:  1  iteration:  7810  parameters:  0.0146 0.0851 0.8563 6.9922 \n",
      "chain:  1  iteration:  7820  parameters:  0.0133 0.1287 0.8275 6.9638 \n",
      "chain:  1  iteration:  7830  parameters:  0.0191 0.1265 0.8106 5.7703 \n",
      "chain:  1  iteration:  7840  parameters:  0.0204 0.1831 0.7846 5.4781 \n",
      "chain:  1  iteration:  7850  parameters:  0.0217 0.1629 0.7697 5.4231 \n",
      "chain:  1  iteration:  7860  parameters:  0.0216 0.1718 0.7656 6.3196 \n",
      "chain:  1  iteration:  7870  parameters:  0.0386 0.2092 0.7037 6.0224 \n",
      "chain:  1  iteration:  7880  parameters:  0.0315 0.247 0.7111 5.825 \n",
      "chain:  1  iteration:  7890  parameters:  0.03 0.3025 0.6487 5.1174 \n",
      "chain:  1  iteration:  7900  parameters:  0.0262 0.2661 0.7058 5.7792 \n",
      "chain:  1  iteration:  7910  parameters:  0.0251 0.2985 0.7028 5.6959 \n",
      "chain:  1  iteration:  7920  parameters:  0.0352 0.2681 0.6931 5.4683 \n",
      "chain:  1  iteration:  7930  parameters:  0.0308 0.269 0.6284 6.4334 \n",
      "chain:  1  iteration:  7940  parameters:  0.038 0.2556 0.6681 4.5914 \n",
      "chain:  1  iteration:  7950  parameters:  0.0494 0.2635 0.6282 4.8778 \n",
      "chain:  1  iteration:  7960  parameters:  0.0573 0.3686 0.5767 4.5137 \n",
      "chain:  1  iteration:  7970  parameters:  0.0328 0.3149 0.6283 5.1801 \n",
      "chain:  1  iteration:  7980  parameters:  0.0421 0.2847 0.6671 4.4767 \n",
      "chain:  1  iteration:  7990  parameters:  0.0249 0.2356 0.7443 3.9095 \n",
      "chain:  1  iteration:  8000  parameters:  0.0281 0.2412 0.7218 4.2556 \n",
      "chain:  1  iteration:  8010  parameters:  0.0475 0.2801 0.6125 6.1518 \n",
      "chain:  1  iteration:  8020  parameters:  0.043 0.3886 0.604 5.8627 \n",
      "chain:  1  iteration:  8030  parameters:  0.0643 0.2816 0.4962 6.3959 \n",
      "chain:  1  iteration:  8040  parameters:  0.058 0.3385 0.5464 5.3782 \n",
      "chain:  1  iteration:  8050  parameters:  0.0409 0.2351 0.6547 6.1265 \n",
      "chain:  1  iteration:  8060  parameters:  0.0416 0.2692 0.6232 6.7918 \n",
      "chain:  1  iteration:  8070  parameters:  0.0442 0.2358 0.6291 5.8636 \n",
      "chain:  1  iteration:  8080  parameters:  0.0357 0.2744 0.6801 6.6168 \n",
      "chain:  1  iteration:  8090  parameters:  0.05 0.2348 0.6289 6.8664 \n",
      "chain:  1  iteration:  8100  parameters:  0.0494 0.2224 0.6526 6.4328 \n",
      "chain:  1  iteration:  8110  parameters:  0.0387 0.2509 0.6808 5.782 \n",
      "chain:  1  iteration:  8120  parameters:  0.03 0.2692 0.6849 6.131 \n",
      "chain:  1  iteration:  8130  parameters:  0.0373 0.2028 0.6866 6.1264 \n",
      "chain:  1  iteration:  8140  parameters:  0.0325 0.1638 0.7099 7.0589 \n",
      "chain:  1  iteration:  8150  parameters:  0.0297 0.212 0.6922 7.6159 \n",
      "chain:  1  iteration:  8160  parameters:  0.024 0.2999 0.6666 9.5074 \n",
      "chain:  1  iteration:  8170  parameters:  0.0252 0.1306 0.7577 14.9614 \n",
      "chain:  1  iteration:  8180  parameters:  0.025 0.1726 0.7288 12.8847 \n",
      "chain:  1  iteration:  8190  parameters:  0.0315 0.2328 0.6971 10.8845 \n",
      "chain:  1  iteration:  8200  parameters:  0.0412 0.1792 0.6847 12.7048 \n",
      "chain:  1  iteration:  8210  parameters:  0.0485 0.3316 0.5631 14.4025 \n",
      "chain:  1  iteration:  8220  parameters:  0.043 0.2982 0.5786 13.1846 \n",
      "chain:  1  iteration:  8230  parameters:  0.0472 0.3069 0.6014 10.6481 \n",
      "chain:  1  iteration:  8240  parameters:  0.028 0.2062 0.7293 8.5059 \n",
      "chain:  1  iteration:  8250  parameters:  0.0176 0.2187 0.7305 7.4487 \n",
      "chain:  1  iteration:  8260  parameters:  0.0269 0.2262 0.7284 5.7764 \n",
      "chain:  1  iteration:  8270  parameters:  0.038 0.2336 0.6925 7.4021 \n",
      "chain:  1  iteration:  8280  parameters:  0.0385 0.219 0.6435 7.8611 \n",
      "chain:  1  iteration:  8290  parameters:  0.054 0.1858 0.6603 7.0659 \n",
      "chain:  1  iteration:  8300  parameters:  0.0277 0.1803 0.7354 6.91 \n",
      "chain:  1  iteration:  8310  parameters:  0.032 0.2214 0.6974 5.3155 \n",
      "chain:  1  iteration:  8320  parameters:  0.0435 0.2083 0.6703 5.2194 \n",
      "chain:  1  iteration:  8330  parameters:  0.0463 0.2758 0.6449 5.4405 \n",
      "chain:  1  iteration:  8340  parameters:  0.0278 0.2467 0.6956 5.9579 \n",
      "chain:  1  iteration:  8350  parameters:  0.0285 0.2225 0.7228 6.3745 \n",
      "chain:  1  iteration:  8360  parameters:  0.029 0.1648 0.7673 5.9313 \n",
      "chain:  1  iteration:  8370  parameters:  0.0223 0.1713 0.7894 6.3322 \n",
      "chain:  1  iteration:  8380  parameters:  0.0291 0.1656 0.7431 5.8468 \n",
      "chain:  1  iteration:  8390  parameters:  0.0319 0.2466 0.6506 5.7655 \n",
      "chain:  1  iteration:  8400  parameters:  0.0483 0.2847 0.5998 5.9901 \n",
      "chain:  1  iteration:  8410  parameters:  0.0496 0.2552 0.6145 7.0227 \n",
      "chain:  1  iteration:  8420  parameters:  0.0549 0.2624 0.5996 7.5352 \n",
      "chain:  1  iteration:  8430  parameters:  0.0507 0.2809 0.5663 7.3099 \n",
      "chain:  1  iteration:  8440  parameters:  0.0464 0.3259 0.5403 8.1384 \n",
      "chain:  1  iteration:  8450  parameters:  0.0482 0.3074 0.5772 7.637 \n",
      "chain:  1  iteration:  8460  parameters:  0.0442 0.3161 0.638 5.7178 \n",
      "chain:  1  iteration:  8470  parameters:  0.0345 0.2314 0.7028 6.2848 \n",
      "chain:  1  iteration:  8480  parameters:  0.0384 0.2227 0.6812 6.5016 \n",
      "chain:  1  iteration:  8490  parameters:  0.0378 0.1164 0.7569 6.9421 \n",
      "chain:  1  iteration:  8500  parameters:  0.0285 0.1402 0.7681 8.389 \n",
      "chain:  1  iteration:  8510  parameters:  0.0253 0.2055 0.7279 8.0818 \n",
      "chain:  1  iteration:  8520  parameters:  0.038 0.1795 0.6887 8.6587 \n",
      "chain:  1  iteration:  8530  parameters:  0.0457 0.1932 0.6305 8.3707 \n",
      "chain:  1  iteration:  8540  parameters:  0.0406 0.2375 0.6603 8.3782 \n",
      "chain:  1  iteration:  8550  parameters:  0.0328 0.2569 0.6808 6.9447 \n",
      "chain:  1  iteration:  8560  parameters:  0.0368 0.1584 0.7079 7.2897 \n",
      "chain:  1  iteration:  8570  parameters:  0.0399 0.1514 0.694 7.2502 \n",
      "chain:  1  iteration:  8580  parameters:  0.0189 0.3372 0.7013 7.5757 \n",
      "chain:  1  iteration:  8590  parameters:  0.0218 0.305 0.7017 6.9358 \n",
      "chain:  1  iteration:  8600  parameters:  0.025 0.2695 0.7052 5.4764 \n",
      "chain:  1  iteration:  8610  parameters:  0.023 0.2602 0.7094 6.0903 \n",
      "chain:  1  iteration:  8620  parameters:  0.0302 0.2242 0.7036 6.1228 \n",
      "chain:  1  iteration:  8630  parameters:  0.0312 0.2584 0.6562 6.8963 \n",
      "chain:  1  iteration:  8640  parameters:  0.0392 0.3035 0.6143 5.7499 \n",
      "chain:  1  iteration:  8650  parameters:  0.0324 0.2309 0.6774 7.9071 \n",
      "chain:  1  iteration:  8660  parameters:  0.0328 0.293 0.6285 6.5397 \n",
      "chain:  1  iteration:  8670  parameters:  0.0401 0.2355 0.6668 6.4286 \n",
      "chain:  1  iteration:  8680  parameters:  0.0332 0.2237 0.6718 6.1428 \n",
      "chain:  1  iteration:  8690  parameters:  0.043 0.2307 0.6587 5.1625 \n",
      "chain:  1  iteration:  8700  parameters:  0.035 0.2544 0.6138 5.5857 \n",
      "chain:  1  iteration:  8710  parameters:  0.0367 0.3181 0.5918 5.848 \n",
      "chain:  1  iteration:  8720  parameters:  0.0552 0.3575 0.5616 6.4533 \n",
      "chain:  1  iteration:  8730  parameters:  0.0477 0.2824 0.6079 7.9538 \n",
      "chain:  1  iteration:  8740  parameters:  0.0558 0.2727 0.5537 6.1186 \n",
      "chain:  1  iteration:  8750  parameters:  0.0363 0.2351 0.6597 6.4486 \n",
      "chain:  1  iteration:  8760  parameters:  0.0525 0.2588 0.6399 5.431 \n",
      "chain:  1  iteration:  8770  parameters:  0.0393 0.2935 0.6159 5.6653 \n",
      "chain:  1  iteration:  8780  parameters:  0.0367 0.2074 0.6991 5.8736 \n",
      "chain:  1  iteration:  8790  parameters:  0.0239 0.2075 0.7337 5.3723 \n",
      "chain:  1  iteration:  8800  parameters:  0.0251 0.2269 0.7169 5.3365 \n",
      "chain:  1  iteration:  8810  parameters:  0.0279 0.1965 0.7541 5.2398 \n",
      "chain:  1  iteration:  8820  parameters:  0.0226 0.1942 0.7719 5.4996 \n",
      "chain:  1  iteration:  8830  parameters:  0.0225 0.1884 0.7695 5.2078 \n",
      "chain:  1  iteration:  8840  parameters:  0.0216 0.187 0.7704 4.7358 \n",
      "chain:  1  iteration:  8850  parameters:  0.0259 0.1764 0.7783 4.5109 \n",
      "chain:  1  iteration:  8860  parameters:  0.0248 0.1814 0.7595 4.959 \n",
      "chain:  1  iteration:  8870  parameters:  0.0194 0.1797 0.7965 4.7842 \n",
      "chain:  1  iteration:  8880  parameters:  0.0193 0.1799 0.7653 5.4199 \n",
      "chain:  1  iteration:  8890  parameters:  0.0186 0.169 0.79 5.6044 \n",
      "chain:  1  iteration:  8900  parameters:  0.0248 0.1622 0.7704 6.3298 \n",
      "chain:  1  iteration:  8910  parameters:  0.0132 0.1725 0.8069 5.747 \n",
      "chain:  1  iteration:  8920  parameters:  0.0221 0.142 0.7954 6.6566 \n",
      "chain:  1  iteration:  8930  parameters:  0.0149 0.2056 0.7614 6.9413 \n",
      "chain:  1  iteration:  8940  parameters:  0.0207 0.1491 0.7808 8.7036 \n",
      "chain:  1  iteration:  8950  parameters:  0.0243 0.1966 0.7138 7.4269 \n",
      "chain:  1  iteration:  8960  parameters:  0.012 0.2257 0.7714 6.7375 \n",
      "chain:  1  iteration:  8970  parameters:  0.0263 0.2121 0.7226 5.8975 \n",
      "chain:  1  iteration:  8980  parameters:  0.0332 0.2399 0.6773 6.2957 \n",
      "chain:  1  iteration:  8990  parameters:  0.0288 0.2135 0.7305 6.9179 \n",
      "chain:  1  iteration:  9000  parameters:  0.0174 0.2636 0.7661 5.6978 \n",
      "chain:  1  iteration:  9010  parameters:  0.0421 0.1931 0.6593 5.9964 \n",
      "chain:  1  iteration:  9020  parameters:  0.035 0.2779 0.6804 6.2088 \n",
      "chain:  1  iteration:  9030  parameters:  0.029 0.1948 0.7401 5.9624 \n",
      "chain:  1  iteration:  9040  parameters:  0.0187 0.3054 0.6978 4.572 \n",
      "chain:  1  iteration:  9050  parameters:  0.0335 0.2939 0.6997 4.8151 \n",
      "chain:  1  iteration:  9060  parameters:  0.0236 0.2361 0.7227 5.1698 \n",
      "chain:  1  iteration:  9070  parameters:  0.0412 0.2808 0.6516 5.2518 \n",
      "chain:  1  iteration:  9080  parameters:  0.0371 0.2111 0.7048 5.0922 \n",
      "chain:  1  iteration:  9090  parameters:  0.019 0.2482 0.7109 6.6164 \n",
      "chain:  1  iteration:  9100  parameters:  0.0251 0.2787 0.7163 5.8146 \n",
      "chain:  1  iteration:  9110  parameters:  0.0376 0.2372 0.6919 4.8345 \n",
      "chain:  1  iteration:  9120  parameters:  0.0512 0.2954 0.5978 5.7572 \n",
      "chain:  1  iteration:  9130  parameters:  0.0372 0.2579 0.6374 6.2401 \n",
      "chain:  1  iteration:  9140  parameters:  0.0462 0.2445 0.62 5.7077 \n",
      "chain:  1  iteration:  9150  parameters:  0.0604 0.3003 0.556 5.4689 \n",
      "chain:  1  iteration:  9160  parameters:  0.0406 0.2549 0.6526 4.1845 \n",
      "chain:  1  iteration:  9170  parameters:  0.0523 0.3145 0.6648 3.8704 \n",
      "chain:  1  iteration:  9180  parameters:  0.0583 0.4742 0.5021 4.1092 \n",
      "chain:  1  iteration:  9190  parameters:  0.0766 0.4539 0.4784 4.0117 \n",
      "chain:  1  iteration:  9200  parameters:  0.0728 0.3835 0.4944 4.0582 \n",
      "chain:  1  iteration:  9210  parameters:  0.1037 0.4753 0.3871 3.8848 \n",
      "chain:  1  iteration:  9220  parameters:  0.0818 0.3992 0.5236 3.5847 \n",
      "chain:  1  iteration:  9230  parameters:  0.0675 0.4282 0.5806 3.4707 \n",
      "chain:  1  iteration:  9240  parameters:  0.0666 0.3567 0.5783 3.4962 \n",
      "chain:  1  iteration:  9250  parameters:  0.0627 0.5069 0.5987 3.3823 \n",
      "chain:  1  iteration:  9260  parameters:  0.0617 0.4134 0.5465 3.7223 \n",
      "chain:  1  iteration:  9270  parameters:  0.0478 0.3703 0.6275 3.4374 \n",
      "chain:  1  iteration:  9280  parameters:  0.0722 0.3232 0.5971 3.4821 \n",
      "chain:  1  iteration:  9290  parameters:  0.0586 0.4024 0.5445 3.8706 \n",
      "chain:  1  iteration:  9300  parameters:  0.0475 0.329 0.5886 4.0565 \n",
      "chain:  1  iteration:  9310  parameters:  0.0399 0.2296 0.6513 5.3024 \n",
      "chain:  1  iteration:  9320  parameters:  0.0289 0.3635 0.6298 5.6683 \n",
      "chain:  1  iteration:  9330  parameters:  0.0442 0.1895 0.637 5.5176 \n",
      "chain:  1  iteration:  9340  parameters:  0.0407 0.273 0.662 4.7028 \n",
      "chain:  1  iteration:  9350  parameters:  0.0345 0.3589 0.6379 4.7348 \n",
      "chain:  1  iteration:  9360  parameters:  0.0195 0.226 0.7128 5.2267 \n",
      "chain:  1  iteration:  9370  parameters:  0.0419 0.2221 0.6685 5.54 \n",
      "chain:  1  iteration:  9380  parameters:  0.0323 0.2808 0.6861 4.8038 \n",
      "chain:  1  iteration:  9390  parameters:  0.0388 0.2415 0.6881 4.4055 \n",
      "chain:  1  iteration:  9400  parameters:  0.0358 0.2734 0.6597 5.2386 \n",
      "chain:  1  iteration:  9410  parameters:  0.0232 0.1901 0.7647 4.789 \n",
      "chain:  1  iteration:  9420  parameters:  0.0234 0.2239 0.7268 5.4123 \n",
      "chain:  1  iteration:  9430  parameters:  0.0153 0.3137 0.7136 5.5833 \n",
      "chain:  1  iteration:  9440  parameters:  0.0292 0.2521 0.685 5.4417 \n",
      "chain:  1  iteration:  9450  parameters:  0.0697 0.2907 0.5376 5.3046 \n",
      "chain:  1  iteration:  9460  parameters:  0.0322 0.2831 0.6809 5.2594 \n",
      "chain:  1  iteration:  9470  parameters:  0.0352 0.195 0.7144 6.0685 \n",
      "chain:  1  iteration:  9480  parameters:  0.0539 0.2853 0.5637 6.1742 \n",
      "chain:  1  iteration:  9490  parameters:  0.0393 0.2878 0.6187 6.1426 \n",
      "chain:  1  iteration:  9500  parameters:  0.0283 0.2539 0.6896 5.7032 \n",
      "chain:  1  iteration:  9510  parameters:  0.0359 0.4198 0.6121 4.2138 \n",
      "chain:  1  iteration:  9520  parameters:  0.0484 0.321 0.6404 4.1664 \n",
      "chain:  1  iteration:  9530  parameters:  0.0599 0.2014 0.6827 4.0446 \n",
      "chain:  1  iteration:  9540  parameters:  0.0337 0.2468 0.6622 4.891 \n",
      "chain:  1  iteration:  9550  parameters:  0.045 0.3025 0.6338 4.2793 \n",
      "chain:  1  iteration:  9560  parameters:  0.0662 0.3187 0.5568 4.3341 \n",
      "chain:  1  iteration:  9570  parameters:  0.0578 0.2825 0.5684 4.7248 \n",
      "chain:  1  iteration:  9580  parameters:  0.0537 0.3334 0.585 4.1009 \n",
      "chain:  1  iteration:  9590  parameters:  0.056 0.2373 0.6518 4.5203 \n",
      "chain:  1  iteration:  9600  parameters:  0.042 0.3101 0.6381 4.8488 \n",
      "chain:  1  iteration:  9610  parameters:  0.0378 0.2387 0.6904 4.9565 \n",
      "chain:  1  iteration:  9620  parameters:  0.0369 0.2962 0.6142 5.7382 \n",
      "chain:  1  iteration:  9630  parameters:  0.0269 0.2398 0.6973 6.4791 \n",
      "chain:  1  iteration:  9640  parameters:  0.0336 0.1527 0.7348 5.7083 \n",
      "chain:  1  iteration:  9650  parameters:  0.0286 0.2516 0.6844 6.3278 \n",
      "chain:  1  iteration:  9660  parameters:  0.0252 0.3114 0.6668 6.1006 \n",
      "chain:  1  iteration:  9670  parameters:  0.018 0.2881 0.7083 5.2672 \n",
      "chain:  1  iteration:  9680  parameters:  0.0232 0.1599 0.7868 5.482 \n",
      "chain:  1  iteration:  9690  parameters:  0.028 0.2032 0.7203 6.0008 \n",
      "chain:  1  iteration:  9700  parameters:  0.0295 0.2341 0.6754 5.5283 \n",
      "chain:  1  iteration:  9710  parameters:  0.0322 0.2491 0.6975 5.3577 \n",
      "chain:  1  iteration:  9720  parameters:  0.0335 0.1976 0.7026 5.7554 \n",
      "chain:  1  iteration:  9730  parameters:  0.0176 0.2329 0.7584 6.1731 \n",
      "chain:  1  iteration:  9740  parameters:  0.0318 0.1758 0.7614 5.3688 \n",
      "chain:  1  iteration:  9750  parameters:  0.0271 0.1358 0.777 6.1179 \n",
      "chain:  1  iteration:  9760  parameters:  0.0214 0.1879 0.7652 9.119 \n",
      "chain:  1  iteration:  9770  parameters:  0.0297 0.189 0.7348 8.7893 \n",
      "chain:  1  iteration:  9780  parameters:  0.0262 0.1392 0.7671 8.6316 \n",
      "chain:  1  iteration:  9790  parameters:  0.0181 0.1925 0.763 8.4251 \n",
      "chain:  1  iteration:  9800  parameters:  0.0244 0.1616 0.7555 5.6711 \n",
      "chain:  1  iteration:  9810  parameters:  0.0334 0.1455 0.7539 5.4876 \n",
      "chain:  1  iteration:  9820  parameters:  0.0224 0.1813 0.7573 5.6882 \n",
      "chain:  1  iteration:  9830  parameters:  0.028 0.2213 0.7235 5.1154 \n",
      "chain:  1  iteration:  9840  parameters:  0.0278 0.1182 0.7993 5.5643 \n",
      "chain:  1  iteration:  9850  parameters:  0.0144 0.1977 0.7865 5.6009 \n",
      "chain:  1  iteration:  9860  parameters:  0.0265 0.1735 0.7591 5.1457 \n",
      "chain:  1  iteration:  9870  parameters:  0.0189 0.1951 0.7914 4.7597 \n",
      "chain:  1  iteration:  9880  parameters:  0.0169 0.1949 0.7873 4.2624 \n",
      "chain:  1  iteration:  9890  parameters:  0.0226 0.245 0.7208 5.1037 \n",
      "chain:  1  iteration:  9900  parameters:  0.0268 0.161 0.7445 6.192 \n",
      "chain:  1  iteration:  9910  parameters:  0.0406 0.2093 0.6736 5.9338 \n",
      "chain:  1  iteration:  9920  parameters:  0.0258 0.218 0.7237 5.7828 \n",
      "chain:  1  iteration:  9930  parameters:  0.0382 0.2728 0.6273 4.7727 \n",
      "chain:  1  iteration:  9940  parameters:  0.0319 0.2455 0.6566 5.4456 \n",
      "chain:  1  iteration:  9950  parameters:  0.0338 0.3186 0.6234 4.9784 \n",
      "chain:  1  iteration:  9960  parameters:  0.0376 0.2719 0.6319 5.3995 \n",
      "chain:  1  iteration:  9970  parameters:  0.0347 0.2624 0.6413 6.2071 \n",
      "chain:  1  iteration:  9980  parameters:  0.0431 0.3145 0.5939 5.6452 \n",
      "chain:  1  iteration:  9990  parameters:  0.0472 0.3898 0.4832 5.794 \n",
      "chain:  1  iteration:  10000  parameters:  0.0977 0.4243 0.457 4.3322 \n",
      "chain:  2  iteration:  10  parameters:  0.0589 0.2131 0.596 92.6761 \n",
      "chain:  2  iteration:  20  parameters:  0.0418 0.2926 0.614 82.6877 \n",
      "chain:  2  iteration:  30  parameters:  0.0416 0.2544 0.6234 84.2676 \n",
      "chain:  2  iteration:  40  parameters:  0.0625 0.3058 0.5158 141.5748 \n",
      "chain:  2  iteration:  50  parameters:  0.0686 0.2465 0.551 119.2904 \n",
      "chain:  2  iteration:  60  parameters:  0.039 0.1755 0.7136 119.792 \n",
      "chain:  2  iteration:  70  parameters:  0.0326 0.1303 0.7673 91.7152 \n",
      "chain:  2  iteration:  80  parameters:  0.0486 0.2544 0.5895 82.201 \n",
      "chain:  2  iteration:  90  parameters:  0.0637 0.2241 0.5756 101.0469 \n",
      "chain:  2  iteration:  100  parameters:  0.0661 0.2343 0.5371 97.86 \n",
      "chain:  2  iteration:  110  parameters:  0.0656 0.2972 0.5374 122.3351 \n",
      "chain:  2  iteration:  120  parameters:  0.0408 0.2205 0.6448 128.7884 \n",
      "chain:  2  iteration:  130  parameters:  0.0421 0.2483 0.6152 117.9373 \n",
      "chain:  2  iteration:  140  parameters:  0.0494 0.2207 0.6285 104.7946 \n",
      "chain:  2  iteration:  150  parameters:  0.0553 0.2928 0.5457 96.1164 \n",
      "chain:  2  iteration:  160  parameters:  0.0344 0.3505 0.6067 129.9209 \n",
      "chain:  2  iteration:  170  parameters:  0.0533 0.2033 0.6145 114.8942 \n",
      "chain:  2  iteration:  180  parameters:  0.0534 0.227 0.5976 119.114 \n",
      "chain:  2  iteration:  190  parameters:  0.0427 0.2322 0.6632 98.4489 \n",
      "chain:  2  iteration:  200  parameters:  0.0487 0.2003 0.6737 86.3415 \n",
      "chain:  2  iteration:  210  parameters:  0.0406 0.2294 0.6479 117.0647 \n",
      "chain:  2  iteration:  220  parameters:  0.049 0.2281 0.6061 87.4321 \n",
      "chain:  2  iteration:  230  parameters:  0.0425 0.2037 0.656 61.8616 \n",
      "chain:  2  iteration:  240  parameters:  0.0332 0.2098 0.7043 45.2241 \n",
      "chain:  2  iteration:  250  parameters:  0.0277 0.1641 0.7325 27.2493 \n",
      "chain:  2  iteration:  260  parameters:  0.0315 0.1347 0.7526 23.1343 \n",
      "chain:  2  iteration:  270  parameters:  0.0326 0.1775 0.7222 20.1319 \n",
      "chain:  2  iteration:  280  parameters:  0.0297 0.1608 0.7383 15.8846 \n",
      "chain:  2  iteration:  290  parameters:  0.034 0.1989 0.696 16.7964 \n",
      "chain:  2  iteration:  300  parameters:  0.0245 0.257 0.6942 12.1157 \n",
      "chain:  2  iteration:  310  parameters:  0.0374 0.0962 0.7617 16.704 \n",
      "chain:  2  iteration:  320  parameters:  0.0227 0.2155 0.7416 14.4266 \n",
      "chain:  2  iteration:  330  parameters:  0.0323 0.1919 0.6942 11.3641 \n",
      "chain:  2  iteration:  340  parameters:  0.0378 0.197 0.6732 14.1647 \n",
      "chain:  2  iteration:  350  parameters:  0.0261 0.2228 0.732 14.2566 \n",
      "chain:  2  iteration:  360  parameters:  0.0225 0.1227 0.8106 13.048 \n",
      "chain:  2  iteration:  370  parameters:  0.0332 0.2365 0.6791 12.2805 \n",
      "chain:  2  iteration:  380  parameters:  0.0208 0.1622 0.7466 8.1031 \n",
      "chain:  2  iteration:  390  parameters:  0.0325 0.1682 0.7277 7.8751 \n",
      "chain:  2  iteration:  400  parameters:  0.0265 0.1594 0.761 6.7805 \n",
      "chain:  2  iteration:  410  parameters:  0.0234 0.1749 0.7586 6.7357 \n",
      "chain:  2  iteration:  420  parameters:  0.0108 0.1837 0.7966 6.4222 \n",
      "chain:  2  iteration:  430  parameters:  0.0195 0.1741 0.7727 6.9892 \n",
      "chain:  2  iteration:  440  parameters:  0.0165 0.1804 0.7679 6.4952 \n",
      "chain:  2  iteration:  450  parameters:  0.0235 0.1354 0.796 6.5924 \n",
      "chain:  2  iteration:  460  parameters:  0.0345 0.1889 0.7173 6.0523 \n",
      "chain:  2  iteration:  470  parameters:  0.0314 0.1366 0.7564 5.6819 \n",
      "chain:  2  iteration:  480  parameters:  0.0206 0.1481 0.8132 4.7237 \n",
      "chain:  2  iteration:  490  parameters:  0.0142 0.1773 0.8075 4.3891 \n",
      "chain:  2  iteration:  500  parameters:  0.015 0.2051 0.8095 4.2091 \n",
      "chain:  2  iteration:  510  parameters:  0.0203 0.1257 0.8171 4.0665 \n",
      "chain:  2  iteration:  520  parameters:  0.0188 0.1399 0.8358 4.2906 \n",
      "chain:  2  iteration:  530  parameters:  0.0158 0.1553 0.8102 4.7797 \n",
      "chain:  2  iteration:  540  parameters:  0.0148 0.1883 0.7882 5.8914 \n",
      "chain:  2  iteration:  550  parameters:  0.0202 0.1807 0.7549 5.8722 \n",
      "chain:  2  iteration:  560  parameters:  0.0221 0.1996 0.7361 6.6189 \n",
      "chain:  2  iteration:  570  parameters:  0.018 0.1395 0.7877 7.7567 \n",
      "chain:  2  iteration:  580  parameters:  0.0252 0.1839 0.7422 7.406 \n",
      "chain:  2  iteration:  590  parameters:  0.0257 0.162 0.7664 6.4411 \n",
      "chain:  2  iteration:  600  parameters:  0.0292 0.1686 0.7726 5.6001 \n",
      "chain:  2  iteration:  610  parameters:  0.0193 0.1808 0.8009 5.0018 \n",
      "chain:  2  iteration:  620  parameters:  0.0193 0.1997 0.8013 4.454 \n",
      "chain:  2  iteration:  630  parameters:  0.0146 0.131 0.8198 5.5466 \n",
      "chain:  2  iteration:  640  parameters:  0.0199 0.1304 0.8286 5.3735 \n",
      "chain:  2  iteration:  650  parameters:  0.0206 0.1316 0.8172 4.6645 \n",
      "chain:  2  iteration:  660  parameters:  0.0129 0.1691 0.8002 5.4072 \n",
      "chain:  2  iteration:  670  parameters:  0.0218 0.1087 0.8247 5.2347 \n",
      "chain:  2  iteration:  680  parameters:  0.0169 0.1612 0.7942 6.0006 \n",
      "chain:  2  iteration:  690  parameters:  0.0321 0.1284 0.7395 6.2671 \n",
      "chain:  2  iteration:  700  parameters:  0.0259 0.2222 0.7079 6.5081 \n",
      "chain:  2  iteration:  710  parameters:  0.0366 0.2648 0.6417 6.42 \n",
      "chain:  2  iteration:  720  parameters:  0.0451 0.1851 0.694 7.4328 \n",
      "chain:  2  iteration:  730  parameters:  0.037 0.2494 0.6432 7.4729 \n",
      "chain:  2  iteration:  740  parameters:  0.0365 0.257 0.6394 6.9979 \n",
      "chain:  2  iteration:  750  parameters:  0.0488 0.34 0.5526 6.995 \n",
      "chain:  2  iteration:  760  parameters:  0.0397 0.2603 0.6497 5.4673 \n",
      "chain:  2  iteration:  770  parameters:  0.0335 0.2507 0.6662 4.9286 \n",
      "chain:  2  iteration:  780  parameters:  0.0399 0.236 0.6754 6.2783 \n",
      "chain:  2  iteration:  790  parameters:  0.0328 0.2682 0.6758 8.1078 \n",
      "chain:  2  iteration:  800  parameters:  0.0379 0.2768 0.6155 6.3995 \n",
      "chain:  2  iteration:  810  parameters:  0.0472 0.2946 0.5685 7.1726 \n",
      "chain:  2  iteration:  820  parameters:  0.0357 0.3304 0.6359 5.4832 \n",
      "chain:  2  iteration:  830  parameters:  0.0421 0.2486 0.6582 5.5362 \n",
      "chain:  2  iteration:  840  parameters:  0.03 0.2254 0.726 5.409 \n",
      "chain:  2  iteration:  850  parameters:  0.0445 0.2873 0.5576 5.6309 \n",
      "chain:  2  iteration:  860  parameters:  0.0262 0.2907 0.6679 6.2968 \n",
      "chain:  2  iteration:  870  parameters:  0.0278 0.1599 0.779 6.3237 \n",
      "chain:  2  iteration:  880  parameters:  0.0269 0.1755 0.7333 5.6372 \n",
      "chain:  2  iteration:  890  parameters:  0.0194 0.2219 0.7541 6.3035 \n",
      "chain:  2  iteration:  900  parameters:  0.0218 0.1482 0.781 5.5554 \n",
      "chain:  2  iteration:  910  parameters:  0.0279 0.1867 0.725 4.7037 \n",
      "chain:  2  iteration:  920  parameters:  0.0269 0.1727 0.774 4.7117 \n",
      "chain:  2  iteration:  930  parameters:  0.0109 0.2048 0.8069 5.226 \n",
      "chain:  2  iteration:  940  parameters:  0.0202 0.1098 0.8162 5.0107 \n",
      "chain:  2  iteration:  950  parameters:  0.014 0.212 0.8079 4.4865 \n",
      "chain:  2  iteration:  960  parameters:  0.0263 0.1927 0.7592 4.8047 \n",
      "chain:  2  iteration:  970  parameters:  0.0434 0.1727 0.6887 4.9163 \n",
      "chain:  2  iteration:  980  parameters:  0.0447 0.2718 0.6342 5.2404 \n",
      "chain:  2  iteration:  990  parameters:  0.0422 0.2092 0.6402 5.9463 \n",
      "chain:  2  iteration:  1000  parameters:  0.0467 0.31 0.5919 5.3502 \n",
      "chain:  2  iteration:  1010  parameters:  0.0449 0.3359 0.5992 4.9533 \n",
      "chain:  2  iteration:  1020  parameters:  0.0445 0.3221 0.5964 5.4183 \n",
      "chain:  2  iteration:  1030  parameters:  0.0354 0.2859 0.6504 4.9775 \n",
      "chain:  2  iteration:  1040  parameters:  0.0363 0.2638 0.6693 5.0008 \n",
      "chain:  2  iteration:  1050  parameters:  0.0364 0.3036 0.6487 4.373 \n",
      "chain:  2  iteration:  1060  parameters:  0.0401 0.2768 0.6376 5.3901 \n",
      "chain:  2  iteration:  1070  parameters:  0.0351 0.2648 0.6369 5.2258 \n",
      "chain:  2  iteration:  1080  parameters:  0.0445 0.2368 0.6594 5.7641 \n",
      "chain:  2  iteration:  1090  parameters:  0.0311 0.3531 0.6273 5.3229 \n",
      "chain:  2  iteration:  1100  parameters:  0.033 0.2878 0.6495 6.0905 \n",
      "chain:  2  iteration:  1110  parameters:  0.0485 0.206 0.6966 5.9844 \n",
      "chain:  2  iteration:  1120  parameters:  0.0436 0.2074 0.6655 5.6102 \n",
      "chain:  2  iteration:  1130  parameters:  0.0185 0.347 0.7054 4.3364 \n",
      "chain:  2  iteration:  1140  parameters:  0.0328 0.3076 0.6812 4.2185 \n",
      "chain:  2  iteration:  1150  parameters:  0.0281 0.2352 0.7228 4.3393 \n",
      "chain:  2  iteration:  1160  parameters:  0.0294 0.1697 0.7543 4.7211 \n",
      "chain:  2  iteration:  1170  parameters:  0.026 0.1944 0.7731 4.4219 \n",
      "chain:  2  iteration:  1180  parameters:  0.0289 0.1751 0.7448 5.8394 \n",
      "chain:  2  iteration:  1190  parameters:  0.0327 0.2433 0.6738 6.2701 \n",
      "chain:  2  iteration:  1200  parameters:  0.0451 0.3084 0.5841 6.3109 \n",
      "chain:  2  iteration:  1210  parameters:  0.0519 0.2593 0.5771 5.5354 \n",
      "chain:  2  iteration:  1220  parameters:  0.0754 0.3332 0.4728 5.8657 \n",
      "chain:  2  iteration:  1230  parameters:  0.0587 0.3336 0.5344 6.077 \n",
      "chain:  2  iteration:  1240  parameters:  0.0469 0.3053 0.5797 6.6115 \n",
      "chain:  2  iteration:  1250  parameters:  0.0328 0.271 0.6367 7.4341 \n",
      "chain:  2  iteration:  1260  parameters:  0.0362 0.1608 0.7301 6.3951 \n",
      "chain:  2  iteration:  1270  parameters:  0.0194 0.1499 0.801 6.4626 \n",
      "chain:  2  iteration:  1280  parameters:  0.0262 0.1705 0.7407 6.8158 \n",
      "chain:  2  iteration:  1290  parameters:  0.0226 0.1695 0.7659 6.2334 \n",
      "chain:  2  iteration:  1300  parameters:  0.0352 0.1797 0.7169 6.3061 \n",
      "chain:  2  iteration:  1310  parameters:  0.0218 0.1715 0.7671 6.3835 \n",
      "chain:  2  iteration:  1320  parameters:  0.0214 0.164 0.7761 5.2205 \n",
      "chain:  2  iteration:  1330  parameters:  0.0111 0.2639 0.7738 5.8638 \n",
      "chain:  2  iteration:  1340  parameters:  0.019 0.23 0.7476 5.3804 \n",
      "chain:  2  iteration:  1350  parameters:  0.0244 0.2037 0.7317 5.0233 \n",
      "chain:  2  iteration:  1360  parameters:  0.0242 0.1551 0.7662 4.5619 \n",
      "chain:  2  iteration:  1370  parameters:  0.0203 0.2638 0.716 4.854 \n",
      "chain:  2  iteration:  1380  parameters:  0.0187 0.2831 0.7216 5.0536 \n",
      "chain:  2  iteration:  1390  parameters:  0.0408 0.2405 0.6478 7.499 \n",
      "chain:  2  iteration:  1400  parameters:  0.0283 0.1852 0.7101 9.906 \n",
      "chain:  2  iteration:  1410  parameters:  0.035 0.2904 0.6203 12.2413 \n",
      "chain:  2  iteration:  1420  parameters:  0.0259 0.2904 0.6723 14.9157 \n",
      "chain:  2  iteration:  1430  parameters:  0.0393 0.2323 0.6519 12.2179 \n",
      "chain:  2  iteration:  1440  parameters:  0.0389 0.2147 0.6644 9.6314 \n",
      "chain:  2  iteration:  1450  parameters:  0.052 0.2334 0.6213 8.0216 \n",
      "chain:  2  iteration:  1460  parameters:  0.0323 0.2269 0.6848 8.5892 \n",
      "chain:  2  iteration:  1470  parameters:  0.0345 0.2177 0.6773 7.1113 \n",
      "chain:  2  iteration:  1480  parameters:  0.0223 0.2306 0.7027 6.7196 \n",
      "chain:  2  iteration:  1490  parameters:  0.0313 0.2724 0.6468 6.7865 \n",
      "chain:  2  iteration:  1500  parameters:  0.0446 0.2359 0.6639 5.5184 \n",
      "chain:  2  iteration:  1510  parameters:  0.0741 0.3461 0.517 4.7366 \n",
      "chain:  2  iteration:  1520  parameters:  0.0429 0.3037 0.6294 5.9219 \n",
      "chain:  2  iteration:  1530  parameters:  0.0508 0.2719 0.5893 6.6961 \n",
      "chain:  2  iteration:  1540  parameters:  0.0669 0.3751 0.4653 5.4756 \n",
      "chain:  2  iteration:  1550  parameters:  0.0668 0.396 0.522 5.2271 \n",
      "chain:  2  iteration:  1560  parameters:  0.0745 0.3318 0.5221 4.8368 \n",
      "chain:  2  iteration:  1570  parameters:  0.0608 0.3399 0.5583 5.3648 \n",
      "chain:  2  iteration:  1580  parameters:  0.0426 0.291 0.6146 4.7334 \n",
      "chain:  2  iteration:  1590  parameters:  0.0288 0.2481 0.6973 4.8969 \n",
      "chain:  2  iteration:  1600  parameters:  0.0362 0.2629 0.6602 5.507 \n",
      "chain:  2  iteration:  1610  parameters:  0.0476 0.234 0.6221 6.3793 \n",
      "chain:  2  iteration:  1620  parameters:  0.0282 0.2065 0.7492 6.5177 \n",
      "chain:  2  iteration:  1630  parameters:  0.0214 0.2126 0.7379 7.0522 \n",
      "chain:  2  iteration:  1640  parameters:  0.0253 0.1786 0.7418 6.991 \n",
      "chain:  2  iteration:  1650  parameters:  0.023 0.2448 0.7106 5.5371 \n",
      "chain:  2  iteration:  1660  parameters:  0.026 0.1751 0.7715 5.003 \n",
      "chain:  2  iteration:  1670  parameters:  0.0295 0.1938 0.7 5.5072 \n",
      "chain:  2  iteration:  1680  parameters:  0.0354 0.2178 0.7037 5.3385 \n",
      "chain:  2  iteration:  1690  parameters:  0.0274 0.2485 0.724 4.8682 \n",
      "chain:  2  iteration:  1700  parameters:  0.0229 0.2542 0.7404 3.855 \n",
      "chain:  2  iteration:  1710  parameters:  0.0305 0.2585 0.7047 4.4448 \n",
      "chain:  2  iteration:  1720  parameters:  0.0262 0.2208 0.7078 5.0755 \n",
      "chain:  2  iteration:  1730  parameters:  0.0303 0.1623 0.7611 7.0918 \n",
      "chain:  2  iteration:  1740  parameters:  0.0149 0.1709 0.7951 7.2462 \n",
      "chain:  2  iteration:  1750  parameters:  0.015 0.1193 0.8384 7.346 \n",
      "chain:  2  iteration:  1760  parameters:  0.0097 0.1602 0.8269 7.4871 \n",
      "chain:  2  iteration:  1770  parameters:  0.021 0.1211 0.8057 8.101 \n",
      "chain:  2  iteration:  1780  parameters:  0.0154 0.1214 0.8348 6.7147 \n",
      "chain:  2  iteration:  1790  parameters:  0.0147 0.1041 0.8432 6.3731 \n",
      "chain:  2  iteration:  1800  parameters:  0.0141 0.1008 0.8649 5.9666 \n",
      "chain:  2  iteration:  1810  parameters:  0.0052 0.0951 0.9001 5.5702 \n",
      "chain:  2  iteration:  1820  parameters:  0.0081 0.1017 0.8693 5.2359 \n",
      "chain:  2  iteration:  1830  parameters:  0.0077 0.1362 0.867 5.6789 \n",
      "chain:  2  iteration:  1840  parameters:  0.0114 0.1533 0.8326 4.4435 \n",
      "chain:  2  iteration:  1850  parameters:  0.0169 0.1037 0.8372 4.5683 \n",
      "chain:  2  iteration:  1860  parameters:  0.0176 0.1373 0.849 4.0232 \n",
      "chain:  2  iteration:  1870  parameters:  0.0276 0.1851 0.7558 4.2038 \n",
      "chain:  2  iteration:  1880  parameters:  0.0237 0.2336 0.7417 4.1168 \n",
      "chain:  2  iteration:  1890  parameters:  0.031 0.2421 0.7546 3.3495 \n",
      "chain:  2  iteration:  1900  parameters:  0.0367 0.2351 0.7146 3.7222 \n",
      "chain:  2  iteration:  1910  parameters:  0.0312 0.2578 0.7185 3.9304 \n",
      "chain:  2  iteration:  1920  parameters:  0.0272 0.1652 0.7817 4.215 \n",
      "chain:  2  iteration:  1930  parameters:  0.0237 0.2188 0.7733 3.7707 \n",
      "chain:  2  iteration:  1940  parameters:  0.0325 0.333 0.6992 3.6508 \n",
      "chain:  2  iteration:  1950  parameters:  0.0237 0.2251 0.772 3.9035 \n",
      "chain:  2  iteration:  1960  parameters:  0.031 0.2227 0.7073 4.0035 \n",
      "chain:  2  iteration:  1970  parameters:  0.056 0.3066 0.5406 4.6916 \n",
      "chain:  2  iteration:  1980  parameters:  0.0325 0.367 0.6138 4.6273 \n",
      "chain:  2  iteration:  1990  parameters:  0.047 0.3492 0.5536 4.9787 \n",
      "chain:  2  iteration:  2000  parameters:  0.0438 0.3318 0.6743 4.4444 \n",
      "chain:  2  iteration:  2010  parameters:  0.0341 0.2936 0.6559 5.0288 \n",
      "chain:  2  iteration:  2020  parameters:  0.0415 0.236 0.6403 5.547 \n",
      "chain:  2  iteration:  2030  parameters:  0.0511 0.3232 0.5944 5.3676 \n",
      "chain:  2  iteration:  2040  parameters:  0.0353 0.2724 0.6121 6.9994 \n",
      "chain:  2  iteration:  2050  parameters:  0.0264 0.2181 0.7173 5.6796 \n",
      "chain:  2  iteration:  2060  parameters:  0.016 0.2389 0.7757 5.411 \n",
      "chain:  2  iteration:  2070  parameters:  0.0251 0.1891 0.7309 6.5031 \n",
      "chain:  2  iteration:  2080  parameters:  0.0389 0.2592 0.6451 5.3963 \n",
      "chain:  2  iteration:  2090  parameters:  0.0482 0.3206 0.5803 5.7729 \n",
      "chain:  2  iteration:  2100  parameters:  0.0496 0.3646 0.5633 5.89 \n",
      "chain:  2  iteration:  2110  parameters:  0.0326 0.2233 0.6961 5.2099 \n",
      "chain:  2  iteration:  2120  parameters:  0.0394 0.2625 0.649 5.317 \n",
      "chain:  2  iteration:  2130  parameters:  0.0511 0.2567 0.5987 5.4295 \n",
      "chain:  2  iteration:  2140  parameters:  0.0401 0.3916 0.6115 4.7458 \n",
      "chain:  2  iteration:  2150  parameters:  0.0409 0.4429 0.647 4.2586 \n",
      "chain:  2  iteration:  2160  parameters:  0.0471 0.2671 0.6311 4.753 \n",
      "chain:  2  iteration:  2170  parameters:  0.0455 0.2608 0.6231 4.6725 \n",
      "chain:  2  iteration:  2180  parameters:  0.0515 0.3204 0.6074 4.877 \n",
      "chain:  2  iteration:  2190  parameters:  0.0473 0.2841 0.643 5.6768 \n",
      "chain:  2  iteration:  2200  parameters:  0.041 0.2496 0.6531 6.0358 \n",
      "chain:  2  iteration:  2210  parameters:  0.0194 0.2366 0.7515 5.3715 \n",
      "chain:  2  iteration:  2220  parameters:  0.0425 0.2381 0.6637 4.7329 \n",
      "chain:  2  iteration:  2230  parameters:  0.0456 0.2488 0.6519 4.1833 \n",
      "chain:  2  iteration:  2240  parameters:  0.0374 0.2603 0.6862 3.9804 \n",
      "chain:  2  iteration:  2250  parameters:  0.0388 0.2803 0.6725 4.5615 \n",
      "chain:  2  iteration:  2260  parameters:  0.0408 0.347 0.6565 4.2539 \n",
      "chain:  2  iteration:  2270  parameters:  0.0325 0.3106 0.7038 4.3634 \n",
      "chain:  2  iteration:  2280  parameters:  0.0396 0.2032 0.6759 4.9293 \n",
      "chain:  2  iteration:  2290  parameters:  0.0267 0.2127 0.7325 5.0454 \n",
      "chain:  2  iteration:  2300  parameters:  0.0139 0.2344 0.7293 5.8827 \n",
      "chain:  2  iteration:  2310  parameters:  0.0153 0.2777 0.7161 4.5557 \n",
      "chain:  2  iteration:  2320  parameters:  0.0423 0.1629 0.709 5.3524 \n",
      "chain:  2  iteration:  2330  parameters:  0.0264 0.2204 0.7341 5.7303 \n",
      "chain:  2  iteration:  2340  parameters:  0.045 0.2493 0.6346 4.8322 \n",
      "chain:  2  iteration:  2350  parameters:  0.052 0.2117 0.6614 4.9741 \n",
      "chain:  2  iteration:  2360  parameters:  0.0372 0.2804 0.6315 5.1556 \n",
      "chain:  2  iteration:  2370  parameters:  0.0643 0.3628 0.5085 4.9978 \n",
      "chain:  2  iteration:  2380  parameters:  0.0526 0.3259 0.5852 6.0959 \n",
      "chain:  2  iteration:  2390  parameters:  0.0565 0.2305 0.5983 5.0398 \n",
      "chain:  2  iteration:  2400  parameters:  0.051 0.3274 0.5948 4.724 \n",
      "chain:  2  iteration:  2410  parameters:  0.0795 0.3524 0.4192 4.8182 \n",
      "chain:  2  iteration:  2420  parameters:  0.0704 0.4167 0.4867 5.0884 \n",
      "chain:  2  iteration:  2430  parameters:  0.0624 0.4535 0.4633 5.0482 \n",
      "chain:  2  iteration:  2440  parameters:  0.0654 0.4088 0.517 5.3947 \n",
      "chain:  2  iteration:  2450  parameters:  0.0615 0.2583 0.5643 5.2714 \n",
      "chain:  2  iteration:  2460  parameters:  0.0472 0.3118 0.5941 5.5512 \n",
      "chain:  2  iteration:  2470  parameters:  0.058 0.3532 0.5353 5.4392 \n",
      "chain:  2  iteration:  2480  parameters:  0.0582 0.2431 0.5954 5.4371 \n",
      "chain:  2  iteration:  2490  parameters:  0.0453 0.2401 0.6511 4.5906 \n",
      "chain:  2  iteration:  2500  parameters:  0.0386 0.2605 0.6564 4.3303 \n",
      "chain:  2  iteration:  2510  parameters:  0.0328 0.235 0.7292 3.903 \n",
      "chain:  2  iteration:  2520  parameters:  0.0234 0.2495 0.7336 4.0792 \n",
      "chain:  2  iteration:  2530  parameters:  0.0322 0.248 0.7358 4.0383 \n",
      "chain:  2  iteration:  2540  parameters:  0.0316 0.1982 0.7243 4.2263 \n",
      "chain:  2  iteration:  2550  parameters:  0.0349 0.2507 0.7014 3.8125 \n",
      "chain:  2  iteration:  2560  parameters:  0.0277 0.3106 0.7151 3.7273 \n",
      "chain:  2  iteration:  2570  parameters:  0.0488 0.3044 0.6459 3.6773 \n",
      "chain:  2  iteration:  2580  parameters:  0.027 0.3829 0.7104 3.5485 \n",
      "chain:  2  iteration:  2590  parameters:  0.065 0.2648 0.6541 3.432 \n",
      "chain:  2  iteration:  2600  parameters:  0.0335 0.4584 0.6244 4.1619 \n",
      "chain:  2  iteration:  2610  parameters:  0.0409 0.328 0.6365 4.107 \n",
      "chain:  2  iteration:  2620  parameters:  0.0422 0.2482 0.7011 4.6125 \n",
      "chain:  2  iteration:  2630  parameters:  0.029 0.1788 0.753 4.8767 \n",
      "chain:  2  iteration:  2640  parameters:  0.0261 0.2785 0.7032 4.4701 \n",
      "chain:  2  iteration:  2650  parameters:  0.0418 0.2418 0.6685 4.4121 \n",
      "chain:  2  iteration:  2660  parameters:  0.0184 0.2517 0.7628 4.8982 \n",
      "chain:  2  iteration:  2670  parameters:  0.0187 0.1617 0.7593 5.261 \n",
      "chain:  2  iteration:  2680  parameters:  0.0324 0.225 0.6999 7.8344 \n",
      "chain:  2  iteration:  2690  parameters:  0.0286 0.3129 0.6331 9.4554 \n",
      "chain:  2  iteration:  2700  parameters:  0.0321 0.2605 0.6538 9.6549 \n",
      "chain:  2  iteration:  2710  parameters:  0.025 0.2866 0.6834 8.8718 \n",
      "chain:  2  iteration:  2720  parameters:  0.0305 0.2396 0.6949 7.441 \n",
      "chain:  2  iteration:  2730  parameters:  0.0358 0.3516 0.5995 9.5245 \n",
      "chain:  2  iteration:  2740  parameters:  0.0337 0.2248 0.621 8.9597 \n",
      "chain:  2  iteration:  2750  parameters:  0.0271 0.2864 0.6754 11.3904 \n",
      "chain:  2  iteration:  2760  parameters:  0.0274 0.1899 0.7168 12.5156 \n",
      "chain:  2  iteration:  2770  parameters:  0.0293 0.1879 0.7154 9.0319 \n",
      "chain:  2  iteration:  2780  parameters:  0.0269 0.1956 0.7241 8.3898 \n",
      "chain:  2  iteration:  2790  parameters:  0.0258 0.2049 0.7277 7.7654 \n",
      "chain:  2  iteration:  2800  parameters:  0.0259 0.1778 0.7391 7.9159 \n",
      "chain:  2  iteration:  2810  parameters:  0.0391 0.1908 0.692 8.7865 \n",
      "chain:  2  iteration:  2820  parameters:  0.0263 0.2115 0.699 8.1612 \n",
      "chain:  2  iteration:  2830  parameters:  0.0221 0.2208 0.7104 9.8164 \n",
      "chain:  2  iteration:  2840  parameters:  0.0305 0.2386 0.6435 7.1927 \n",
      "chain:  2  iteration:  2850  parameters:  0.0373 0.2014 0.649 8.2824 \n",
      "chain:  2  iteration:  2860  parameters:  0.0405 0.3103 0.5919 6.7946 \n",
      "chain:  2  iteration:  2870  parameters:  0.0663 0.2744 0.584 5.7767 \n",
      "chain:  2  iteration:  2880  parameters:  0.0359 0.3077 0.6165 5.7513 \n",
      "chain:  2  iteration:  2890  parameters:  0.0435 0.195 0.6926 5.0211 \n",
      "chain:  2  iteration:  2900  parameters:  0.0322 0.2535 0.6825 5.0929 \n",
      "chain:  2  iteration:  2910  parameters:  0.0473 0.2683 0.6199 6.1223 \n",
      "chain:  2  iteration:  2920  parameters:  0.038 0.2857 0.65 6.1601 \n",
      "chain:  2  iteration:  2930  parameters:  0.0498 0.2596 0.6042 7.9371 \n",
      "chain:  2  iteration:  2940  parameters:  0.0437 0.2173 0.6775 6.1747 \n",
      "chain:  2  iteration:  2950  parameters:  0.0443 0.1756 0.6719 7.8887 \n",
      "chain:  2  iteration:  2960  parameters:  0.0431 0.3155 0.6214 5.3654 \n",
      "chain:  2  iteration:  2970  parameters:  0.0666 0.3269 0.5511 5.3909 \n",
      "chain:  2  iteration:  2980  parameters:  0.0333 0.2873 0.6709 4.8426 \n",
      "chain:  2  iteration:  2990  parameters:  0.04 0.3218 0.5918 5.1713 \n",
      "chain:  2  iteration:  3000  parameters:  0.0588 0.3796 0.5539 4.7265 \n",
      "chain:  2  iteration:  3010  parameters:  0.0553 0.3127 0.5691 4.6396 \n",
      "chain:  2  iteration:  3020  parameters:  0.0506 0.3154 0.5861 4.4747 \n",
      "chain:  2  iteration:  3030  parameters:  0.0562 0.3567 0.5419 4.7636 \n",
      "chain:  2  iteration:  3040  parameters:  0.0563 0.3354 0.5524 4.5836 \n",
      "chain:  2  iteration:  3050  parameters:  0.0434 0.3583 0.6055 4.3654 \n",
      "chain:  2  iteration:  3060  parameters:  0.0538 0.2566 0.6679 4.0277 \n",
      "chain:  2  iteration:  3070  parameters:  0.0267 0.2551 0.7236 4.4721 \n",
      "chain:  2  iteration:  3080  parameters:  0.0415 0.2322 0.6605 4.8042 \n",
      "chain:  2  iteration:  3090  parameters:  0.0405 0.289 0.6626 5.2238 \n",
      "chain:  2  iteration:  3100  parameters:  0.0589 0.2383 0.6205 4.7996 \n",
      "chain:  2  iteration:  3110  parameters:  0.0394 0.2837 0.6209 5.3461 \n",
      "chain:  2  iteration:  3120  parameters:  0.0331 0.2871 0.658 4.3475 \n",
      "chain:  2  iteration:  3130  parameters:  0.0476 0.2565 0.6541 4.574 \n",
      "chain:  2  iteration:  3140  parameters:  0.0399 0.2941 0.7234 4.3264 \n",
      "chain:  2  iteration:  3150  parameters:  0.0341 0.2405 0.6947 4.219 \n",
      "chain:  2  iteration:  3160  parameters:  0.0322 0.2178 0.6974 5.1958 \n",
      "chain:  2  iteration:  3170  parameters:  0.024 0.1865 0.7438 5.554 \n",
      "chain:  2  iteration:  3180  parameters:  0.0226 0.1851 0.7636 6.1752 \n",
      "chain:  2  iteration:  3190  parameters:  0.0243 0.2101 0.7693 4.9467 \n",
      "chain:  2  iteration:  3200  parameters:  0.0205 0.2867 0.7507 4.4549 \n",
      "chain:  2  iteration:  3210  parameters:  0.0271 0.2716 0.6826 5.2398 \n",
      "chain:  2  iteration:  3220  parameters:  0.0468 0.1769 0.7078 4.6999 \n",
      "chain:  2  iteration:  3230  parameters:  0.0353 0.2158 0.7178 3.9478 \n",
      "chain:  2  iteration:  3240  parameters:  0.0262 0.2674 0.7373 3.9293 \n",
      "chain:  2  iteration:  3250  parameters:  0.0217 0.2388 0.7705 4.2219 \n",
      "chain:  2  iteration:  3260  parameters:  0.0219 0.196 0.7977 4.7569 \n",
      "chain:  2  iteration:  3270  parameters:  0.0247 0.1101 0.8201 5.0421 \n",
      "chain:  2  iteration:  3280  parameters:  0.0129 0.1769 0.8074 4.8436 \n",
      "chain:  2  iteration:  3290  parameters:  0.0133 0.1725 0.828 5.0691 \n",
      "chain:  2  iteration:  3300  parameters:  0.0188 0.1802 0.8038 4.6067 \n",
      "chain:  2  iteration:  3310  parameters:  0.0197 0.1717 0.7701 5.6913 \n",
      "chain:  2  iteration:  3320  parameters:  0.0287 0.182 0.756 5.9315 \n",
      "chain:  2  iteration:  3330  parameters:  0.0238 0.214 0.7359 5.5756 \n",
      "chain:  2  iteration:  3340  parameters:  0.0261 0.1718 0.7558 5.7013 \n",
      "chain:  2  iteration:  3350  parameters:  0.0253 0.2023 0.7397 6.5149 \n",
      "chain:  2  iteration:  3360  parameters:  0.0246 0.1904 0.7248 6.6018 \n",
      "chain:  2  iteration:  3370  parameters:  0.0175 0.1909 0.7723 7.3198 \n",
      "chain:  2  iteration:  3380  parameters:  0.0161 0.1483 0.8021 7.9769 \n",
      "chain:  2  iteration:  3390  parameters:  0.0181 0.1539 0.7981 8.8193 \n",
      "chain:  2  iteration:  3400  parameters:  0.0197 0.1344 0.8035 7.136 \n",
      "chain:  2  iteration:  3410  parameters:  0.0207 0.1533 0.7764 6.8919 \n",
      "chain:  2  iteration:  3420  parameters:  0.0194 0.1576 0.8011 6.1429 \n",
      "chain:  2  iteration:  3430  parameters:  0.0325 0.2169 0.691 6.1091 \n",
      "chain:  2  iteration:  3440  parameters:  0.026 0.1843 0.7598 4.4892 \n",
      "chain:  2  iteration:  3450  parameters:  0.023 0.2191 0.742 5.0853 \n",
      "chain:  2  iteration:  3460  parameters:  0.0322 0.2234 0.72 5.4563 \n",
      "chain:  2  iteration:  3470  parameters:  0.0382 0.1562 0.753 4.6996 \n",
      "chain:  2  iteration:  3480  parameters:  0.014 0.2255 0.7526 5.609 \n",
      "chain:  2  iteration:  3490  parameters:  0.0315 0.1772 0.7537 5.0601 \n",
      "chain:  2  iteration:  3500  parameters:  0.0199 0.1792 0.7945 4.3095 \n",
      "chain:  2  iteration:  3510  parameters:  0.0248 0.1485 0.8025 3.8519 \n",
      "chain:  2  iteration:  3520  parameters:  0.0237 0.1387 0.814 3.9211 \n",
      "chain:  2  iteration:  3530  parameters:  0.0228 0.1407 0.8277 4.018 \n",
      "chain:  2  iteration:  3540  parameters:  0.0259 0.2474 0.7388 4.812 \n",
      "chain:  2  iteration:  3550  parameters:  0.0246 0.2035 0.7698 4.2219 \n",
      "chain:  2  iteration:  3560  parameters:  0.018 0.192 0.8135 3.8084 \n",
      "chain:  2  iteration:  3570  parameters:  0.0126 0.223 0.7846 4.2403 \n",
      "chain:  2  iteration:  3580  parameters:  0.0236 0.2794 0.7295 4.4024 \n",
      "chain:  2  iteration:  3590  parameters:  0.0338 0.2642 0.6645 6.049 \n",
      "chain:  2  iteration:  3600  parameters:  0.0303 0.3469 0.6274 4.7409 \n",
      "chain:  2  iteration:  3610  parameters:  0.0371 0.1774 0.7037 4.1754 \n",
      "chain:  2  iteration:  3620  parameters:  0.0323 0.237 0.7467 3.7193 \n",
      "chain:  2  iteration:  3630  parameters:  0.029 0.1654 0.7684 3.8968 \n",
      "chain:  2  iteration:  3640  parameters:  0.019 0.1814 0.7621 4.4111 \n",
      "chain:  2  iteration:  3650  parameters:  0.0201 0.1886 0.747 6.0492 \n",
      "chain:  2  iteration:  3660  parameters:  0.0242 0.1785 0.7647 5.6694 \n",
      "chain:  2  iteration:  3670  parameters:  0.0229 0.1346 0.798 6.9055 \n",
      "chain:  2  iteration:  3680  parameters:  0.0195 0.1369 0.7921 6.3041 \n",
      "chain:  2  iteration:  3690  parameters:  0.0157 0.1526 0.812 5.8371 \n",
      "chain:  2  iteration:  3700  parameters:  0.0133 0.1724 0.8255 5.599 \n",
      "chain:  2  iteration:  3710  parameters:  0.0103 0.1316 0.8469 5.589 \n",
      "chain:  2  iteration:  3720  parameters:  0.0201 0.1312 0.8178 4.8752 \n",
      "chain:  2  iteration:  3730  parameters:  0.0323 0.1511 0.7553 5.1638 \n",
      "chain:  2  iteration:  3740  parameters:  0.0418 0.1918 0.7132 4.9875 \n",
      "chain:  2  iteration:  3750  parameters:  0.0347 0.1696 0.7319 4.7177 \n",
      "chain:  2  iteration:  3760  parameters:  0.0204 0.1878 0.7656 4.9985 \n",
      "chain:  2  iteration:  3770  parameters:  0.0295 0.2182 0.7388 4.3717 \n",
      "chain:  2  iteration:  3780  parameters:  0.0221 0.2857 0.7147 5.3603 \n",
      "chain:  2  iteration:  3790  parameters:  0.0336 0.2527 0.6892 5.86 \n",
      "chain:  2  iteration:  3800  parameters:  0.0359 0.3192 0.6136 5.3658 \n",
      "chain:  2  iteration:  3810  parameters:  0.069 0.3485 0.5189 5.1662 \n",
      "chain:  2  iteration:  3820  parameters:  0.0683 0.4122 0.517 4.2559 \n",
      "chain:  2  iteration:  3830  parameters:  0.066 0.4148 0.4748 3.8593 \n",
      "chain:  2  iteration:  3840  parameters:  0.0858 0.4122 0.4812 3.8742 \n",
      "chain:  2  iteration:  3850  parameters:  0.0815 0.5136 0.4852 3.3734 \n",
      "chain:  2  iteration:  3860  parameters:  0.0683 0.4099 0.5936 3.2707 \n",
      "chain:  2  iteration:  3870  parameters:  0.1011 0.4301 0.4851 3.6141 \n",
      "chain:  2  iteration:  3880  parameters:  0.0538 0.2994 0.6188 4.2473 \n",
      "chain:  2  iteration:  3890  parameters:  0.0312 0.2671 0.6884 4.126 \n",
      "chain:  2  iteration:  3900  parameters:  0.046 0.2438 0.675 3.7089 \n",
      "chain:  2  iteration:  3910  parameters:  0.0326 0.2547 0.7099 4.7781 \n",
      "chain:  2  iteration:  3920  parameters:  0.0241 0.2708 0.6992 6.7777 \n",
      "chain:  2  iteration:  3930  parameters:  0.0355 0.2638 0.6768 6.3285 \n",
      "chain:  2  iteration:  3940  parameters:  0.0386 0.3312 0.583 5.4891 \n",
      "chain:  2  iteration:  3950  parameters:  0.0316 0.2793 0.7025 6.4492 \n",
      "chain:  2  iteration:  3960  parameters:  0.0333 0.3164 0.6532 5.864 \n",
      "chain:  2  iteration:  3970  parameters:  0.0407 0.2972 0.6255 6.6853 \n",
      "chain:  2  iteration:  3980  parameters:  0.0276 0.2061 0.7297 5.2009 \n",
      "chain:  2  iteration:  3990  parameters:  0.0376 0.2065 0.69 6.6857 \n",
      "chain:  2  iteration:  4000  parameters:  0.0298 0.224 0.6869 7.1547 \n",
      "chain:  2  iteration:  4010  parameters:  0.0293 0.2843 0.6611 6.0369 \n",
      "chain:  2  iteration:  4020  parameters:  0.0205 0.2757 0.7335 5.0225 \n",
      "chain:  2  iteration:  4030  parameters:  0.0208 0.3469 0.6824 4.5859 \n",
      "chain:  2  iteration:  4040  parameters:  0.0368 0.2046 0.7507 4.6585 \n",
      "chain:  2  iteration:  4050  parameters:  0.024 0.2253 0.7285 4.7459 \n",
      "chain:  2  iteration:  4060  parameters:  0.0342 0.2136 0.6873 5.0847 \n",
      "chain:  2  iteration:  4070  parameters:  0.0468 0.2271 0.6654 5.2184 \n",
      "chain:  2  iteration:  4080  parameters:  0.0359 0.1949 0.6815 5.3774 \n",
      "chain:  2  iteration:  4090  parameters:  0.032 0.195 0.734 5.01 \n",
      "chain:  2  iteration:  4100  parameters:  0.0274 0.2293 0.6958 4.8839 \n",
      "chain:  2  iteration:  4110  parameters:  0.0365 0.2527 0.6507 5.3389 \n",
      "chain:  2  iteration:  4120  parameters:  0.0368 0.2957 0.6336 5.4717 \n",
      "chain:  2  iteration:  4130  parameters:  0.0567 0.2418 0.6213 5.1311 \n",
      "chain:  2  iteration:  4140  parameters:  0.0319 0.3223 0.6507 5.9352 \n",
      "chain:  2  iteration:  4150  parameters:  0.0489 0.245 0.5734 5.9264 \n",
      "chain:  2  iteration:  4160  parameters:  0.0482 0.2598 0.5685 7.2073 \n",
      "chain:  2  iteration:  4170  parameters:  0.0394 0.2321 0.6186 6.6043 \n",
      "chain:  2  iteration:  4180  parameters:  0.0458 0.222 0.6295 7.0123 \n",
      "chain:  2  iteration:  4190  parameters:  0.0525 0.2494 0.5955 7.2732 \n",
      "chain:  2  iteration:  4200  parameters:  0.0629 0.3624 0.5505 5.498 \n",
      "chain:  2  iteration:  4210  parameters:  0.0627 0.3208 0.5259 5.8245 \n",
      "chain:  2  iteration:  4220  parameters:  0.0441 0.3135 0.5721 6.2407 \n",
      "chain:  2  iteration:  4230  parameters:  0.043 0.2935 0.6081 5.7287 \n",
      "chain:  2  iteration:  4240  parameters:  0.0461 0.2477 0.6402 6.6128 \n",
      "chain:  2  iteration:  4250  parameters:  0.0334 0.2353 0.673 6.3633 \n",
      "chain:  2  iteration:  4260  parameters:  0.0439 0.2385 0.618 5.5057 \n",
      "chain:  2  iteration:  4270  parameters:  0.045 0.2395 0.6253 6.8168 \n",
      "chain:  2  iteration:  4280  parameters:  0.0193 0.2424 0.7166 6.9749 \n",
      "chain:  2  iteration:  4290  parameters:  0.0216 0.2395 0.7046 7.3645 \n",
      "chain:  2  iteration:  4300  parameters:  0.0263 0.287 0.6979 7.0382 \n",
      "chain:  2  iteration:  4310  parameters:  0.038 0.2827 0.643 6.6926 \n",
      "chain:  2  iteration:  4320  parameters:  0.0426 0.2548 0.6186 7.5768 \n",
      "chain:  2  iteration:  4330  parameters:  0.058 0.1984 0.6108 7.2817 \n",
      "chain:  2  iteration:  4340  parameters:  0.0355 0.269 0.6425 6.9954 \n",
      "chain:  2  iteration:  4350  parameters:  0.0169 0.1988 0.7521 6.2525 \n",
      "chain:  2  iteration:  4360  parameters:  0.0298 0.1596 0.7535 6.4643 \n",
      "chain:  2  iteration:  4370  parameters:  0.0304 0.183 0.7268 7.2754 \n",
      "chain:  2  iteration:  4380  parameters:  0.0293 0.2087 0.7395 5.2831 \n",
      "chain:  2  iteration:  4390  parameters:  0.0264 0.2254 0.7438 5.3034 \n",
      "chain:  2  iteration:  4400  parameters:  0.0251 0.174 0.7684 5.5163 \n",
      "chain:  2  iteration:  4410  parameters:  0.0241 0.1194 0.7885 5.7058 \n",
      "chain:  2  iteration:  4420  parameters:  0.0196 0.1844 0.7614 6.224 \n",
      "chain:  2  iteration:  4430  parameters:  0.0212 0.0983 0.8421 6.5573 \n",
      "chain:  2  iteration:  4440  parameters:  0.0222 0.1491 0.7769 6.0453 \n",
      "chain:  2  iteration:  4450  parameters:  0.01 0.1611 0.8053 6.9366 \n",
      "chain:  2  iteration:  4460  parameters:  0.0242 0.2094 0.721 7.1964 \n",
      "chain:  2  iteration:  4470  parameters:  0.031 0.2267 0.6811 7.0328 \n",
      "chain:  2  iteration:  4480  parameters:  0.0346 0.2495 0.651 7.3863 \n",
      "chain:  2  iteration:  4490  parameters:  0.0241 0.1727 0.7499 7.9761 \n",
      "chain:  2  iteration:  4500  parameters:  0.0355 0.1637 0.738 9.8119 \n",
      "chain:  2  iteration:  4510  parameters:  0.0259 0.1099 0.8077 9.5028 \n",
      "chain:  2  iteration:  4520  parameters:  0.0211 0.1346 0.7938 9.5035 \n",
      "chain:  2  iteration:  4530  parameters:  0.0198 0.2106 0.7492 9.3359 \n",
      "chain:  2  iteration:  4540  parameters:  0.0258 0.1718 0.7444 11.5294 \n",
      "chain:  2  iteration:  4550  parameters:  0.0171 0.1666 0.7866 9.9321 \n",
      "chain:  2  iteration:  4560  parameters:  0.0178 0.1418 0.7871 12.6053 \n",
      "chain:  2  iteration:  4570  parameters:  0.0153 0.2045 0.7368 11.9569 \n",
      "chain:  2  iteration:  4580  parameters:  0.0372 0.181 0.7127 13.861 \n",
      "chain:  2  iteration:  4590  parameters:  0.0247 0.2272 0.7006 10.0712 \n",
      "chain:  2  iteration:  4600  parameters:  0.0221 0.1649 0.783 7.5032 \n",
      "chain:  2  iteration:  4610  parameters:  0.0131 0.1916 0.7839 8.7314 \n",
      "chain:  2  iteration:  4620  parameters:  0.0144 0.1948 0.7552 9.6843 \n",
      "chain:  2  iteration:  4630  parameters:  0.015 0.229 0.7683 6.3644 \n",
      "chain:  2  iteration:  4640  parameters:  0.0256 0.214 0.7346 7.2984 \n",
      "chain:  2  iteration:  4650  parameters:  0.0282 0.1683 0.7461 6.4738 \n",
      "chain:  2  iteration:  4660  parameters:  0.0264 0.1761 0.7511 6.0101 \n",
      "chain:  2  iteration:  4670  parameters:  0.0175 0.1939 0.8096 5.8123 \n",
      "chain:  2  iteration:  4680  parameters:  0.0219 0.1783 0.7659 5.1098 \n",
      "chain:  2  iteration:  4690  parameters:  0.0271 0.2088 0.7357 4.8069 \n",
      "chain:  2  iteration:  4700  parameters:  0.033 0.2198 0.7178 4.3477 \n",
      "chain:  2  iteration:  4710  parameters:  0.0428 0.2461 0.6741 4.328 \n",
      "chain:  2  iteration:  4720  parameters:  0.0448 0.2445 0.669 4.4146 \n",
      "chain:  2  iteration:  4730  parameters:  0.0335 0.2376 0.6827 4.5086 \n",
      "chain:  2  iteration:  4740  parameters:  0.0264 0.2521 0.6986 4.5281 \n",
      "chain:  2  iteration:  4750  parameters:  0.0605 0.2954 0.632 4.414 \n",
      "chain:  2  iteration:  4760  parameters:  0.0413 0.3524 0.6127 4.1868 \n",
      "chain:  2  iteration:  4770  parameters:  0.048 0.2621 0.6721 3.8757 \n",
      "chain:  2  iteration:  4780  parameters:  0.0473 0.2614 0.6495 3.9694 \n",
      "chain:  2  iteration:  4790  parameters:  0.0449 0.3005 0.6713 3.5978 \n",
      "chain:  2  iteration:  4800  parameters:  0.0304 0.2563 0.7429 3.6903 \n",
      "chain:  2  iteration:  4810  parameters:  0.047 0.3122 0.6804 3.5677 \n",
      "chain:  2  iteration:  4820  parameters:  0.0405 0.4053 0.6589 3.5633 \n",
      "chain:  2  iteration:  4830  parameters:  0.0613 0.2827 0.6496 3.5151 \n",
      "chain:  2  iteration:  4840  parameters:  0.0505 0.4365 0.6338 3.1356 \n",
      "chain:  2  iteration:  4850  parameters:  0.0692 0.407 0.6011 3.3121 \n",
      "chain:  2  iteration:  4860  parameters:  0.0552 0.2661 0.6008 4.3584 \n",
      "chain:  2  iteration:  4870  parameters:  0.0367 0.2595 0.7265 4.3949 \n",
      "chain:  2  iteration:  4880  parameters:  0.0202 0.2641 0.7503 4.015 \n",
      "chain:  2  iteration:  4890  parameters:  0.031 0.266 0.6777 4.5647 \n",
      "chain:  2  iteration:  4900  parameters:  0.0265 0.3076 0.6964 4.746 \n",
      "chain:  2  iteration:  4910  parameters:  0.0481 0.2924 0.6145 5.6603 \n",
      "chain:  2  iteration:  4920  parameters:  0.0552 0.295 0.5972 5.1663 \n",
      "chain:  2  iteration:  4930  parameters:  0.0207 0.339 0.6349 6.4147 \n",
      "chain:  2  iteration:  4940  parameters:  0.0382 0.2514 0.6374 8.1919 \n",
      "chain:  2  iteration:  4950  parameters:  0.0308 0.192 0.7147 10.0542 \n",
      "chain:  2  iteration:  4960  parameters:  0.0258 0.195 0.7082 7.4856 \n",
      "chain:  2  iteration:  4970  parameters:  0.0278 0.2072 0.6846 8.8068 \n",
      "chain:  2  iteration:  4980  parameters:  0.0316 0.2235 0.7069 7.4552 \n",
      "chain:  2  iteration:  4990  parameters:  0.0252 0.1934 0.7312 7.0813 \n",
      "chain:  2  iteration:  5000  parameters:  0.02 0.2263 0.7514 6.921 \n",
      "chain:  2  iteration:  5010  parameters:  0.0221 0.1365 0.8079 8.8091 \n",
      "chain:  2  iteration:  5020  parameters:  0.0222 0.1244 0.7866 6.8887 \n",
      "chain:  2  iteration:  5030  parameters:  0.0222 0.1481 0.8102 7.318 \n",
      "chain:  2  iteration:  5040  parameters:  0.0255 0.1527 0.7493 9.9099 \n",
      "chain:  2  iteration:  5050  parameters:  0.0239 0.2249 0.7149 11.4931 \n",
      "chain:  2  iteration:  5060  parameters:  0.0315 0.203 0.6992 8.3331 \n",
      "chain:  2  iteration:  5070  parameters:  0.0393 0.2044 0.6838 7.2538 \n",
      "chain:  2  iteration:  5080  parameters:  0.0238 0.2223 0.7298 6.3639 \n",
      "chain:  2  iteration:  5090  parameters:  0.0164 0.1802 0.7703 7.3221 \n",
      "chain:  2  iteration:  5100  parameters:  0.0249 0.2013 0.7411 7.6718 \n",
      "chain:  2  iteration:  5110  parameters:  0.0258 0.2729 0.6817 7.9035 \n",
      "chain:  2  iteration:  5120  parameters:  0.068 0.2647 0.5295 5.5589 \n",
      "chain:  2  iteration:  5130  parameters:  0.0456 0.431 0.5694 4.8102 \n",
      "chain:  2  iteration:  5140  parameters:  0.0718 0.2931 0.5437 4.621 \n",
      "chain:  2  iteration:  5150  parameters:  0.0314 0.2879 0.675 4.8228 \n",
      "chain:  2  iteration:  5160  parameters:  0.0433 0.3022 0.6164 5.5091 \n",
      "chain:  2  iteration:  5170  parameters:  0.0446 0.3616 0.561 5.5456 \n",
      "chain:  2  iteration:  5180  parameters:  0.036 0.2438 0.6436 5.5571 \n",
      "chain:  2  iteration:  5190  parameters:  0.0495 0.16 0.6573 6.9258 \n",
      "chain:  2  iteration:  5200  parameters:  0.0326 0.2679 0.642 5.8475 \n",
      "chain:  2  iteration:  5210  parameters:  0.0335 0.2366 0.6838 6.8267 \n",
      "chain:  2  iteration:  5220  parameters:  0.0327 0.293 0.6624 5.371 \n",
      "chain:  2  iteration:  5230  parameters:  0.041 0.4491 0.5707 5.0089 \n",
      "chain:  2  iteration:  5240  parameters:  0.0689 0.4954 0.4643 5.7251 \n",
      "chain:  2  iteration:  5250  parameters:  0.0889 0.2923 0.4699 5.3475 \n",
      "chain:  2  iteration:  5260  parameters:  0.0622 0.5034 0.4347 5.6611 \n",
      "chain:  2  iteration:  5270  parameters:  0.073 0.3079 0.5114 5.3092 \n",
      "chain:  2  iteration:  5280  parameters:  0.0529 0.3579 0.5357 4.7728 \n",
      "chain:  2  iteration:  5290  parameters:  0.0425 0.3303 0.6476 5.409 \n",
      "chain:  2  iteration:  5300  parameters:  0.0365 0.2558 0.6748 5.2727 \n",
      "chain:  2  iteration:  5310  parameters:  0.0369 0.1833 0.7109 6.3551 \n",
      "chain:  2  iteration:  5320  parameters:  0.0562 0.2536 0.5595 7.3395 \n",
      "chain:  2  iteration:  5330  parameters:  0.0571 0.3461 0.5788 6.6158 \n",
      "chain:  2  iteration:  5340  parameters:  0.0467 0.2655 0.6561 6.3761 \n",
      "chain:  2  iteration:  5350  parameters:  0.0439 0.2496 0.6729 6.7271 \n",
      "chain:  2  iteration:  5360  parameters:  0.0614 0.2975 0.4761 8.2166 \n",
      "chain:  2  iteration:  5370  parameters:  0.0639 0.3098 0.5522 8.944 \n",
      "chain:  2  iteration:  5380  parameters:  0.0542 0.3173 0.5627 7.4289 \n",
      "chain:  2  iteration:  5390  parameters:  0.0597 0.3064 0.5667 5.833 \n",
      "chain:  2  iteration:  5400  parameters:  0.0414 0.3426 0.6216 6.0321 \n",
      "chain:  2  iteration:  5410  parameters:  0.0717 0.3456 0.5395 5.5281 \n",
      "chain:  2  iteration:  5420  parameters:  0.0308 0.4842 0.5489 4.67 \n",
      "chain:  2  iteration:  5430  parameters:  0.0849 0.3401 0.5595 3.9094 \n",
      "chain:  2  iteration:  5440  parameters:  0.0817 0.4334 0.4862 3.7644 \n",
      "chain:  2  iteration:  5450  parameters:  0.0755 0.3948 0.493 3.7262 \n",
      "chain:  2  iteration:  5460  parameters:  0.0941 0.5052 0.4099 3.558 \n",
      "chain:  2  iteration:  5470  parameters:  0.0618 0.3585 0.5414 4.2443 \n",
      "chain:  2  iteration:  5480  parameters:  0.0452 0.2623 0.6706 4.8193 \n",
      "chain:  2  iteration:  5490  parameters:  0.0572 0.2469 0.6383 4.2367 \n",
      "chain:  2  iteration:  5500  parameters:  0.0438 0.2529 0.6683 4.4494 \n",
      "chain:  2  iteration:  5510  parameters:  0.0278 0.2519 0.7298 3.9307 \n",
      "chain:  2  iteration:  5520  parameters:  0.0278 0.1727 0.8013 3.6625 \n",
      "chain:  2  iteration:  5530  parameters:  0.0235 0.2162 0.7665 3.7048 \n",
      "chain:  2  iteration:  5540  parameters:  0.042 0.1857 0.6846 4.2907 \n",
      "chain:  2  iteration:  5550  parameters:  0.0238 0.2891 0.707 5.3107 \n",
      "chain:  2  iteration:  5560  parameters:  0.0291 0.2575 0.7019 4.9088 \n",
      "chain:  2  iteration:  5570  parameters:  0.0279 0.2432 0.7104 4.9711 \n",
      "chain:  2  iteration:  5580  parameters:  0.0347 0.3216 0.6169 5.1183 \n",
      "chain:  2  iteration:  5590  parameters:  0.0296 0.3146 0.6129 5.9948 \n",
      "chain:  2  iteration:  5600  parameters:  0.0782 0.2095 0.5178 6.757 \n",
      "chain:  2  iteration:  5610  parameters:  0.0297 0.2387 0.7043 9.0326 \n",
      "chain:  2  iteration:  5620  parameters:  0.0441 0.2374 0.6164 9.9953 \n",
      "chain:  2  iteration:  5630  parameters:  0.0543 0.2345 0.5895 10.0463 \n",
      "chain:  2  iteration:  5640  parameters:  0.0578 0.3362 0.5555 9.6833 \n",
      "chain:  2  iteration:  5650  parameters:  0.0607 0.2764 0.5601 8.4344 \n",
      "chain:  2  iteration:  5660  parameters:  0.0516 0.2775 0.5525 7.0757 \n",
      "chain:  2  iteration:  5670  parameters:  0.0475 0.2484 0.6373 6.0745 \n",
      "chain:  2  iteration:  5680  parameters:  0.0533 0.3088 0.5839 5.765 \n",
      "chain:  2  iteration:  5690  parameters:  0.0334 0.2842 0.6453 4.7836 \n",
      "chain:  2  iteration:  5700  parameters:  0.0321 0.2695 0.726 4.5111 \n",
      "chain:  2  iteration:  5710  parameters:  0.0316 0.2107 0.7609 3.9824 \n",
      "chain:  2  iteration:  5720  parameters:  0.025 0.2978 0.7265 3.8284 \n",
      "chain:  2  iteration:  5730  parameters:  0.0358 0.2397 0.7258 3.6661 \n",
      "chain:  2  iteration:  5740  parameters:  0.0491 0.2141 0.6491 4.0416 \n",
      "chain:  2  iteration:  5750  parameters:  0.0352 0.307 0.669 4.1817 \n",
      "chain:  2  iteration:  5760  parameters:  0.0263 0.2788 0.6936 4.5955 \n",
      "chain:  2  iteration:  5770  parameters:  0.0308 0.3421 0.6616 4.2694 \n",
      "chain:  2  iteration:  5780  parameters:  0.0452 0.3337 0.6237 4.5091 \n",
      "chain:  2  iteration:  5790  parameters:  0.0533 0.3205 0.5848 4.219 \n",
      "chain:  2  iteration:  5800  parameters:  0.0405 0.2052 0.72 4.6525 \n",
      "chain:  2  iteration:  5810  parameters:  0.0301 0.2479 0.7145 5.0937 \n",
      "chain:  2  iteration:  5820  parameters:  0.0329 0.2445 0.7041 5.1309 \n",
      "chain:  2  iteration:  5830  parameters:  0.0364 0.2297 0.6532 5.1878 \n",
      "chain:  2  iteration:  5840  parameters:  0.0471 0.227 0.651 5.2478 \n",
      "chain:  2  iteration:  5850  parameters:  0.026 0.2677 0.6818 5.7063 \n",
      "chain:  2  iteration:  5860  parameters:  0.0398 0.2181 0.6576 6.3971 \n",
      "chain:  2  iteration:  5870  parameters:  0.0302 0.2814 0.6665 5.5498 \n",
      "chain:  2  iteration:  5880  parameters:  0.0514 0.2537 0.6012 5.2507 \n",
      "chain:  2  iteration:  5890  parameters:  0.0479 0.233 0.6697 5.4874 \n",
      "chain:  2  iteration:  5900  parameters:  0.0604 0.2326 0.6017 5.5829 \n",
      "chain:  2  iteration:  5910  parameters:  0.0769 0.2127 0.573 5.1159 \n",
      "chain:  2  iteration:  5920  parameters:  0.0293 0.3434 0.6458 5.3362 \n",
      "chain:  2  iteration:  5930  parameters:  0.0348 0.1823 0.722 5.2348 \n",
      "chain:  2  iteration:  5940  parameters:  0.0457 0.2525 0.5888 6.4858 \n",
      "chain:  2  iteration:  5950  parameters:  0.0471 0.2264 0.6 6.1722 \n",
      "chain:  2  iteration:  5960  parameters:  0.0404 0.3112 0.6123 5.4161 \n",
      "chain:  2  iteration:  5970  parameters:  0.0311 0.2125 0.7194 5.5031 \n",
      "chain:  2  iteration:  5980  parameters:  0.0229 0.1736 0.7531 7.4207 \n",
      "chain:  2  iteration:  5990  parameters:  0.0176 0.1562 0.7944 5.304 \n",
      "chain:  2  iteration:  6000  parameters:  0.026 0.2363 0.7326 4.9755 \n",
      "chain:  2  iteration:  6010  parameters:  0.0317 0.2638 0.6741 6.0313 \n",
      "chain:  2  iteration:  6020  parameters:  0.0385 0.3233 0.6518 5.3558 \n",
      "chain:  2  iteration:  6030  parameters:  0.0293 0.2301 0.7274 5.9608 \n",
      "chain:  2  iteration:  6040  parameters:  0.0233 0.2109 0.7549 6.3582 \n",
      "chain:  2  iteration:  6050  parameters:  0.0266 0.2657 0.6679 5.7305 \n",
      "chain:  2  iteration:  6060  parameters:  0.0298 0.2577 0.7232 4.4053 \n",
      "chain:  2  iteration:  6070  parameters:  0.0291 0.2022 0.7392 4.9599 \n",
      "chain:  2  iteration:  6080  parameters:  0.0224 0.2062 0.7476 4.7067 \n",
      "chain:  2  iteration:  6090  parameters:  0.0251 0.1829 0.7685 4.6964 \n",
      "chain:  2  iteration:  6100  parameters:  0.0258 0.2649 0.7192 5.4917 \n",
      "chain:  2  iteration:  6110  parameters:  0.0347 0.2603 0.6948 5.8306 \n",
      "chain:  2  iteration:  6120  parameters:  0.044 0.3306 0.6008 5.4668 \n",
      "chain:  2  iteration:  6130  parameters:  0.0427 0.3459 0.5914 4.357 \n",
      "chain:  2  iteration:  6140  parameters:  0.0441 0.2682 0.623 4.9307 \n",
      "chain:  2  iteration:  6150  parameters:  0.0473 0.2797 0.5827 5.9201 \n",
      "chain:  2  iteration:  6160  parameters:  0.0364 0.3425 0.5947 5.0439 \n",
      "chain:  2  iteration:  6170  parameters:  0.0392 0.3362 0.6169 4.9698 \n",
      "chain:  2  iteration:  6180  parameters:  0.0388 0.2706 0.6737 3.9242 \n",
      "chain:  2  iteration:  6190  parameters:  0.0365 0.1886 0.7361 5.0644 \n",
      "chain:  2  iteration:  6200  parameters:  0.0264 0.1794 0.7679 4.9069 \n",
      "chain:  2  iteration:  6210  parameters:  0.0229 0.2517 0.7223 4.0302 \n",
      "chain:  2  iteration:  6220  parameters:  0.0208 0.321 0.6925 4.052 \n",
      "chain:  2  iteration:  6230  parameters:  0.0287 0.2735 0.6988 3.9136 \n",
      "chain:  2  iteration:  6240  parameters:  0.0592 0.315 0.6027 4.0512 \n",
      "chain:  2  iteration:  6250  parameters:  0.0393 0.4294 0.6392 4.0644 \n",
      "chain:  2  iteration:  6260  parameters:  0.0769 0.3593 0.5668 3.742 \n",
      "chain:  2  iteration:  6270  parameters:  0.0372 0.3646 0.6398 4.2392 \n",
      "chain:  2  iteration:  6280  parameters:  0.0311 0.3144 0.6522 4.6382 \n",
      "chain:  2  iteration:  6290  parameters:  0.0512 0.2269 0.66 4.3827 \n",
      "chain:  2  iteration:  6300  parameters:  0.0338 0.3271 0.6826 4.0679 \n",
      "chain:  2  iteration:  6310  parameters:  0.0456 0.3594 0.5948 4.023 \n",
      "chain:  2  iteration:  6320  parameters:  0.0409 0.329 0.6085 4.1105 \n",
      "chain:  2  iteration:  6330  parameters:  0.0612 0.3063 0.6326 4.7153 \n",
      "chain:  2  iteration:  6340  parameters:  0.0479 0.2476 0.6685 4.2155 \n",
      "chain:  2  iteration:  6350  parameters:  0.0335 0.2341 0.7033 4.6116 \n",
      "chain:  2  iteration:  6360  parameters:  0.0153 0.3687 0.6675 5.0188 \n",
      "chain:  2  iteration:  6370  parameters:  0.0389 0.2354 0.6446 5.0396 \n",
      "chain:  2  iteration:  6380  parameters:  0.0382 0.2505 0.6507 4.8064 \n",
      "chain:  2  iteration:  6390  parameters:  0.049 0.2894 0.6098 4.5978 \n",
      "chain:  2  iteration:  6400  parameters:  0.0402 0.3407 0.6128 5.3904 \n",
      "chain:  2  iteration:  6410  parameters:  0.0519 0.2368 0.6289 5.9805 \n",
      "chain:  2  iteration:  6420  parameters:  0.0423 0.2321 0.6566 6.396 \n",
      "chain:  2  iteration:  6430  parameters:  0.0308 0.2562 0.6298 8.8763 \n",
      "chain:  2  iteration:  6440  parameters:  0.0522 0.2692 0.594 13.716 \n",
      "chain:  2  iteration:  6450  parameters:  0.0621 0.3079 0.4981 15.0174 \n",
      "chain:  2  iteration:  6460  parameters:  0.0454 0.3277 0.6031 11.692 \n",
      "chain:  2  iteration:  6470  parameters:  0.0446 0.2688 0.5721 8.4356 \n",
      "chain:  2  iteration:  6480  parameters:  0.042 0.3017 0.6338 6.6829 \n",
      "chain:  2  iteration:  6490  parameters:  0.0305 0.1846 0.7096 6.5727 \n",
      "chain:  2  iteration:  6500  parameters:  0.038 0.1915 0.6846 6.4202 \n",
      "chain:  2  iteration:  6510  parameters:  0.0382 0.2659 0.6512 6.7753 \n",
      "chain:  2  iteration:  6520  parameters:  0.0365 0.3205 0.6243 5.5669 \n",
      "chain:  2  iteration:  6530  parameters:  0.0377 0.1856 0.6754 5.8439 \n",
      "chain:  2  iteration:  6540  parameters:  0.0359 0.2079 0.6948 5.5009 \n",
      "chain:  2  iteration:  6550  parameters:  0.0266 0.2552 0.7229 4.7217 \n",
      "chain:  2  iteration:  6560  parameters:  0.037 0.2566 0.6884 5.0285 \n",
      "chain:  2  iteration:  6570  parameters:  0.0309 0.2637 0.6944 5.4091 \n",
      "chain:  2  iteration:  6580  parameters:  0.031 0.2797 0.6777 5.2915 \n",
      "chain:  2  iteration:  6590  parameters:  0.0351 0.2171 0.7389 5.2783 \n",
      "chain:  2  iteration:  6600  parameters:  0.0149 0.2776 0.7471 4.8022 \n",
      "chain:  2  iteration:  6610  parameters:  0.024 0.1884 0.7644 4.6844 \n",
      "chain:  2  iteration:  6620  parameters:  0.037 0.2162 0.6864 4.6859 \n",
      "chain:  2  iteration:  6630  parameters:  0.0337 0.1586 0.7436 5.182 \n",
      "chain:  2  iteration:  6640  parameters:  0.031 0.1335 0.7587 5.5284 \n",
      "chain:  2  iteration:  6650  parameters:  0.0176 0.1848 0.7827 5.5879 \n",
      "chain:  2  iteration:  6660  parameters:  0.0187 0.1332 0.7908 6.3635 \n",
      "chain:  2  iteration:  6670  parameters:  0.0207 0.1722 0.7599 4.8311 \n",
      "chain:  2  iteration:  6680  parameters:  0.0144 0.317 0.7365 4.0233 \n",
      "chain:  2  iteration:  6690  parameters:  0.0306 0.1448 0.8001 4.6623 \n",
      "chain:  2  iteration:  6700  parameters:  0.024 0.1553 0.7762 5.7475 \n",
      "chain:  2  iteration:  6710  parameters:  0.0231 0.1596 0.7907 5.5913 \n",
      "chain:  2  iteration:  6720  parameters:  0.0209 0.1841 0.7507 6.8818 \n",
      "chain:  2  iteration:  6730  parameters:  0.0163 0.2328 0.7382 8.3044 \n",
      "chain:  2  iteration:  6740  parameters:  0.0261 0.164 0.7508 7.1244 \n",
      "chain:  2  iteration:  6750  parameters:  0.0253 0.1796 0.7292 7.1699 \n",
      "chain:  2  iteration:  6760  parameters:  0.0188 0.1654 0.7773 6.8893 \n",
      "chain:  2  iteration:  6770  parameters:  0.0237 0.1439 0.7887 5.9611 \n",
      "chain:  2  iteration:  6780  parameters:  0.0182 0.1883 0.7912 5.8677 \n",
      "chain:  2  iteration:  6790  parameters:  0.0205 0.168 0.7857 5.9355 \n",
      "chain:  2  iteration:  6800  parameters:  0.0204 0.2032 0.7699 5.32 \n",
      "chain:  2  iteration:  6810  parameters:  0.0203 0.1305 0.8164 5.791 \n",
      "chain:  2  iteration:  6820  parameters:  0.0184 0.1703 0.7716 7.9248 \n",
      "chain:  2  iteration:  6830  parameters:  0.0121 0.1428 0.8156 9.8836 \n",
      "chain:  2  iteration:  6840  parameters:  0.0268 0.1162 0.7929 10.6229 \n",
      "chain:  2  iteration:  6850  parameters:  0.0295 0.2006 0.688 11.9915 \n",
      "chain:  2  iteration:  6860  parameters:  0.0427 0.1395 0.6998 9.7913 \n",
      "chain:  2  iteration:  6870  parameters:  0.0336 0.2057 0.6883 7.1736 \n",
      "chain:  2  iteration:  6880  parameters:  0.0383 0.2644 0.6572 5.1148 \n",
      "chain:  2  iteration:  6890  parameters:  0.0415 0.274 0.6456 5.824 \n",
      "chain:  2  iteration:  6900  parameters:  0.0378 0.2939 0.5936 5.8716 \n",
      "chain:  2  iteration:  6910  parameters:  0.0347 0.4014 0.5545 5.0972 \n",
      "chain:  2  iteration:  6920  parameters:  0.0404 0.269 0.6205 4.5903 \n",
      "chain:  2  iteration:  6930  parameters:  0.0557 0.2665 0.538 5.9359 \n",
      "chain:  2  iteration:  6940  parameters:  0.0491 0.3083 0.5415 6.8614 \n",
      "chain:  2  iteration:  6950  parameters:  0.0697 0.2854 0.5435 6.2248 \n",
      "chain:  2  iteration:  6960  parameters:  0.0643 0.2867 0.5106 7.5656 \n",
      "chain:  2  iteration:  6970  parameters:  0.0624 0.3131 0.5166 7.4146 \n",
      "chain:  2  iteration:  6980  parameters:  0.0555 0.29 0.5474 6.4225 \n",
      "chain:  2  iteration:  6990  parameters:  0.0373 0.3093 0.6195 5.096 \n",
      "chain:  2  iteration:  7000  parameters:  0.058 0.2379 0.5887 5.1627 \n",
      "chain:  2  iteration:  7010  parameters:  0.0626 0.3967 0.5383 4.49 \n",
      "chain:  2  iteration:  7020  parameters:  0.0594 0.3924 0.5447 5.3718 \n",
      "chain:  2  iteration:  7030  parameters:  0.0753 0.4051 0.3968 6.6196 \n",
      "chain:  2  iteration:  7040  parameters:  0.0483 0.4223 0.5351 5.4835 \n",
      "chain:  2  iteration:  7050  parameters:  0.058 0.4511 0.4928 4.9724 \n",
      "chain:  2  iteration:  7060  parameters:  0.0831 0.3623 0.4764 5.2115 \n",
      "chain:  2  iteration:  7070  parameters:  0.0801 0.2663 0.4902 5.6724 \n",
      "chain:  2  iteration:  7080  parameters:  0.0612 0.2697 0.5676 5.1962 \n",
      "chain:  2  iteration:  7090  parameters:  0.0496 0.3412 0.5903 5.3361 \n",
      "chain:  2  iteration:  7100  parameters:  0.0617 0.3416 0.5494 6.0005 \n",
      "chain:  2  iteration:  7110  parameters:  0.0544 0.227 0.6166 5.6628 \n",
      "chain:  2  iteration:  7120  parameters:  0.0206 0.2073 0.7459 5.4728 \n",
      "chain:  2  iteration:  7130  parameters:  0.0182 0.1525 0.8135 6.4089 \n",
      "chain:  2  iteration:  7140  parameters:  0.0161 0.1944 0.7705 6.8848 \n",
      "chain:  2  iteration:  7150  parameters:  0.0168 0.1807 0.795 6.3327 \n",
      "chain:  2  iteration:  7160  parameters:  0.0181 0.1376 0.793 7.132 \n",
      "chain:  2  iteration:  7170  parameters:  0.029 0.1858 0.742 6.3292 \n",
      "chain:  2  iteration:  7180  parameters:  0.0391 0.1992 0.7074 6.865 \n",
      "chain:  2  iteration:  7190  parameters:  0.022 0.2127 0.7309 7.1523 \n",
      "chain:  2  iteration:  7200  parameters:  0.0319 0.2004 0.6936 6.2285 \n",
      "chain:  2  iteration:  7210  parameters:  0.0343 0.244 0.6578 5.6913 \n",
      "chain:  2  iteration:  7220  parameters:  0.0313 0.2537 0.6717 5.1952 \n",
      "chain:  2  iteration:  7230  parameters:  0.0213 0.2262 0.7469 5.1831 \n",
      "chain:  2  iteration:  7240  parameters:  0.0307 0.2418 0.6858 5.8307 \n",
      "chain:  2  iteration:  7250  parameters:  0.0165 0.2109 0.7875 4.8565 \n",
      "chain:  2  iteration:  7260  parameters:  0.0163 0.159 0.8107 4.3935 \n",
      "chain:  2  iteration:  7270  parameters:  0.0107 0.1563 0.8451 4.1611 \n",
      "chain:  2  iteration:  7280  parameters:  0.0074 0.2062 0.8052 4.9607 \n",
      "chain:  2  iteration:  7290  parameters:  0.0186 0.1602 0.7664 6.3339 \n",
      "chain:  2  iteration:  7300  parameters:  0.032 0.1236 0.7696 6.3141 \n",
      "chain:  2  iteration:  7310  parameters:  0.0211 0.159 0.7916 6.8446 \n",
      "chain:  2  iteration:  7320  parameters:  0.0135 0.1812 0.7953 5.092 \n",
      "chain:  2  iteration:  7330  parameters:  0.0284 0.1666 0.7435 5.069 \n",
      "chain:  2  iteration:  7340  parameters:  0.0338 0.1777 0.7173 5.0374 \n",
      "chain:  2  iteration:  7350  parameters:  0.0262 0.2336 0.7066 4.5473 \n",
      "chain:  2  iteration:  7360  parameters:  0.0274 0.2822 0.683 5.0694 \n",
      "chain:  2  iteration:  7370  parameters:  0.0273 0.2338 0.699 4.8457 \n",
      "chain:  2  iteration:  7380  parameters:  0.0193 0.1765 0.8013 4.5404 \n",
      "chain:  2  iteration:  7390  parameters:  0.0121 0.1856 0.8101 4.4622 \n",
      "chain:  2  iteration:  7400  parameters:  0.0186 0.1431 0.8183 4.024 \n",
      "chain:  2  iteration:  7410  parameters:  0.0134 0.1438 0.841 5.1364 \n",
      "chain:  2  iteration:  7420  parameters:  0.012 0.2073 0.7734 6.5414 \n",
      "chain:  2  iteration:  7430  parameters:  0.0347 0.1445 0.7056 7.5752 \n",
      "chain:  2  iteration:  7440  parameters:  0.0179 0.2286 0.7675 8.2274 \n",
      "chain:  2  iteration:  7450  parameters:  0.0182 0.191 0.771 7.4719 \n",
      "chain:  2  iteration:  7460  parameters:  0.0145 0.1904 0.7892 7.0801 \n",
      "chain:  2  iteration:  7470  parameters:  0.0149 0.1828 0.7767 6.4136 \n",
      "chain:  2  iteration:  7480  parameters:  0.0166 0.1452 0.798 7.1363 \n",
      "chain:  2  iteration:  7490  parameters:  0.0256 0.1547 0.7712 6.9397 \n",
      "chain:  2  iteration:  7500  parameters:  0.0192 0.1686 0.7688 7.6332 \n",
      "chain:  2  iteration:  7510  parameters:  0.0229 0.2032 0.7354 7.7842 \n",
      "chain:  2  iteration:  7520  parameters:  0.0372 0.1656 0.676 7.0425 \n",
      "chain:  2  iteration:  7530  parameters:  0.0367 0.2198 0.6948 7.0796 \n",
      "chain:  2  iteration:  7540  parameters:  0.0382 0.2805 0.6352 8.3053 \n",
      "chain:  2  iteration:  7550  parameters:  0.043 0.2768 0.6345 6.6064 \n",
      "chain:  2  iteration:  7560  parameters:  0.0592 0.1797 0.6261 6.9663 \n",
      "chain:  2  iteration:  7570  parameters:  0.0355 0.326 0.6165 8.1957 \n",
      "chain:  2  iteration:  7580  parameters:  0.0514 0.1781 0.6818 6.7482 \n",
      "chain:  2  iteration:  7590  parameters:  0.022 0.2532 0.7105 5.438 \n",
      "chain:  2  iteration:  7600  parameters:  0.0184 0.2933 0.7023 4.9666 \n",
      "chain:  2  iteration:  7610  parameters:  0.0339 0.2748 0.7071 4.6787 \n",
      "chain:  2  iteration:  7620  parameters:  0.0359 0.1978 0.7064 5.5709 \n",
      "chain:  2  iteration:  7630  parameters:  0.0432 0.2014 0.6609 5.5738 \n",
      "chain:  2  iteration:  7640  parameters:  0.038 0.2579 0.6598 4.9324 \n",
      "chain:  2  iteration:  7650  parameters:  0.0373 0.2404 0.706 4.8649 \n",
      "chain:  2  iteration:  7660  parameters:  0.0353 0.3169 0.6531 4.356 \n",
      "chain:  2  iteration:  7670  parameters:  0.0299 0.3283 0.6589 4.0036 \n",
      "chain:  2  iteration:  7680  parameters:  0.0598 0.2062 0.6413 4.4448 \n",
      "chain:  2  iteration:  7690  parameters:  0.0455 0.2544 0.6698 5.0321 \n",
      "chain:  2  iteration:  7700  parameters:  0.0442 0.2885 0.5913 6.6794 \n",
      "chain:  2  iteration:  7710  parameters:  0.049 0.2435 0.5809 8.0996 \n",
      "chain:  2  iteration:  7720  parameters:  0.051 0.2164 0.5323 9.7667 \n",
      "chain:  2  iteration:  7730  parameters:  0.0364 0.295 0.6289 6.4008 \n",
      "chain:  2  iteration:  7740  parameters:  0.0553 0.2605 0.6435 6.6461 \n",
      "chain:  2  iteration:  7750  parameters:  0.0449 0.2986 0.5722 4.8209 \n",
      "chain:  2  iteration:  7760  parameters:  0.0743 0.2383 0.553 5.9173 \n",
      "chain:  2  iteration:  7770  parameters:  0.0355 0.2417 0.6763 5.9021 \n",
      "chain:  2  iteration:  7780  parameters:  0.0159 0.279 0.7329 5.6738 \n",
      "chain:  2  iteration:  7790  parameters:  0.0343 0.2001 0.7177 4.7583 \n",
      "chain:  2  iteration:  7800  parameters:  0.0253 0.2212 0.7621 5.1559 \n",
      "chain:  2  iteration:  7810  parameters:  0.0239 0.2903 0.6905 4.7606 \n",
      "chain:  2  iteration:  7820  parameters:  0.0225 0.2592 0.7332 4.6569 \n",
      "chain:  2  iteration:  7830  parameters:  0.0237 0.2325 0.7532 4.9566 \n",
      "chain:  2  iteration:  7840  parameters:  0.0292 0.1524 0.79 4.8767 \n",
      "chain:  2  iteration:  7850  parameters:  0.0294 0.1343 0.7899 4.4925 \n",
      "chain:  2  iteration:  7860  parameters:  0.0221 0.2267 0.7298 5.1356 \n",
      "chain:  2  iteration:  7870  parameters:  0.0193 0.1886 0.794 4.7973 \n",
      "chain:  2  iteration:  7880  parameters:  0.0288 0.1869 0.7467 5.1459 \n",
      "chain:  2  iteration:  7890  parameters:  0.0401 0.2196 0.6717 5.2287 \n",
      "chain:  2  iteration:  7900  parameters:  0.0293 0.2486 0.6679 5.0933 \n",
      "chain:  2  iteration:  7910  parameters:  0.0318 0.2637 0.7289 4.8133 \n",
      "chain:  2  iteration:  7920  parameters:  0.0348 0.2303 0.6814 4.5348 \n",
      "chain:  2  iteration:  7930  parameters:  0.0469 0.2519 0.6329 5.1736 \n",
      "chain:  2  iteration:  7940  parameters:  0.0477 0.3447 0.6145 4.6151 \n",
      "chain:  2  iteration:  7950  parameters:  0.0509 0.2011 0.6712 5.4983 \n",
      "chain:  2  iteration:  7960  parameters:  0.022 0.2633 0.7028 6.2339 \n",
      "chain:  2  iteration:  7970  parameters:  0.0271 0.2282 0.7197 5.5868 \n",
      "chain:  2  iteration:  7980  parameters:  0.025 0.1427 0.7987 6.5884 \n",
      "chain:  2  iteration:  7990  parameters:  0.0218 0.197 0.7774 6.3535 \n",
      "chain:  2  iteration:  8000  parameters:  0.0184 0.2129 0.742 5.2147 \n",
      "chain:  2  iteration:  8010  parameters:  0.0232 0.1948 0.7778 5.045 \n",
      "chain:  2  iteration:  8020  parameters:  0.0242 0.1892 0.7795 4.6231 \n",
      "chain:  2  iteration:  8030  parameters:  0.012 0.2139 0.7894 4.3174 \n",
      "chain:  2  iteration:  8040  parameters:  0.0221 0.2158 0.7324 4.2532 \n",
      "chain:  2  iteration:  8050  parameters:  0.0266 0.2069 0.7549 4.8374 \n",
      "chain:  2  iteration:  8060  parameters:  0.0214 0.1973 0.7636 4.2927 \n",
      "chain:  2  iteration:  8070  parameters:  0.012 0.2207 0.7891 4.6577 \n",
      "chain:  2  iteration:  8080  parameters:  0.0179 0.1662 0.7894 5.3086 \n",
      "chain:  2  iteration:  8090  parameters:  0.0177 0.2349 0.761 5.1641 \n",
      "chain:  2  iteration:  8100  parameters:  0.0302 0.2078 0.731 5.1281 \n",
      "chain:  2  iteration:  8110  parameters:  0.0329 0.2053 0.6996 5.7008 \n",
      "chain:  2  iteration:  8120  parameters:  0.0231 0.2733 0.6918 5.5017 \n",
      "chain:  2  iteration:  8130  parameters:  0.0359 0.2397 0.7098 5.0913 \n",
      "chain:  2  iteration:  8140  parameters:  0.0335 0.2719 0.6725 5.3303 \n",
      "chain:  2  iteration:  8150  parameters:  0.0448 0.2928 0.6238 4.856 \n",
      "chain:  2  iteration:  8160  parameters:  0.0403 0.3023 0.627 5.247 \n",
      "chain:  2  iteration:  8170  parameters:  0.0273 0.2156 0.7553 4.2028 \n",
      "chain:  2  iteration:  8180  parameters:  0.0235 0.2204 0.7566 4.3357 \n",
      "chain:  2  iteration:  8190  parameters:  0.0189 0.2598 0.7714 4.4923 \n",
      "chain:  2  iteration:  8200  parameters:  0.0512 0.323 0.6292 4.1299 \n",
      "chain:  2  iteration:  8210  parameters:  0.0538 0.3251 0.5902 4.4369 \n",
      "chain:  2  iteration:  8220  parameters:  0.0348 0.2797 0.6547 5.1025 \n",
      "chain:  2  iteration:  8230  parameters:  0.0328 0.2707 0.6543 6.149 \n",
      "chain:  2  iteration:  8240  parameters:  0.0538 0.257 0.5902 5.1351 \n",
      "chain:  2  iteration:  8250  parameters:  0.0408 0.321 0.635 5.4124 \n",
      "chain:  2  iteration:  8260  parameters:  0.031 0.2265 0.7056 4.8901 \n",
      "chain:  2  iteration:  8270  parameters:  0.0328 0.2632 0.7037 4.3742 \n",
      "chain:  2  iteration:  8280  parameters:  0.03 0.2551 0.719 5.5269 \n",
      "chain:  2  iteration:  8290  parameters:  0.0349 0.1751 0.7613 5.4564 \n",
      "chain:  2  iteration:  8300  parameters:  0.0351 0.2235 0.65 7.3054 \n",
      "chain:  2  iteration:  8310  parameters:  0.0397 0.2244 0.6399 7.1072 \n",
      "chain:  2  iteration:  8320  parameters:  0.0368 0.239 0.6173 7.3917 \n",
      "chain:  2  iteration:  8330  parameters:  0.0289 0.2452 0.6728 7.3797 \n",
      "chain:  2  iteration:  8340  parameters:  0.0293 0.1641 0.747 9.595 \n",
      "chain:  2  iteration:  8350  parameters:  0.0257 0.2213 0.7192 10.0671 \n",
      "chain:  2  iteration:  8360  parameters:  0.0259 0.2071 0.7133 7.0011 \n",
      "chain:  2  iteration:  8370  parameters:  0.0288 0.1547 0.7416 8.0863 \n",
      "chain:  2  iteration:  8380  parameters:  0.0355 0.1685 0.7241 8.3283 \n",
      "chain:  2  iteration:  8390  parameters:  0.0328 0.3088 0.6313 8.2445 \n",
      "chain:  2  iteration:  8400  parameters:  0.0371 0.2486 0.6573 7.9087 \n",
      "chain:  2  iteration:  8410  parameters:  0.0185 0.2191 0.758 6.5595 \n",
      "chain:  2  iteration:  8420  parameters:  0.0172 0.2053 0.7494 6.7343 \n",
      "chain:  2  iteration:  8430  parameters:  0.019 0.1823 0.7601 8.2438 \n",
      "chain:  2  iteration:  8440  parameters:  0.02 0.1569 0.7904 6.2399 \n",
      "chain:  2  iteration:  8450  parameters:  0.029 0.1657 0.7653 5.6064 \n",
      "chain:  2  iteration:  8460  parameters:  0.0273 0.1365 0.7793 6.7211 \n",
      "chain:  2  iteration:  8470  parameters:  0.0235 0.1044 0.8098 6.8696 \n",
      "chain:  2  iteration:  8480  parameters:  0.0179 0.1628 0.7968 7.9408 \n",
      "chain:  2  iteration:  8490  parameters:  0.0128 0.1478 0.8184 7.602 \n",
      "chain:  2  iteration:  8500  parameters:  0.0223 0.1364 0.8033 8.1726 \n",
      "chain:  2  iteration:  8510  parameters:  0.0146 0.1661 0.8019 10.5351 \n",
      "chain:  2  iteration:  8520  parameters:  0.0201 0.1801 0.7818 9.2217 \n",
      "chain:  2  iteration:  8530  parameters:  0.0452 0.17 0.6945 6.7677 \n",
      "chain:  2  iteration:  8540  parameters:  0.0396 0.2609 0.6327 8.4198 \n",
      "chain:  2  iteration:  8550  parameters:  0.0444 0.2102 0.6543 8.4392 \n",
      "chain:  2  iteration:  8560  parameters:  0.0424 0.3446 0.5387 7.8461 \n",
      "chain:  2  iteration:  8570  parameters:  0.0611 0.2866 0.5373 10.1751 \n",
      "chain:  2  iteration:  8580  parameters:  0.0626 0.2681 0.5287 12.0235 \n",
      "chain:  2  iteration:  8590  parameters:  0.0628 0.3138 0.4757 9.758 \n",
      "chain:  2  iteration:  8600  parameters:  0.0376 0.2917 0.6292 7.5439 \n",
      "chain:  2  iteration:  8610  parameters:  0.0405 0.2588 0.6159 6.8837 \n",
      "chain:  2  iteration:  8620  parameters:  0.0299 0.2836 0.7046 5.6687 \n",
      "chain:  2  iteration:  8630  parameters:  0.0376 0.2328 0.6818 5.1749 \n",
      "chain:  2  iteration:  8640  parameters:  0.0363 0.246 0.6938 5.6717 \n",
      "chain:  2  iteration:  8650  parameters:  0.034 0.1849 0.6933 5.752 \n",
      "chain:  2  iteration:  8660  parameters:  0.0266 0.3018 0.6746 5.8372 \n",
      "chain:  2  iteration:  8670  parameters:  0.0345 0.2425 0.6717 5.7986 \n",
      "chain:  2  iteration:  8680  parameters:  0.0355 0.1786 0.6991 5.9629 \n",
      "chain:  2  iteration:  8690  parameters:  0.0361 0.2145 0.6891 7.0245 \n",
      "chain:  2  iteration:  8700  parameters:  0.0207 0.2656 0.7307 5.7549 \n",
      "chain:  2  iteration:  8710  parameters:  0.0286 0.1378 0.7543 5.2899 \n",
      "chain:  2  iteration:  8720  parameters:  0.0353 0.1956 0.7149 4.5885 \n",
      "chain:  2  iteration:  8730  parameters:  0.0283 0.2072 0.719 4.969 \n",
      "chain:  2  iteration:  8740  parameters:  0.0234 0.2268 0.7269 5.0987 \n",
      "chain:  2  iteration:  8750  parameters:  0.024 0.1718 0.7539 6.0536 \n",
      "chain:  2  iteration:  8760  parameters:  0.0254 0.1597 0.7515 6.0836 \n",
      "chain:  2  iteration:  8770  parameters:  0.0236 0.1655 0.7952 5.1559 \n",
      "chain:  2  iteration:  8780  parameters:  0.0101 0.243 0.7761 5.269 \n",
      "chain:  2  iteration:  8790  parameters:  0.0199 0.1147 0.8182 6.0079 \n",
      "chain:  2  iteration:  8800  parameters:  0.0195 0.1635 0.8093 5.5666 \n",
      "chain:  2  iteration:  8810  parameters:  0.0141 0.1626 0.8027 5.354 \n",
      "chain:  2  iteration:  8820  parameters:  0.0213 0.1504 0.775 5.6327 \n",
      "chain:  2  iteration:  8830  parameters:  0.0218 0.1997 0.7717 6.0274 \n",
      "chain:  2  iteration:  8840  parameters:  0.0266 0.1784 0.7496 5.3834 \n",
      "chain:  2  iteration:  8850  parameters:  0.0288 0.2168 0.7372 7.2058 \n",
      "chain:  2  iteration:  8860  parameters:  0.0329 0.1795 0.7177 6.1301 \n",
      "chain:  2  iteration:  8870  parameters:  0.0275 0.1788 0.7344 6.7307 \n",
      "chain:  2  iteration:  8880  parameters:  0.0511 0.1748 0.6461 6.1371 \n",
      "chain:  2  iteration:  8890  parameters:  0.0287 0.1814 0.7427 7.3966 \n",
      "chain:  2  iteration:  8900  parameters:  0.0312 0.1914 0.7153 7.692 \n",
      "chain:  2  iteration:  8910  parameters:  0.0174 0.2689 0.7237 5.7896 \n",
      "chain:  2  iteration:  8920  parameters:  0.0244 0.1884 0.7188 7.8594 \n",
      "chain:  2  iteration:  8930  parameters:  0.045 0.2605 0.642 6.1386 \n",
      "chain:  2  iteration:  8940  parameters:  0.0405 0.2061 0.6755 5.5347 \n",
      "chain:  2  iteration:  8950  parameters:  0.0325 0.1889 0.7269 6.8856 \n",
      "chain:  2  iteration:  8960  parameters:  0.0331 0.2371 0.6897 5.5918 \n",
      "chain:  2  iteration:  8970  parameters:  0.0304 0.3154 0.6529 5.9536 \n",
      "chain:  2  iteration:  8980  parameters:  0.0203 0.2182 0.7283 6.5157 \n",
      "chain:  2  iteration:  8990  parameters:  0.0209 0.2102 0.7612 5.8043 \n",
      "chain:  2  iteration:  9000  parameters:  0.0223 0.199 0.7298 6.9339 \n",
      "chain:  2  iteration:  9010  parameters:  0.0231 0.1801 0.732 6.0978 \n",
      "chain:  2  iteration:  9020  parameters:  0.029 0.224 0.7423 6.2099 \n",
      "chain:  2  iteration:  9030  parameters:  0.0297 0.1762 0.7469 5.6927 \n",
      "chain:  2  iteration:  9040  parameters:  0.0265 0.1818 0.7404 6.9126 \n",
      "chain:  2  iteration:  9050  parameters:  0.0266 0.2289 0.6945 7.6265 \n",
      "chain:  2  iteration:  9060  parameters:  0.0212 0.1875 0.7694 6.1041 \n",
      "chain:  2  iteration:  9070  parameters:  0.0253 0.2312 0.7129 5.8299 \n",
      "chain:  2  iteration:  9080  parameters:  0.0332 0.2116 0.6936 5.7774 \n",
      "chain:  2  iteration:  9090  parameters:  0.0248 0.2988 0.6913 5.3655 \n",
      "chain:  2  iteration:  9100  parameters:  0.0325 0.1662 0.7129 6.7208 \n",
      "chain:  2  iteration:  9110  parameters:  0.0285 0.1781 0.7519 5.8993 \n",
      "chain:  2  iteration:  9120  parameters:  0.0279 0.1852 0.7245 5.699 \n",
      "chain:  2  iteration:  9130  parameters:  0.0396 0.2652 0.6471 6.3611 \n",
      "chain:  2  iteration:  9140  parameters:  0.0379 0.2107 0.7149 5.9884 \n",
      "chain:  2  iteration:  9150  parameters:  0.0351 0.2426 0.6722 5.2965 \n",
      "chain:  2  iteration:  9160  parameters:  0.0309 0.1281 0.7586 5.6148 \n",
      "chain:  2  iteration:  9170  parameters:  0.0154 0.1216 0.8387 5.3523 \n",
      "chain:  2  iteration:  9180  parameters:  0.0131 0.1323 0.8394 4.8602 \n",
      "chain:  2  iteration:  9190  parameters:  0.0114 0.1869 0.8223 5.0489 \n",
      "chain:  2  iteration:  9200  parameters:  0.0216 0.1926 0.7549 5.6008 \n",
      "chain:  2  iteration:  9210  parameters:  0.0304 0.2596 0.6907 5.9592 \n",
      "chain:  2  iteration:  9220  parameters:  0.0302 0.242 0.7112 5.2653 \n",
      "chain:  2  iteration:  9230  parameters:  0.0267 0.2099 0.7463 4.9742 \n",
      "chain:  2  iteration:  9240  parameters:  0.0206 0.2101 0.7428 5.7638 \n",
      "chain:  2  iteration:  9250  parameters:  0.0239 0.1829 0.7601 5.7049 \n",
      "chain:  2  iteration:  9260  parameters:  0.0224 0.1443 0.8206 6.3311 \n",
      "chain:  2  iteration:  9270  parameters:  0.009 0.1869 0.8265 5.8116 \n",
      "chain:  2  iteration:  9280  parameters:  0.0249 0.2194 0.7266 5.9855 \n",
      "chain:  2  iteration:  9290  parameters:  0.0275 0.2167 0.7354 5.3065 \n",
      "chain:  2  iteration:  9300  parameters:  0.0228 0.2009 0.76 5.9912 \n",
      "chain:  2  iteration:  9310  parameters:  0.0189 0.1669 0.798 5.5474 \n",
      "chain:  2  iteration:  9320  parameters:  0.0257 0.167 0.7606 5.0325 \n",
      "chain:  2  iteration:  9330  parameters:  0.0394 0.2794 0.6858 4.737 \n",
      "chain:  2  iteration:  9340  parameters:  0.0284 0.3144 0.6315 4.5389 \n",
      "chain:  2  iteration:  9350  parameters:  0.0464 0.2915 0.668 3.8693 \n",
      "chain:  2  iteration:  9360  parameters:  0.0419 0.1968 0.7279 3.9938 \n",
      "chain:  2  iteration:  9370  parameters:  0.0216 0.3264 0.724 4.366 \n",
      "chain:  2  iteration:  9380  parameters:  0.0297 0.3209 0.7033 3.5126 \n",
      "chain:  2  iteration:  9390  parameters:  0.0563 0.4491 0.563 4.3729 \n",
      "chain:  2  iteration:  9400  parameters:  0.0971 0.3574 0.4401 4.6508 \n",
      "chain:  2  iteration:  9410  parameters:  0.0857 0.3053 0.5093 4.6028 \n",
      "chain:  2  iteration:  9420  parameters:  0.084 0.321 0.4759 5.1205 \n",
      "chain:  2  iteration:  9430  parameters:  0.0426 0.3773 0.6126 4.6045 \n",
      "chain:  2  iteration:  9440  parameters:  0.0659 0.3246 0.5625 3.8928 \n",
      "chain:  2  iteration:  9450  parameters:  0.0692 0.3878 0.537 4.4045 \n",
      "chain:  2  iteration:  9460  parameters:  0.0689 0.3898 0.5219 4.5389 \n",
      "chain:  2  iteration:  9470  parameters:  0.048 0.2764 0.6375 5.2226 \n",
      "chain:  2  iteration:  9480  parameters:  0.0341 0.3233 0.6336 4.7254 \n",
      "chain:  2  iteration:  9490  parameters:  0.032 0.259 0.6544 4.6091 \n",
      "chain:  2  iteration:  9500  parameters:  0.041 0.2405 0.6884 4.4176 \n",
      "chain:  2  iteration:  9510  parameters:  0.0343 0.2094 0.7037 4.6513 \n",
      "chain:  2  iteration:  9520  parameters:  0.0211 0.2568 0.7349 4.265 \n",
      "chain:  2  iteration:  9530  parameters:  0.0333 0.1995 0.7406 4.7737 \n",
      "chain:  2  iteration:  9540  parameters:  0.0303 0.1859 0.6975 5.9463 \n",
      "chain:  2  iteration:  9550  parameters:  0.0466 0.1782 0.6701 5.8481 \n",
      "chain:  2  iteration:  9560  parameters:  0.0465 0.23 0.6347 6.4582 \n",
      "chain:  2  iteration:  9570  parameters:  0.0342 0.3118 0.6608 5.6373 \n",
      "chain:  2  iteration:  9580  parameters:  0.0247 0.2931 0.685 4.9895 \n",
      "chain:  2  iteration:  9590  parameters:  0.0227 0.205 0.7369 5.0122 \n",
      "chain:  2  iteration:  9600  parameters:  0.0279 0.1728 0.7558 5.2468 \n",
      "chain:  2  iteration:  9610  parameters:  0.031 0.1756 0.7091 5.6002 \n",
      "chain:  2  iteration:  9620  parameters:  0.0288 0.2513 0.6878 5.1324 \n",
      "chain:  2  iteration:  9630  parameters:  0.0326 0.2679 0.667 5.754 \n",
      "chain:  2  iteration:  9640  parameters:  0.029 0.212 0.7193 5.0977 \n",
      "chain:  2  iteration:  9650  parameters:  0.0367 0.1727 0.7461 4.5193 \n",
      "chain:  2  iteration:  9660  parameters:  0.0402 0.2676 0.6403 5.0377 \n",
      "chain:  2  iteration:  9670  parameters:  0.0418 0.2239 0.6982 4.5938 \n",
      "chain:  2  iteration:  9680  parameters:  0.0313 0.2507 0.6628 5.8066 \n",
      "chain:  2  iteration:  9690  parameters:  0.0194 0.2794 0.7217 5.6168 \n",
      "chain:  2  iteration:  9700  parameters:  0.0302 0.1951 0.7112 6.0281 \n",
      "chain:  2  iteration:  9710  parameters:  0.0239 0.1931 0.751 5.59 \n",
      "chain:  2  iteration:  9720  parameters:  0.0111 0.1853 0.8127 6.1486 \n",
      "chain:  2  iteration:  9730  parameters:  0.0205 0.1198 0.8278 6.2445 \n",
      "chain:  2  iteration:  9740  parameters:  0.0127 0.1505 0.8303 5.73 \n",
      "chain:  2  iteration:  9750  parameters:  0.0237 0.1072 0.817 5.0019 \n",
      "chain:  2  iteration:  9760  parameters:  0.0281 0.1406 0.7965 4.7039 \n",
      "chain:  2  iteration:  9770  parameters:  0.0152 0.1689 0.8043 4.6506 \n",
      "chain:  2  iteration:  9780  parameters:  0.0153 0.161 0.8264 4.4027 \n",
      "chain:  2  iteration:  9790  parameters:  0.0209 0.1765 0.808 5.2338 \n",
      "chain:  2  iteration:  9800  parameters:  0.0211 0.2207 0.7444 4.9464 \n",
      "chain:  2  iteration:  9810  parameters:  0.0218 0.2199 0.7565 4.8659 \n",
      "chain:  2  iteration:  9820  parameters:  0.0248 0.2144 0.7542 5.2646 \n",
      "chain:  2  iteration:  9830  parameters:  0.0096 0.2377 0.7926 4.6606 \n",
      "chain:  2  iteration:  9840  parameters:  0.0136 0.2089 0.769 5.1364 \n",
      "chain:  2  iteration:  9850  parameters:  0.0121 0.1947 0.8185 5.0026 \n",
      "chain:  2  iteration:  9860  parameters:  0.0155 0.1396 0.8233 5.9162 \n",
      "chain:  2  iteration:  9870  parameters:  0.0208 0.1766 0.7824 5.6036 \n",
      "chain:  2  iteration:  9880  parameters:  0.0274 0.2077 0.6994 4.877 \n",
      "chain:  2  iteration:  9890  parameters:  0.0169 0.1961 0.7624 5.2085 \n",
      "chain:  2  iteration:  9900  parameters:  0.0241 0.1341 0.8035 4.3855 \n",
      "chain:  2  iteration:  9910  parameters:  0.0172 0.1451 0.801 5.2521 \n",
      "chain:  2  iteration:  9920  parameters:  0.0185 0.2056 0.7841 5.162 \n",
      "chain:  2  iteration:  9930  parameters:  0.0218 0.1671 0.7809 5.3417 \n",
      "chain:  2  iteration:  9940  parameters:  0.0234 0.2456 0.6926 6.8746 \n",
      "chain:  2  iteration:  9950  parameters:  0.0371 0.2339 0.6572 6.7131 \n",
      "chain:  2  iteration:  9960  parameters:  0.0417 0.2324 0.6367 8.2757 \n",
      "chain:  2  iteration:  9970  parameters:  0.0432 0.2294 0.6105 9.0572 \n",
      "chain:  2  iteration:  9980  parameters:  0.057 0.3684 0.527 8.4484 \n",
      "chain:  2  iteration:  9990  parameters:  0.0493 0.2388 0.5969 7.7065 \n",
      "chain:  2  iteration:  10000  parameters:  0.0544 0.2821 0.6136 6.5801 \n"
     ]
    }
   ],
   "source": [
    "mcmc <- bayesGARCH(y, control = list(n.chain = 2, l.chain = 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n.chain:  2 \n",
      "l.chain:  10000 \n",
      "l.bi:  500 \n",
      "batch.size:  1 \n",
      "smpl size:  19000 \n"
     ]
    }
   ],
   "source": [
    "smpl <- formSmpl(mcmc, l.bi = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Iterations = 1:19000\n",
       "Thinning interval = 1 \n",
       "Number of chains = 1 \n",
       "Sample size per chain = 19000 \n",
       "\n",
       "1. Empirical mean and standard deviation for each variable,\n",
       "   plus standard error of the mean:\n",
       "\n",
       "          Mean      SD  Naive SE Time-series SE\n",
       "alpha0 0.03468 0.01488 0.0001080      0.0009616\n",
       "alpha1 0.23961 0.07148 0.0005186      0.0047609\n",
       "beta   0.68720 0.08519 0.0006180      0.0060648\n",
       "nu     5.99034 1.63491 0.0118609      0.1197958\n",
       "\n",
       "2. Quantiles for each variable:\n",
       "\n",
       "          2.5%     25%     50%    75%   97.5%\n",
       "alpha0 0.01261 0.02374 0.03246 0.0430 0.07054\n",
       "alpha1 0.12437 0.18888 0.23233 0.2799 0.40564\n",
       "beta   0.50330 0.63380 0.69295 0.7500 0.83000\n",
       "nu     3.80827 4.89464 5.67226 6.7176 9.91333\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(smpl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
